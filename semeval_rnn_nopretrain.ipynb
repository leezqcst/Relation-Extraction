{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import collections\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "\n",
    "import data_handler as dh\n",
    "import semeval_data_helper as sdh\n",
    "# plot settings\n",
    "% matplotlib inline\n",
    "# print(plt.rcParams.keys())\n",
    "plt.rcParams['figure.figsize'] = (16,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RelEmbed(object):\n",
    "    \"\"\" Encapsulation of the dependency RNN lang model\"\"\"\n",
    "    def __init__(self, config):\n",
    "        self.max_num_steps = config['max_num_steps']\n",
    "        self.word_embed_size = config['word_embed_size']\n",
    "        self.dep_embed_size = config['dep_embed_size']\n",
    "#         self.class_hidden_size = config['class_hidden_size']\n",
    "        self.input_size = self.word_embed_size + self.dep_embed_size\n",
    "        self.hidden_size = 2 * self.word_embed_size #config['hidden_size']\n",
    "        self.pretrained_word_embeddings = config['pretrained_word_embeddings'] # None if we don't provide them\n",
    "        if np.any(self.pretrained_word_embeddings):\n",
    "            assert self.word_embed_size == self.pretrained_word_embeddings.shape[1]\n",
    "        self.num_classes = config['num_predict_classes']\n",
    "        self.max_grad_norm = config['max_grad_norm']\n",
    "        \n",
    "        self.vocab_size = config['vocab_size']\n",
    "        self.dep_vocab_size = config['dep_vocab_size']\n",
    "        self.name = config['model_name']\n",
    "        self.checkpoint_prefix = config['checkpoint_prefix'] + self.name\n",
    "        self.summary_prefix = config['summary_prefix'] + self.name\n",
    "        \n",
    "        # initialize with gaussian Xavier initialization\n",
    "        self.word_initializer = tf.truncated_normal_initializer(mean=0.0, stddev=1./(self.word_embed_size))\n",
    "        self.dep_initializer = tf.truncated_normal_initializer(mean=0.0, stddev=1./(self.dep_embed_size))\n",
    "        self.hidden_initializer = tf.truncated_normal_initializer(mean=0.0, stddev=1./(self.hidden_size))\n",
    "        with tf.name_scope(self.name):\n",
    "            with tf.name_scope(\"Forward\"):\n",
    "                self._build_forward_graph()\n",
    "                with tf.name_scope(\"Classification\"):\n",
    "                    self._build_classification_graph()\n",
    "            with tf.name_scope(\"Backward\"):\n",
    "                self._build_train_graph()\n",
    "                self._build_class_train_graph()\n",
    "            with tf.name_scope(\"Nearby\"):\n",
    "                self._build_similarity_graph()\n",
    "        \n",
    "        self._valid_accuracy = tf.Variable(0.0, trainable=False)\n",
    "        self._valid_acc_summary = tf.merge_summary([tf.scalar_summary(\"Valid_accuracy\", self._valid_accuracy)])\n",
    "\n",
    "        self.saver = tf.train.Saver(tf.all_variables(), max_to_keep=config['checkpoints_to_keep'])\n",
    "            \n",
    "        self.session = tf.InteractiveSession()\n",
    "        self.session.run(tf.initialize_all_variables())        \n",
    "        self.summary_writer = tf.train.SummaryWriter(self.summary_prefix, self.session.graph_def)\n",
    "        \n",
    "    def save_validation_accuracy(self, new_score):\n",
    "        assign_op = self._valid_accuracy.assign(new_score)\n",
    "        _, summary = self.session.run([assign_op, self._valid_acc_summary])\n",
    "        self.summary_writer.add_summary(summary)\n",
    "    \n",
    "#     def one_hot(self, dense_labels):\n",
    "#         sparse_labels = tf.reshape(dense_labels, [-1, 1])\n",
    "#         derived_size = tf.shape(dense_labels)[0]\n",
    "#         if dense_labels.dtype == tf.int64:\n",
    "#             indices = tf.to_int64(tf.reshape(tf.range(0, derived_size, 1,), [-1, 1]))\n",
    "#             concated = tf.concat(1, [indices, sparse_labels])\n",
    "#             outshape = tf.to_int64(tf.pack([derived_size, self.num_classes]))\n",
    "#             labels = tf.sparse_to_dense(concated, outshape, 1.0, 0.0)\n",
    "#         else:\n",
    "#             indices = tf.reshape(tf.range(0, derived_size, 1,), [-1, 1])\n",
    "#             concated = tf.concat(1, [indices, sparse_labels])\n",
    "#             outshape = tf.pack([derived_size, self.num_classes])\n",
    "#             labels = tf.sparse_to_dense(concated, outshape, 1.0, 0.0)\n",
    "#         return labels\n",
    "        \n",
    "    def _build_forward_graph(self):\n",
    "        # input tensor of zero padded indices to get to max_num_steps\n",
    "        # None allows for variable batch sizes\n",
    "        self._lambda = tf.Variable(.001, trainable=False, name=\"L2_Lambda\")\n",
    "        with tf.name_scope(\"Inputs\"):\n",
    "            self._input_phrases = tf.placeholder(tf.int32, [None, self.max_num_steps, 2]) # [batch_size, w_{1:N}, 2]\n",
    "            self._input_targets = tf.placeholder(tf.int32, [None, 2]) # [batch_size, w_x]\n",
    "            self._input_labels = tf.placeholder(tf.int32, [None, 1]) # [batch_size, from true data?] \\in {0,1}\n",
    "            self._input_lengths = tf.placeholder(tf.int32, [None, 1]) # [batch_size, N] (len of each sequence)\n",
    "            self._keep_prob = tf.placeholder(tf.float32) # keep prob for drop out\n",
    "            batch_size = tf.shape(self._input_lengths)[0]\n",
    "        \n",
    "        with tf.name_scope(\"Embeddings\"):\n",
    "            if np.any(self.pretrained_word_embeddings):\n",
    "                self._word_embeddings = tf.Variable(self.pretrained_word_embeddings, name=\"word_embeddings\")\n",
    "                self._left_target_embeddings = tf.Variable(self.pretrained_word_embeddings, name=\"left_target_embeddings\")\n",
    "                self._right_target_embeddings = tf.Variable(self.pretrained_word_embeddings, name=\"right_target_embeddings\")\n",
    "            else:\n",
    "                self._word_embeddings = tf.get_variable(\"word_embeddings\", \n",
    "                                                        [self.vocab_size, self.word_embed_size], \n",
    "                                                    initializer=self.word_initializer,\n",
    "                                                        dtype=tf.float32)\n",
    "                self._left_target_embeddings = tf.get_variable(\"left_target_embeddings\", \n",
    "                                                        [self.vocab_size, self.word_embed_size], \n",
    "                                                    initializer=self.word_initializer,\n",
    "                                                        dtype=tf.float32)\n",
    "                self._right_target_embeddings = tf.get_variable(\"right_target_embeddings\", \n",
    "                                                        [self.vocab_size, self.word_embed_size], \n",
    "                                                    initializer=self.word_initializer,\n",
    "                                                        dtype=tf.float32)\n",
    "            \n",
    "            self._dependency_embeddings = tf.get_variable(\"dependency_embeddings\", \n",
    "                                                    [self.dep_vocab_size, self.dep_embed_size], \n",
    "                                                    initializer=self.dep_initializer,\n",
    "                                                    dtype=tf.float32)\n",
    "            # TODO: Add POS embeddings\n",
    "            \n",
    "            input_embeds = tf.nn.dropout(tf.nn.embedding_lookup(self._word_embeddings, \n",
    "                                                  tf.slice(self._input_phrases, [0,0,0], [-1, -1, 1])),\n",
    "                                         self._keep_prob)\n",
    "            dep_embeds = tf.nn.dropout(tf.nn.embedding_lookup(self._dependency_embeddings,\n",
    "                                                tf.slice(self._input_phrases, [0,0,1], [-1, -1, 1])),\n",
    "                                       self._keep_prob)\n",
    "            left_target_embeds = tf.nn.dropout(tf.nn.embedding_lookup(self._left_target_embeddings, \n",
    "                                                        tf.slice(self._input_targets, [0,0], [-1, 1])),\n",
    "                                               self._keep_prob)\n",
    "            right_target_embeds = tf.nn.dropout(tf.nn.embedding_lookup(self._right_target_embeddings, \n",
    "                                                        tf.slice(self._input_targets, [0,1], [-1, 1])),\n",
    "                                                self._keep_prob)\n",
    "#             print(tf.slice(self._input_phrases, [0,0,1], [-1, -1, 1]).get_shape(), dep_embeds.get_shape())\n",
    "#             print(left_target_embeds.get_shape(), right_target_embeds.get_shape())\n",
    "            self._target_embeds = tf.squeeze(tf.concat(2, [left_target_embeds, right_target_embeds]), [1])\n",
    "#             print(target_embeds.get_shape())\n",
    "        \n",
    "        with tf.name_scope(\"RNN\"):\n",
    "            # start off with a basic configuration\n",
    "#             self.cell = tf.nn.rnn_cell.GRUCell(self.hidden_size, \n",
    "#                                                 input_size=self.input_size)\n",
    "            self.fwcell = tf.nn.rnn_cell.GRUCell(self.hidden_size/2, \n",
    "                                                input_size=self.input_size)\n",
    "            self.bwcell = tf.nn.rnn_cell.GRUCell(self.hidden_size/2, \n",
    "                                                input_size=self.input_size)\n",
    "            # TODO: Make it multilevel\n",
    "#             self._initial_state = self.cell.zero_state(batch_size, tf.float32)\n",
    "#             print(self._initial_state.get_shape())\n",
    "            input_words = [ tf.squeeze(input_, [1, 2]) for input_ in tf.split(1, self.max_num_steps, input_embeds)]\n",
    "            input_deps = [ tf.squeeze(input_, [1, 2]) for input_ in tf.split(1, self.max_num_steps, dep_embeds)]\n",
    "            inputs = [ tf.concat(1, [input_word, input_dep]) \n",
    "                      for (input_word, input_dep) in zip(input_words, input_deps)]\n",
    "\n",
    "#             _, state = tf.nn.rnn(self.cell, inputs, \n",
    "#                                  sequence_length=tf.squeeze(self._input_lengths, [1]),\n",
    "#                                  dtype=tf.float32)\n",
    "            outs = tf.nn.bidirectional_rnn(self.fwcell, self.bwcell, inputs, \n",
    "                                        sequence_length=tf.to_int64(tf.squeeze(self._input_lengths, [1])),\n",
    "                                        dtype=tf.float32)\n",
    "            # splice out the final forward and backward hidden states since apparently the documentation lies\n",
    "            fw_state = tf.split(1, 2, outs[-1])[0]\n",
    "            bw_state = tf.split(1, 2, outs[0])[1]\n",
    "            state = tf.concat(1, [fw_state, bw_state])\n",
    "#             print(outs)\n",
    "#             state=outs[0]\n",
    "            self._final_state = tf.nn.dropout(state, self._keep_prob)\n",
    "            \n",
    "        with tf.name_scope(\"Loss\"):\n",
    "            flat_states = tf.reshape(state, [-1])\n",
    "            flat_target_embeds = tf.reshape(self._target_embeds, [-1])\n",
    "#             assert self.hidden_size == (self.word_embed_size), \"Hidden state must equal concated inputs\" \n",
    "            flat_logits = tf.mul(flat_states, flat_target_embeds)\n",
    "            logits = tf.reduce_sum(tf.reshape(flat_logits, tf.pack([batch_size, -1])), 1)\n",
    "#             self._l2_penalty = self._lambda*tf.nn.l2_loss(logits, name='l2_penalty')\n",
    "            self._l2_penalty = self._lambda*(tf.nn.l2_loss(self._word_embeddings)\n",
    "                                            +tf.nn.l2_loss(self._dependency_embeddings)\n",
    "                                            +tf.nn.l2_loss(self._left_target_embeddings)\n",
    "                                            +tf.nn.l2_loss(self._right_target_embeddings))\n",
    "            self._xent = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits, \n",
    "                                                                    tf.to_float(self._input_labels)),\n",
    "                                        name=\"neg_sample_loss\")\n",
    "            self._loss = self._xent + self._l2_penalty\n",
    "            \n",
    "            \n",
    "            \n",
    "        with tf.name_scope(\"Summaries\"):\n",
    "            logit_mag = tf.histogram_summary(\"Logit_magnitudes\", logits)\n",
    "            l2 = tf.scalar_summary(\"L2_penalty\", self._l2_penalty)\n",
    "            xent = tf.scalar_summary(\"Sigmoid_xent\", self._xent)\n",
    "            target_embed_mag = tf.histogram_summary(\"Target_Embed_L2\", tf.nn.l2_loss(self._target_embeds))\n",
    "            state_mag = tf.histogram_summary(\"RNN_final_state_L2\", tf.nn.l2_loss(self._final_state))\n",
    "            self._penalty_summary = tf.merge_summary([logit_mag, l2, xent, target_embed_mag, state_mag])\n",
    "            self._train_cost_summary = tf.merge_summary([tf.scalar_summary(\"Train_NEG_Loss\", self._loss)])\n",
    "            self._valid_cost_summary = tf.merge_summary([tf.scalar_summary(\"Validation_NEG_Loss\", self._loss)])\n",
    "        \n",
    "    def _build_classification_graph(self):\n",
    "        with tf.name_scope(\"Classifier\"):\n",
    "            self._class_lambda = tf.Variable(0.01, trainable=False, name=\"Class_L2_Lambda\")\n",
    "            self._class_labels = tf.placeholder(tf.int64, [None, 1])\n",
    "            self._class_labels_mask = tf.placeholder(tf.bool, [None, self.num_classes])\n",
    "            self._softmax_input = tf.concat(1, [self._final_state, self._target_embeds], name=\"concat_input\")\n",
    "            batch_size = self._softmax_input.get_shape()[0]\n",
    "\n",
    "            # instead of concat lets element wise multiply\n",
    "            # CUBIC ADDITIVE POLYNOMICAL DEEP\n",
    "#             self._softmax_wh = tf.get_variable(\"softmax_wh\", [self.class_hidden_size, 2*self.hidden_size])\n",
    "# #             self._softmax_wt = tf.get_variable(\"softmax_wt\", [self.class_hidden_size, self.hidden_size])\n",
    "# #             self._softmax_wr = tf.get_variable(\"softmax_wr\", [self.class_hidden_size, self.word_embed_size])\n",
    "#             self._softmax_hb = tf.Variable(tf.zeros([self.class_hidden_size], dtype=tf.float32), name=\"softmax_hb\")\n",
    "            \n",
    "#             self._softmax_wc = tf.get_variable(\"softmax_wc\", [self.num_classes, self.class_hidden_size])\n",
    "#             self._softmax_cb = tf.Variable(tf.zeros([self.num_classes], dtype=tf.float32), name=\"softmax_cb\")\n",
    "            \n",
    "# #             self._softmax_W = tf.concat(1, [self._softmax_wh, self._softmax_wt])\n",
    "#             # [hidden size x batch size]\n",
    "#             hidden_logits = (tf.matmul( self._softmax_input, self._softmax_wh, transpose_b=True)\n",
    "#                             + self._softmax_hb)\n",
    "# #             hidden_logits = tf.add(tf.matmul(self._softmax_wh, self._softmax_input, transpose_b=True), self._softmax_hb)\n",
    "#             hidden_output = tf.nn.dropout(tf.pow(hidden_logits, 3., name=\"cubic_activation\"), keep_prob=self._keep_prob)\n",
    "# #             hidden_output = tf.nn.dropout(tf.nn.tanh(hidden_logits), keep_prob=self._keep_prob)\n",
    "            \n",
    "#             # [batch size x num classes]\n",
    "#             class_logits = tf.add(tf.transpose(tf.matmul(self._softmax_wc, hidden_output, transpose_b=True)), self._softmax_cb)\n",
    "#             self._class_softmax_l2 = self._class_lambda*(tf.nn.l2_loss(self._softmax_wh) # includes all three\n",
    "#                                                          + tf.nn.l2_loss(self._softmax_hb)\n",
    "#                                                          + tf.nn.l2_loss(self._softmax_wc)\n",
    "#                                                          + tf.nn.l2_loss(self._softmax_cb))\n",
    "# #             self._class_softmax_l2 = self._class_lambda*tf.nn.l2_loss(class_logits)\n",
    "#             self._predictions = tf.argmax(class_logits, 1, name=\"predict\")\n",
    "#             self._predict_probs = tf.nn.softmax(class_logits, name=\"predict_probabilities\")   \n",
    "            \n",
    "            # Multiplicative input\n",
    "#             self._softmax_input = tf.mul(self._final_state, self._target_embeds, name=\"mult_input\") \n",
    "            # Additive input\n",
    "#             self._softmax_input = self._final_state + self._target_embeds\n",
    "\n",
    "            # SIMPLE LOGISTIC\n",
    "#             self._softmax_w = tf.get_variable(\"softmax_w\", [self._softmax_input.get_shape()[1], self.num_classes])\n",
    "#             self._softmax_b = tf.Variable(tf.zeros([self.num_classes], dtype=tf.float32), name=\"softmax_b\")\n",
    "\n",
    "#             class_logits = tf.matmul(self._softmax_input, self._softmax_w) + self._softmax_b\n",
    "#             self._class_l2 = self._class_lambda*(tf.nn.l2_loss(self._softmax_w) \n",
    "#                                                          + tf.nn.l2_loss(self._softmax_b)\n",
    "#                                                          + tf.nn.l2_loss(self._softmax_input))\n",
    "#             self._predictions = tf.argmax(class_logits, 1, name=\"predict\")\n",
    "#             self._predict_probs = tf.nn.softmax(class_logits, name=\"predict_probabilities\")\n",
    "            \n",
    "            # SOFT PLUS RANKING LOSS W/O OTHER\n",
    "            self._scoring_w = tf.get_variable(\"score_w\",  [self.hidden_size, self.hidden_size, self.num_classes],\n",
    "                                                initializer=self.hidden_initializer)\n",
    "#             self._scoring_b = tf.Variable(tf.zeros([self.num_classes], dtype=tf.float32), name=\"score_b\")\n",
    "            self._margin = tf.Variable(2.0, trainable=False, name=\"Ranking_margin\")\n",
    "            \n",
    "            # batch tensor inner product (note: target == hidden)\n",
    "            hidden = tf.expand_dims(self._final_state, [1])   # [ batch, 1, hidden]\n",
    "            hidden = tf.tile(hidden, [self.num_classes, 1, 1])                      # [ batch x num_class, 1, hidden]\n",
    "            target = tf.expand_dims(self._target_embeds, [1]) # [ batch, 1, target]\n",
    "            target = tf.tile(target, [self.num_classes, 1, 1])                 # [ batch, x num_class, 1, target]\n",
    "            W = tf.reshape(self._scoring_w, [-1, self.hidden_size, self.hidden_size]) # [num_class, hidden, hidden]\n",
    "            W = tf.tile(W, tf.pack([tf.shape(self._target_embeds)[0], 1, 1]))                         # [ batch x num_class, hidden, hidden ]\n",
    "            left = tf.batch_matmul(hidden, W)                 # [bact x num_class, 1, hidden]\n",
    "            right = tf.squeeze(tf.batch_matmul(left, target, adj_y=True), [1,2]) # [batch x num_class]\n",
    "                        \n",
    "#             print(right.get_shape())\n",
    "            # we don't model the 'Other' class.  Also it's label index is num_classes (one past known classes)\n",
    "            scores = tf.reshape(right, tf.pack([tf.shape(self._target_embeds)[0], self.num_classes])) # [batch, num_class]\n",
    "            self._predictions = tf.argmax(scores[:,:num_classes-1], 1, name=\"predict\")\n",
    "            pred_scores = tf.reduce_max(scores[:,:num_classes-1], 1)\n",
    "            # take all predictions that have negative scores and replace them with 'Other' label\n",
    "            others = (self.num_classes-1)*tf.ones_like(self._predictions)\n",
    "            self._predictions = tf.select(tf.less_equal(pred_scores, tf.zeros_like(pred_scores)), \n",
    "                                          others, self._predictions)\n",
    "            \n",
    "        with tf.name_scope(\"Loss\"):\n",
    "#             # collect all of the scores for the true class, set to 0 if it was other\n",
    "#             flat_scores = tf.reshape(scores, [-1])\n",
    "#             flat_true_indices = tf.squeeze(self._class_labels, [1]) + tf.to_int64(tf.range(tf.shape(scores)[0])*tf.shape(scores)[1])\n",
    "#             # filter out the others\n",
    "#             flat_true_scores = tf.expand_dims(tf.gather(flat_scores, flat_true_indices), [1])\n",
    "\n",
    "#             others = tf.expand_dims(others, [1])\n",
    "\n",
    "#             self.true_scores = tf.select(tf.equal(self._class_labels, others),\n",
    "#                                     tf.zeros_like(self._class_labels, dtype=tf.float32), \n",
    "#                                     flat_true_scores, name=\"other_replace\")\n",
    "#             # tile it to match all size of all scores\n",
    "#             tile_scores = tf.tile(self.true_scores, [1, self.num_classes])\n",
    "#             # subtract margin from all scores where the score is the true class\n",
    "#             # at these we'll have the objective term is margin - true_score + true_score - margin = 0 \n",
    "#             flat_scores = tf.select(flat_true_indices, (flat_scores - self._margin), flat_scores)\n",
    "#             scores = tf.reshape(flat_scores)(scores.get_shape())\n",
    "#             # now calculate the component-wise rank losses\n",
    "#             rank_loss = tf.nn.softplus(self._margin*tf.ones_like(scores) - tile_scores + scores)\n",
    "# #             rank_loss = tf.maximum(tf.zeros_like(scores, dtype=tf.float32), \n",
    "# #                                    (self._margin*tf.ones_like(scores) - tile_scores + scores))\n",
    "#             self._avg_class_loss = tf.reduce_mean(rank_loss)\n",
    "    \n",
    "    \n",
    "            self._avg_class_loss, true_scores, false_scores = self.classification_loss(scores, \n",
    "                                                            self._class_labels, \n",
    "                                                            self._class_labels_mask,\n",
    "                                                            margin=self._margin, \n",
    "                                                            num_classes=self.num_classes)\n",
    "#             self._avg_class_xent = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(class_logits, \n",
    "#                                                                               tf.squeeze(self._class_labels, [1])))\n",
    "#             self._class_loss = self._avg_class_xent + self._class_softmax_l2\n",
    "            self._class_l2 = self._class_lambda*(tf.nn.l2_loss(self._scoring_w))\n",
    "            self._class_loss = self._avg_class_loss + self._class_l2\n",
    "            \n",
    "        with tf.name_scope(\"Summaries\"):\n",
    "            class_true_scores = tf.histogram_summary(\"Classify_true_scores\", true_scores)\n",
    "            class_false_scores = tf.histogram_summary(\"Classify_false_scores\", false_scores)\n",
    "            class_hidden_mag = tf.histogram_summary(\"Classify_hidden_magnitudes\", self._final_state)\n",
    "            class_target_mag = tf.histogram_summary(\"Classify_target_magnitudes\", self._target_embeds)\n",
    "            class_w_mag = tf.histogram_summary(\"Classify_w_magnitudes\", self._scoring_w)\n",
    "            class_logit_mag = tf.histogram_summary(\"Classify_Score_magnitudes\", scores)\n",
    "#             class_logit_mag = tf.histogram_summary(\"Classify_Logit_magnitudes\", class_logits)\n",
    "            class_l2 = tf.scalar_summary(\"Classify_L2_penalty\", self._class_l2)\n",
    "#             class_xent = tf.scalar_summary(\"Avg_Softmax_xent\", self._avg_class_xent)\n",
    "            class_xent = tf.scalar_summary(\"Avg_Log_Rank_Loss\", self._avg_class_loss)\n",
    "            self._class_penalty_summary = tf.merge_summary([class_true_scores, class_false_scores,\n",
    "                                                            class_hidden_mag, class_target_mag, class_w_mag,\n",
    "                                                            class_logit_mag, class_l2, class_xent])\n",
    "            self._train_class_loss_summary = tf.merge_summary([tf.scalar_summary(\"Train_Avg_Log_Rank_Loss\", self._class_loss)])\n",
    "            self._valid_class_loss_summary = tf.merge_summary([tf.scalar_summary(\"Valid_Avg_Log_Rank_Loss\", self._class_loss)])\n",
    "\n",
    "    def classification_loss(self, scores, class_labels, label_mask, margin=1.0, num_classes=3):\n",
    "        \"\"\"Calculate the classification loss of the network\n",
    "\n",
    "        Args:\n",
    "            - scores (Tensor[batch_size, num_classes]): \n",
    "                The matrix of predicted scores for all examples\n",
    "\n",
    "            - class_labels (Tensor[batch_size, 1]):\n",
    "                The list lof class labels with an expanded 2nd dimension\n",
    "\n",
    "            - label_mask (Tensor[batch_size, num_classes], dtype=bool): \n",
    "                The boolean masked encoding of the class labels for the score tensor.\n",
    "                Done this way because sparse indicator masks in tensorflow have unknown shapes...\n",
    "\n",
    "        Returns:\n",
    "            avg_class_loss: the average loss over all of the scores\n",
    "        \"\"\"\n",
    "        # get the true values\n",
    "        print(scores.op)\n",
    "#         true_scores = tf.expand_dims(tf.boolean_mask(scores, label_mask), [1])\n",
    "#         false_scores = tf.expand_dims(tf.boolean_mask(scores, tf.logical_not(label_mask)), [1])\n",
    "        true_scores = tf.ones_like(scores)\n",
    "        false_scores = tf.zeros_like(scores)\n",
    "        # set true values for 'Other' class to zero (we don't actually model that class)\n",
    "        others = (num_classes-1)*tf.ones_like(class_labels)\n",
    "        true_scores = tf.select(tf.equal(class_labels, others),\n",
    "                        tf.zeros_like(class_labels, dtype=tf.float32), \n",
    "                        true_scores, name=\"other_replace\")\n",
    "        # repeat the true score across columns for each row\n",
    "        tile_true_scores = tf.tile(true_scores, [1, num_classes])\n",
    "\n",
    "        # create margins same size as scores\n",
    "        margins = margin*tf.ones_like(scores)\n",
    "\n",
    "        # calculate the intermediate loss value inside the real loss function\n",
    "        raw_loss = margins - tile_true_scores + scores\n",
    "\n",
    "        # set the loss for true labels to 0\n",
    "        raw_loss = tf.select(label_mask, tf.zeros_like(raw_loss), raw_loss)\n",
    "        \n",
    "#         # use only the highest loss \n",
    "#         raw_loss = tf.reduce_max(raw_loss, 1, keep_dims=True)\n",
    "\n",
    "        # SOFT PLUS LOSS\n",
    "        rank_loss = tf.nn.softplus(raw_loss)\n",
    "        # HINGE LOSS\n",
    "#         rank_loss = tf.maximum(tf.zeros_like(scores, dtype=tf.float32), raw_loss)\n",
    "        \n",
    "        loss = tf.reduce_mean(tf.reduce_sum(rank_loss, 1))\n",
    "        return loss, true_scores, false_scores\n",
    "    \n",
    "            \n",
    "    def _build_train_graph(self):\n",
    "        with tf.name_scope(\"Unsupervised_Trainer\"):\n",
    "            self._global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "#             self._lr = tf.Variable(1.0, trainable=False)\n",
    "            self._optimizer = tf.train.AdagradOptimizer(1.0)\n",
    "            \n",
    "            # clip and apply gradients\n",
    "            grads_and_vars = self._optimizer.compute_gradients(self._loss)\n",
    "#             for gv in grads_and_vars:\n",
    "#                 print(gv, gv[1] is self._cost)\n",
    "            clipped_grads_and_vars = [(tf.clip_by_norm(gv[0], self.max_grad_norm), gv[1]) \n",
    "                                      for gv in grads_and_vars if gv[0] is not None] # clip_by_norm doesn't like None\n",
    "            \n",
    "            with tf.name_scope(\"Summaries\"):\n",
    "                grad_summaries = []\n",
    "                for g, v in grads_and_vars:\n",
    "                    if g is not None:\n",
    "                        grad_hist_summary = tf.histogram_summary(\"{}/grad/hist\".format(v.name), g)\n",
    "                        sparsity_summary = tf.scalar_summary(\"{}/grad/sparsity\".format(v.name), tf.nn.zero_fraction(g))\n",
    "        \n",
    "                        grad_summaries.append(grad_hist_summary)\n",
    "                        grad_summaries.append(sparsity_summary)\n",
    "                self._grad_summaries = tf.merge_summary(grad_summaries)\n",
    "            self._train_op = self._optimizer.apply_gradients(clipped_grads_and_vars, global_step=self._global_step)\n",
    "            \n",
    "    def _build_class_train_graph(self):\n",
    "        with tf.name_scope(\"Classification_Trainer\"):\n",
    "            self._class_global_step = tf.Variable(0, name=\"class_global_step\", trainable=False)\n",
    "#             self._lr = tf.Variable(1.0, trainable=False)\n",
    "            self._class_optimizer = tf.train.AdagradOptimizer(1.0)\n",
    "            \n",
    "            # clip and apply gradients\n",
    "            grads_and_vars = self._class_optimizer.compute_gradients(self._class_loss)\n",
    "#             for gv in grads_and_vars:\n",
    "#                 print(gv, gv[1] is self._cost)\n",
    "            clipped_grads_and_vars = [(tf.clip_by_norm(gv[0], self.max_grad_norm), gv[1]) \n",
    "                                      for gv in grads_and_vars if gv[0] is not None] # clip_by_norm doesn't like None\n",
    "#             clipped_grads_and_vars = [(tf.clip_by_value(gv[0], -1., 1.), gv[1]) \n",
    "#                                       for gv in grads_and_vars if gv[0] is not None] # clip_by_norm doesn't like None\n",
    "            \n",
    "            \n",
    "            with tf.name_scope(\"Summaries\"):\n",
    "                grad_summaries = []\n",
    "                for g, v in grads_and_vars:\n",
    "                    if g is not None:\n",
    "                        grad_hist_summary = tf.histogram_summary(\"class_{}/grad/hist\".format(v.name), g)\n",
    "                        sparsity_summary = tf.scalar_summary(\"class_{}/grad/sparsity\".format(v.name), tf.nn.zero_fraction(g))\n",
    "                        grad_summaries.append(grad_hist_summary)\n",
    "                        grad_summaries.append(sparsity_summary)\n",
    "                self._class_grad_summaries = tf.merge_summary(grad_summaries)\n",
    "            self._class_train_op = self._class_optimizer.apply_gradients(clipped_grads_and_vars, \n",
    "                                                                         global_step=self._class_global_step)\n",
    "            \n",
    "    def _build_similarity_graph(self):\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "        with tf.name_scope(\"Inputs\"):\n",
    "            # word or phrase we want similarities for\n",
    "#             self._query_word = tf.placeholder(tf.int32, [1], name=\"q_word\")\n",
    "            self._query_phrase = tf.placeholder(tf.int32, [self.max_num_steps, 2], name=\"q_phrase\")\n",
    "            self._query_length = tf.placeholder(tf.int32, [1], name=\"q_len\") # lengths for RNN\n",
    "            # words and phrases to compute similarities over\n",
    "#             self._sim_words = tf.placeholder(tf.int32, [None, 1])\n",
    "            self._sim_phrases = tf.placeholder(tf.int32, [None, self.max_num_steps, 2])\n",
    "            self._sim_lengths = tf.placeholder(tf.int32, [None, 1]) # lengths for RNN\n",
    "            sim_size = tf.shape(self._sim_lengths)[0]\n",
    "        \n",
    "        with tf.name_scope(\"Embeddings\"):\n",
    "            query_phrase_embed = tf.nn.embedding_lookup(self._word_embeddings, \n",
    "                                                  tf.slice(self._query_phrase, [0,0], [-1, 1]))\n",
    "            query_dep_embed = tf.nn.embedding_lookup(self._dependency_embeddings,\n",
    "                                                tf.slice(self._query_phrase, [0,1], [-1, 1]))\n",
    "#             query_word_embed = tf.nn.embedding_lookup(self._word_embeddings, self._query_word)\n",
    "#             query_phrase_embed = tf.nn.embedding_lookup(self._word_embeddings, self._query_phrase)\n",
    "#             sim_word_embed = tf.nn.embedding_lookup(self._word_embeddings, tf.squeeze(self._sim_words, [1]))\n",
    "            sim_phrase_embed = tf.nn.embedding_lookup(self._word_embeddings, \n",
    "                                                  tf.slice(self._sim_phrases, [0, 0, 0], [-1, -1, 1]))\n",
    "            sim_dep_embed = tf.nn.embedding_lookup(self._dependency_embeddings, \n",
    "                                                  tf.slice(self._sim_phrases, [0, 0, 1], [-1, -1, 1]))\n",
    "        \n",
    "        with tf.name_scope(\"RNN\"):\n",
    "            # compute rep of a query phrase\n",
    "            query_phrase = [tf.squeeze(qw, [1]) for qw in tf.split(0, self.max_num_steps, query_phrase_embed)]\n",
    "            query_dep = [tf.squeeze(qd, [1]) for qd in tf.split(0, self.max_num_steps, query_dep_embed)]\n",
    "#             print(query_phrase[0].get_shape(), query_dep[0].get_shape())\n",
    "            query_input = [ tf.concat(1, [qw, qd]) for (qw, qd) in zip(query_phrase, query_dep)]\n",
    "#             _, query_phrase_state = tf.nn.rnn(self.cell, query_input, \n",
    "#                                               sequence_length=self._query_length, \n",
    "#                                               dtype=tf.float32)\n",
    "            outs = tf.nn.bidirectional_rnn(self.fwcell, self.bwcell, query_input, \n",
    "                                        sequence_length=tf.to_int64(self._query_length),\n",
    "                                        dtype=tf.float32)\n",
    "            # splice out the final forward and backward hidden states since apparently the documentation lies\n",
    "            fw_state = tf.split(1, 2, outs[-1])[0]\n",
    "            bw_state = tf.split(1, 2, outs[0])[1]\n",
    "            query_phrase_state = tf.concat(1, [fw_state, bw_state])\n",
    "            # compute reps of similarity phrases\n",
    "            sim_phrases = [tf.squeeze(qw, [1,2]) for qw in tf.split(1, self.max_num_steps, sim_phrase_embed)]\n",
    "            sim_deps = [tf.squeeze(qd, [1,2]) for qd in tf.split(1, self.max_num_steps, sim_dep_embed)]\n",
    "            sim_input = [ tf.concat(1, [qw, qd]) for (qw, qd) in zip(sim_phrases, sim_deps)]\n",
    "#             _, sim_phrase_states = tf.nn.rnn(self.cell, sim_input, \n",
    "#                                              sequence_length=tf.squeeze(self._sim_lengths, [1]), \n",
    "#                                              dtype=tf.float32)\n",
    "            outs = tf.nn.bidirectional_rnn(self.fwcell, self.bwcell, sim_input, \n",
    "                                        sequence_length=tf.to_int64(tf.squeeze(self._sim_lengths, [1])),\n",
    "                                        dtype=tf.float32)\n",
    "            # splice out the final forward and backward hidden states since apparently the documentation lies\n",
    "            fw_state = tf.split(1, 2, outs[-1])[0]\n",
    "            bw_state = tf.split(1, 2, outs[0])[1]\n",
    "            sim_phrase_states = tf.concat(1, [fw_state, bw_state])\n",
    "            \n",
    "        with tf.name_scope(\"Similarities\"):\n",
    "            with tf.name_scope(\"Normalize\"):\n",
    "#                 print(query_phrase.get_shape())\n",
    "                query_phrase = tf.nn.l2_normalize(query_phrase_state, 1)\n",
    "#                 query_word = tf.nn.l2_normalize(query_word_embed, 1)\n",
    "                sim_phrases = tf.nn.l2_normalize(sim_phrase_states, 1)\n",
    "#                 sim_word = tf.nn.l2_normalize(sim_word_embed, 1)                \n",
    "\n",
    "            with tf.name_scope(\"Calc_distances\"):\n",
    "                # do for words\n",
    "#                 print(q)\n",
    "#                 query_word_nearby_dist = tf.matmul(query_word, sim_word, transpose_b=True)\n",
    "#                 qw_nearby_val, qw_nearby_idx = tf.nn.top_k(query_word_nearby_dist, min(1000, self.vocab_size))\n",
    "#                 self.qw_nearby_val = tf.squeeze(qw_nearby_val)\n",
    "#                 self.qw_nearby_idx = tf.squeeze(qw_nearby_idx)\n",
    "#                 self.qw_nearby_words = tf.squeeze(tf.gather(self._sim_words, qw_nearby_idx))\n",
    "\n",
    "                # do for phrases\n",
    "                query_phrase_nearby_dist = tf.matmul(query_phrase, sim_phrases, transpose_b=True)\n",
    "                qp_nearby_val, qp_nearby_idx = tf.nn.top_k(query_phrase_nearby_dist, min(1000, sim_size))\n",
    "#                 self.sanity_check = tf.squeeze(tf.matmul(query_phrase, query_phrase, transpose_b=True))\n",
    "                self.qp_nearby_val = tf.squeeze(qp_nearby_val)\n",
    "                self.qp_nearby_idx = tf.squeeze(qp_nearby_idx)\n",
    "#                 self.qp_nearby_lens = tf.squeeze(tf.gather(self._sim_lengths, qp_nearby_idx))\n",
    "            \n",
    "    def partial_class_fit(self, input_phrases, input_targets, class_labels, input_lengths, keep_prob=.5):\n",
    "        \"\"\"Fit a mini-batch\n",
    "        \n",
    "        Expects a batch_x: [self.batch_size, self.max_num_steps]\n",
    "                  batch_y: the same\n",
    "                  batch_seq_lens: [self.batch_size]\n",
    "                  \n",
    "        Returns average batch perplexity\n",
    "        \"\"\"\n",
    "        # create the label mask array... much easier in numpy than in tf\n",
    "        class_labels_mask = np.zeros([len(class_labels), num_classes], dtype=np.bool)\n",
    "        for i in range(len(class_labels_mask)):\n",
    "            class_labels_mask[i, class_labels[i]] = True\n",
    "            \n",
    "        loss, _, g_summaries, c_summary, p_summary = self.session.run([self._class_loss, self._class_train_op, \n",
    "                                                            self._class_grad_summaries,\n",
    "                                                            self._train_class_loss_summary,\n",
    "                                                            self._class_penalty_summary],\n",
    "                                                           {self._input_phrases:input_phrases,\n",
    "                                                            self._input_targets:input_targets,\n",
    "                                                            self._class_labels:class_labels,\n",
    "                                                            self._class_labels_mask:class_labels_mask,\n",
    "                                                            self._input_lengths:input_lengths,\n",
    "                                                            self._keep_prob:keep_prob})\n",
    "        self.summary_writer.add_summary(g_summaries)\n",
    "        self.summary_writer.add_summary(c_summary)        \n",
    "        self.summary_writer.add_summary(p_summary)\n",
    "        return loss\n",
    "    \n",
    "    def partial_unsup_fit(self, input_phrases, input_targets, input_labels, input_lengths, keep_prob=.5):\n",
    "        \"\"\"Fit a mini-batch\n",
    "        \n",
    "        Expects a batch_x: [self.batch_size, self.max_num_steps]\n",
    "                  batch_y: the same\n",
    "                  batch_seq_lens: [self.batch_size]\n",
    "                  \n",
    "        Returns average batch perplexity\n",
    "        \"\"\"\n",
    "        loss, _, g_summaries, c_summary, p_summary = self.session.run([self._loss, self._train_op, \n",
    "                                                            self._grad_summaries,\n",
    "                                                            self._train_cost_summary,\n",
    "                                                            self._penalty_summary],\n",
    "                                                           {self._input_phrases:input_phrases,\n",
    "                                                            self._input_targets:input_targets,\n",
    "                                                            self._input_labels:input_labels,\n",
    "                                                            self._input_lengths:input_lengths,\n",
    "                                                            self._keep_prob:keep_prob})\n",
    "        self.summary_writer.add_summary(g_summaries)\n",
    "        self.summary_writer.add_summary(c_summary)\n",
    "        self.summary_writer.add_summary(p_summary)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def validation_loss(self, valid_phrases, valid_targets, valid_labels, valid_lengths, keep_prob=1.0):\n",
    "        \"\"\"Calculate loss on validation inputs, but don't run trainer\"\"\"\n",
    "        loss, v_summary = self.session.run([self._loss, self._valid_cost_summary],\n",
    "                                           {self._input_phrases:valid_phrases,\n",
    "                                            self._input_targets:valid_targets,\n",
    "                                            self._input_labels:valid_labels,\n",
    "                                            self._input_lengths:valid_lengths,\n",
    "                                            self._keep_prob:keep_prob})\n",
    "        self.summary_writer.add_summary(v_summary)\n",
    "        return loss\n",
    "    \n",
    "    def validation_class_loss(self, valid_phrases, valid_targets, valid_labels, valid_lengths, keep_prob=1.0):\n",
    "        \"\"\"Calculate loss on validation inputs, but don't run trainer\"\"\"\n",
    "        # create the label mask array... much easier in numpy than in tf\n",
    "        valid_labels_mask = np.zeros([len(valid_labels), num_classes], dtype=np.bool)\n",
    "        for i in range(len(valid_labels_mask)):\n",
    "            valid_labels_mask[i, valid_labels[i]] = True\n",
    "        loss, v_summary = self.session.run([self._class_loss, self._valid_class_loss_summary],\n",
    "                                           {self._input_phrases:valid_phrases,\n",
    "                                            self._input_targets:valid_targets,\n",
    "                                            self._class_labels:valid_labels,\n",
    "                                            self._class_labels_mask:valid_labels_mask,\n",
    "                                            self._input_lengths:valid_lengths,\n",
    "                                            self._keep_prob:keep_prob})\n",
    "        self.summary_writer.add_summary(v_summary)\n",
    "        return loss\n",
    "    \n",
    "    def validation_phrase_nearby(self, q_phrase, q_phrase_len, sim_phrases, sim_phrase_lens, keep_prob=1.0):\n",
    "        \"\"\"Return nearby phrases from the similarity set\n",
    "        \"\"\"\n",
    "        nearby_vals, nearby_idx = self.session.run([self.qp_nearby_val, self.qp_nearby_idx],\n",
    "                                                                   {self._query_phrase:q_phrase, \n",
    "                                                                    self._query_length:q_phrase_len,\n",
    "                                                                    self._sim_phrases:sim_phrases,\n",
    "                                                                    self._sim_lengths:sim_phrase_lens,\n",
    "                                                                    self._keep_prob:keep_prob})\n",
    "#         print(\"Sanity check: %r\" % sanity)\n",
    "        return nearby_vals, nearby_idx\n",
    "    \n",
    "    def embed_phrases_and_targets(self, phrases, targets, lengths, keep_prob=1.0):\n",
    "        phrase_reps, target_reps = self.session.run([self._final_state, self._target_embeds],\n",
    "                                                    { self._input_phrases:phrases,\n",
    "                                                      self._input_targets:targets,\n",
    "                                                      self._input_lengths:lengths,\n",
    "                                                      self._keep_prob:keep_prob})\n",
    "        return phrase_reps, target_reps\n",
    "    \n",
    "#     def validation_word_nearby(self, q_word, sim_words):\n",
    "#         \"\"\"Return nearby phrases from the similarity set\n",
    "#         \"\"\"\n",
    "#         nearby_vals, nearby_idx = self.session.run([self.qw_nearby_val, \n",
    "#                                                       self.qw_nearby_idx],\n",
    "#                                                        {self._query_word:q_word, \n",
    "#                                                         self._sim_words:sim_words})\n",
    "#         return nearby_vals, nearby_idx\n",
    "        \n",
    "    def predict(self, paths, targets, path_lens, keep_prob=1.0):\n",
    "        predictions = self.session.run([self._predictions],\n",
    "                                      {self._input_phrases:paths,\n",
    "                                       self._input_targets:targets,\n",
    "                                       self._input_lengths:path_lens,\n",
    "                                       self._keep_prob:keep_prob})\n",
    "        return predictions[0] # predictions comes back as a 2darray with one row\n",
    "            \n",
    "    def checkpoint(self):\n",
    "        save_name = (self.checkpoint_prefix + '.ckpt-'+str(self._global_step.eval())+'-'+str(self._class_global_step.eval()))\n",
    "        print(\"Saving model to file: %s\" %  save_name)\n",
    "        self.saver.save(self.session, save_name)\n",
    "        return save_name\n",
    "        \n",
    "    def restore(self, model_ckpt_path):\n",
    "        self.saver.restore(self.session, model_ckpt_path)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return (\"<DPNN: W:%i, D:%i, H:%i, V:%i>\" \n",
    "                % (self.word_embed_size, self.dep_embed_size, self.hidden_size, self.vocab_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Data objects...\n",
      "Done creating Data objects\n",
      "7999 total examples :: 7199 training : 800 valid (90:10 split)\n",
      "Vocab size: 22683 Dep size: 50\n"
     ]
    }
   ],
   "source": [
    "# reload(dh)\n",
    "DH = dh.DataHandler('data/semeval_train_sdp_8000', valid_percent=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Didn't find common ancestor\n",
      "1790\t\"The imams were removed from a US Airways <e1>flight</e1> awaiting departure from the Minneapolis-St. Paul <e2>airport</e2>.\"\n",
      "\n",
      "(The imams were removed from a US Airways flight awaiting departure from the Minneapolis - St . Paul airport ., flight , airport )\n",
      "Bad sentence: '1790\\t\"The imams were removed from a US Airways <e1>flight</e1> awaiting departure from the Minneapolis-St. Paul <e2>airport</e2>.\"\\r\\n'\n",
      "((The imams were removed from a US Airways flight awaiting departure from the Minneapolis - St . Paul airport ., flight , airport ), None)\n",
      "Skipping this one... '1790\\t\"The imams were removed from a US Airways <e1>flight</e1> awaiting departure from the Minneapolis-St. Paul <e2>airport</e2>.\"\\r\\n'\n",
      "(None, None, None, 4)\n",
      "Num training: 7108\n",
      "Num valididation: 891\n",
      "Didn't find common ancestor\n",
      "8310\t\"Tributes have been paid to the <e1>writer</e1> who created Goodness Gracious Me, the hit BBC television <e2>series</e2>.\"\n",
      "\n",
      "(Tributes have been paid to the writer who created Goodness Gracious Me , the hit BBC television series ., writer , series )\n",
      "Bad sentence: '8310\\t\"Tributes have been paid to the <e1>writer</e1> who created Goodness Gracious Me, the hit BBC television <e2>series</e2>.\"\\r\\n'\n",
      "((Tributes have been paid to the writer who created Goodness Gracious Me , the hit BBC television series ., writer , series ), None)\n",
      "Skipping this one... '8000\\t\"The <e1>surgeon</e1> cuts a small <e2>hole</e2> in the skull and lifts the edge of the brain to expose the nerve.\"\\r\\n'\n",
      "(None, None, None, 3)\n",
      "Num testing: 2717\n"
     ]
    }
   ],
   "source": [
    "# reload(sdh)\n",
    "train, valid, test, label2int, int2label = sdh.load_semeval_data()\n",
    "# _, _ , test, label2int, int2label = sdh.load_semeval_data()\n",
    "num_classes = len(int2label.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert the semeval data to indices under the wiki vocab:\n",
    "train['sdps'] = DH.sentences_to_sequences(train['sdps'])\n",
    "valid['sdps'] = DH.sentences_to_sequences(valid['sdps'])\n",
    "test['sdps'] = DH.sentences_to_sequences(test['sdps'])\n",
    "    \n",
    "train['targets'] = DH.sentences_to_sequences(train['targets'])\n",
    "valid['targets'] = DH.sentences_to_sequences(valid['targets'])\n",
    "test['targets'] = DH.sentences_to_sequences(test['targets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 13\n"
     ]
    }
   ],
   "source": [
    "max_seq_len = max([len(path) for path in train['sdps']+valid['sdps']+test['sdps']])\n",
    "print(max_seq_len, DH.max_seq_len)\n",
    "DH.max_seq_len = max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19423 / 22683 pretrained\n"
     ]
    }
   ],
   "source": [
    "# the embedding matrix is started of as random uniform [-1,1]\n",
    "# then we replace everything but the OOV tokens with the approprate google vector\n",
    "fname = 'data/GoogleNews-vectors-negative300.bin'\n",
    "word2vec = Word2Vec.load_word2vec_format(fname, binary=True)\n",
    "\n",
    "word_embeddings = np.random.uniform(low=-1., high=1., size=[DH.vocab_size, 300]).astype(np.float32)\n",
    "num_found = 0\n",
    "for i, token in enumerate(DH.vocab):\n",
    "    if token in word2vec:\n",
    "        word_embeddings[i] = word2vec[token]\n",
    "        num_found += 1\n",
    "print(\"%i / %i pretrained\" % (num_found, DH.vocab_size))\n",
    "del word2vec # save a lot of RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create the embedding matrix from Omar Levy's dep embeddings instead\n",
    "%time\n",
    "word_embeddings = np.random.uniform(low=-1., high=1., size=[DH.vocab_size, 300]).astype(np.float32)\n",
    "num_found = 0\n",
    "vocab_set = set(DH.vocab)\n",
    "with open('data/deps.words', 'r') as levy:\n",
    "    for i, line in enumerate(levy):\n",
    "        split = line.split()\n",
    "        word = unicode(split[0], 'utf-8')\n",
    "        vec = np.array(split[1:]).astype(np.float32)\n",
    "        if word in vocab_set:\n",
    "            word_embeddings[DH._vocab2int[word]] = vec\n",
    "            num_found +=1\n",
    "print(\"%i / %i pretrained\" % (num_found, DH.vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"semeval_blank_rank_lambda_0.01_clip1/Forward/Classification/Classifier/Reshape_1\"\n",
      "op: \"Reshape\"\n",
      "input: \"semeval_blank_rank_lambda_0.01_clip1/Forward/Classification/Classifier/Squeeze_1\"\n",
      "input: \"semeval_blank_rank_lambda_0.01_clip1/Forward/Classification/Classifier/pack_1\"\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    type: DT_FLOAT\n",
      "  }\n",
      "}\n",
      "\n",
      "<DPNN: W:150, D:25, H:300, V:22683>\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'max_num_steps':DH.max_seq_len,\n",
    "    'word_embed_size':150,#300,\n",
    "#     'class_hidden_size':100,\n",
    "    'dep_embed_size':25,\n",
    "    'vocab_size':DH.vocab_size,\n",
    "    'dep_vocab_size':DH.dep_size,\n",
    "    'num_predict_classes':num_classes,\n",
    "    'pretrained_word_embeddings':None,#word_embeddings,\n",
    "    'max_grad_norm':1.,\n",
    "    'model_name':'semeval_blank_rank_lambda_0.01_clip1',\n",
    "    'checkpoints_to_keep':0,\n",
    "    'checkpoint_prefix':'checkpoints/',\n",
    "    'summary_prefix':'tensor_summaries/'\n",
    "}\n",
    "try:\n",
    "    tf.reset_default_graph()\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    tf.get_default_session().close()\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    del drnn\n",
    "except: \n",
    "    pass\n",
    "drnn = RelEmbed(config)\n",
    "print(drnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf tensor_summaries/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm checkpoints/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_validation_test(num_nearby=20):\n",
    "    valid_phrases, valid_targets , _, valid_lens = DH.validation_batch()\n",
    "    random_index = int(random.uniform(0, len(valid_lens)))\n",
    "    query_phrase = valid_phrases[random_index]\n",
    "    query_len = valid_lens[random_index]\n",
    "    query_target = valid_targets[random_index]\n",
    "    padded_qp = np.zeros([DH.max_seq_len, 2]).astype(np.int32)\n",
    "    padded_qp[:len(query_phrase), 0] = [x[0] for x in query_phrase]\n",
    "    padded_qp[:len(query_phrase), 1] = [x[1] for x in query_phrase]    \n",
    "    dists, phrase_idx = drnn.validation_phrase_nearby(padded_qp, query_len, valid_phrases, valid_lens)\n",
    "    print(\"=\"*80)\n",
    "    print(\"Top %i closest phrases to <%s> '%s' <%s>\" \n",
    "          % (num_nearby, DH.vocab_at(query_target[0]), \n",
    "             DH.sequence_to_sentence(query_phrase, query_len), \n",
    "             DH.vocab_at(query_target[1])))\n",
    "    for i in range(num_nearby):\n",
    "        dist = dists[i]\n",
    "        phrase = valid_phrases[phrase_idx[i]]\n",
    "        len_ = valid_lens[phrase_idx[i]]\n",
    "        target = valid_targets[phrase_idx[i]]\n",
    "        print(\"%i: %0.3f : <%s> '%s' <%s>\" \n",
    "              % (i, dist, DH.vocab_at(target[0]),\n",
    "                 DH.sequence_to_sentence(phrase, len_),\n",
    "                 DH.vocab_at(target[1])))\n",
    "    print(\"=\"*80)\n",
    "#     drnn.save_validation_accuracy(frac_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_left(num_epochs, num_steps, fit_time, nearby_time, start_time, nearby_mod):\n",
    "    total = num_epochs*num_steps*fit_time + ((num_epochs*num_steps)/float(nearby_mod))*nearby_time\n",
    "    return total - (time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "num_epochs = 10\n",
    "batch_size =50\n",
    "neg_per = 15\n",
    "neg_level = 1\n",
    "num_nearby = 30\n",
    "nearby_mod = 50\n",
    "sample_power = .75\n",
    "DH.scale_vocab_dist(sample_power)\n",
    "\n",
    "# bookkeeping\n",
    "num_steps = DH.num_steps(batch_size)\n",
    "total_step = 1\n",
    "save_interval = 30 * 60 # half hour in seconds\n",
    "save_time = time()\n",
    "\n",
    "#timing stuff\n",
    "start = time()\n",
    "fit_time = 0\n",
    "nearby_time = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    offset = 0 #if epoch else 400\n",
    "    DH.shuffle_data()\n",
    "    for step , batch in enumerate(DH.batches(batch_size, offset=offset, neg_per=neg_per)):\n",
    "        if not step: step = offset\n",
    "        t0 = time()\n",
    "        loss = drnn.partial_unsup_fit(*batch)\n",
    "        fit_time = (fit_time * float(total_step) +  time() - t0) / (total_step + 1) # running average\n",
    "        if step % 10 == 0:\n",
    "            m,s = divmod(time()-start, 60)\n",
    "            h,m = divmod(m, 60)\n",
    "            left = time_left(num_epochs, num_steps, fit_time, nearby_time, start, nearby_mod)\n",
    "            ml,sl = divmod(left, 60)\n",
    "            hl,ml = divmod(ml, 60)\n",
    "            pps = batch_size*(neg_per + 1) / fit_time \n",
    "            print(\"(%i:%i:%i) step %i/%i, epoch %i Training Loss = %1.5f :: %0.3f phrases/sec :: (%i:%i:%i) hours left\" \n",
    "                  % (h,m,s, step, num_steps, epoch, loss, pps, hl, ml, sl))\n",
    "        if (total_step-1) % nearby_mod == 0: # do one right away so we get a good timing estimate\n",
    "            t0 = time()\n",
    "            run_validation_test(num_nearby) # check out the nearby phrases in the validation set\n",
    "            valid_loss = drnn.validation_loss(*DH.validation_batch())\n",
    "            print(\"Validation loss: %0.4f\" % valid_loss)\n",
    "            nearby_time = (nearby_time * float(total_step) + time() - t0) / (total_step + 1) # running average\n",
    "\n",
    "        if (time() - save_time) > save_interval:\n",
    "            print(\"Saving model...\")\n",
    "            drnn.checkpoint()\n",
    "            save_time = time()\n",
    "        total_step +=1\n",
    "drnn.checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drnn.checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test the embeddings\n",
    "\n",
    "### VALID ###\n",
    "valid_phrases, valid_targets, _, valid_lens = DH.validation_batch()\n",
    "phrase_embeds, target_embeds = drnn.embed_phrases_and_targets(valid_phrases, valid_targets, valid_lens)\n",
    "phrase_labels, target_labels = DH.readable_data(valid=True)\n",
    "\n",
    "### TRAIN ###\n",
    "# train_phrases, train_targets, _, train_lens = DH.batches(500, neg_per=0, offset=0).next()\n",
    "# phrase_embeds, target_embeds = drnn.embed_phrases_and_targets(train_phrases, train_targets, train_lens)\n",
    "# phrase_labels, target_labels = DH.readable_data(show_dep=False, valid=False)\n",
    "        \n",
    "phrase_embeds /= np.sqrt(np.sum(phrase_embeds**2, 1, keepdims=True))\n",
    "target_embeds /= np.sqrt(np.sum(target_embeds**2, 1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ### JOINT ###\n",
    "# start = 0\n",
    "# stride = 40\n",
    "# end = start + stride\n",
    "\n",
    "# lowd = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)\n",
    "# # lowd = PCA(n_components=2)\n",
    "\n",
    "# joint_embeds = np.vstack([phrase_embeds[start:end], target_embeds[start:end]])\n",
    "# joint_2d = lowd.fit_transform(joint_embeds)\n",
    "# phrase_2d, target_2d = joint_2d[:stride], joint_2d[stride:]\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(20,16))\n",
    "# for i, label in enumerate(phrase_labels[start:end]):\n",
    "#     label = \"%i: %s\" % (i, label)\n",
    "#     x, y = phrase_2d[i,:]\n",
    "#     ax.scatter(x, y, color='b')\n",
    "#     ax.annotate(label, xy=(x, y), xytext=(5, 2), textcoords='offset points',\n",
    "#                    ha='right', va='bottom')\n",
    "# for i, label in enumerate(target_labels[start:end]):\n",
    "#     label = \"%i: %s\" % (i, label)\n",
    "#     x, y = target_2d[i,:]\n",
    "#     ax.scatter(x, y, color='r')\n",
    "#     ax.annotate(label, xy=(x, y), xytext=(5, 2), textcoords='offset points',\n",
    "#                    ha='right', va='bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### PHRASE ONLY ###\n",
    "start = 100\n",
    "stride = 50\n",
    "end = start + stride\n",
    "\n",
    "# lowd = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)\n",
    "lowd = PCA(n_components=2)\n",
    "\n",
    "phrase_2d = lowd.fit_transform(phrase_embeds[start:end])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,16))\n",
    "for i, label in enumerate(phrase_labels[start:end]):\n",
    "    label = \"%s\" % (label)\n",
    "    x, y = phrase_2d[i,:]\n",
    "    ax.scatter(x, y, color='b')\n",
    "    ax.annotate(label, xy=(x, y), xytext=(5, 2), textcoords='offset points',\n",
    "                   ha='right', va='bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### TARGET ONLY ###\n",
    "start = 0\n",
    "stride = 35\n",
    "end = start + stride\n",
    "\n",
    "# lowd = TSNE(perplexity=20, n_components=2, init='pca', n_iter=5000)\n",
    "lowd = PCA(n_components=2)\n",
    "\n",
    "target_2d = lowd.fit_transform(target_embeds[start:end])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,16))\n",
    "for i, label in enumerate(target_labels[start:end]):\n",
    "    label = \"%i: %s\" % (i, label)\n",
    "    x, y = target_2d[i,:]\n",
    "    ax.scatter(x, y, color='r')\n",
    "    ax.annotate(label, xy=(x, y), xytext=(5, 2), textcoords='offset points',\n",
    "                   ha='right', va='bottom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test out semeval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zip_train = zip(train['raws'], train['sents'], train['sdps'], train['targets'], train['labels'])\n",
    "zip_valid = zip(valid['raws'], valid['sents'], valid['sdps'], valid['targets'], valid['labels'])\n",
    "zip_test = zip(test['raws'], test['sents'], test['sdps'], test['targets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t\"The system as described above has its greatest application in an arrayed <e1>configuration</e1> of antenna <e2>elements</e2>.\"\r\n",
      "\n",
      "(<X>, pobj) (of, prep) (<Y>, pobj) :: configuration elements\n",
      "Component-Whole(e2,e1)\n",
      "================================================================================\n",
      "2\t\"The <e1>child</e1> was carefully wrapped and bound into the <e2>cradle</e2> by means of a cord.\"\r\n",
      "\n",
      "(<X>, nsubjpass) (wrapped, ROOT) (bound, conj) (into, prep) (<Y>, pobj) :: child cradle\n",
      "Other\n",
      "================================================================================\n",
      "3\t\"The <e1>author</e1> of a keygen uses a <e2>disassembler</e2> to look at the raw assembly code.\"\r\n",
      "\n",
      "(<X>, nsubj) (uses, ROOT) (<Y>, dobj) :: author disassembler\n",
      "Instrument-Agency(e2,e1)\n",
      "================================================================================\n",
      "4\t\"A misty <e1>ridge</e1> uprises from the <e2>surge</e2>.\"\r\n",
      "\n",
      "(<X>, nsubj) (uprises, ROOT) (from, prep) (<Y>, pobj) :: ridge surge\n",
      "Other\n",
      "================================================================================\n",
      "5\t\"The <e1>student</e1> <e2>association</e2> is the voice of the undergraduate student population of the State University of New York at Buffalo.\"\r\n",
      "\n",
      "(<X>, compound) (<Y>, nsubj) :: student association\n",
      "Member-Collection(e1,e2)\n",
      "================================================================================\n",
      "6\t\"This is the sprawling <e1>complex</e1> that is Peru's largest <e2>producer</e2> of silver.\"\r\n",
      "\n",
      "(<X>, attr) (is, relcl) (<Y>, attr) :: complex producer\n",
      "Other\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "for i, (raw, _, sdp, target, label) in enumerate(zip_train):\n",
    "    if i > 5:\n",
    "        break\n",
    "    print(raw)\n",
    "    print(\"%s :: %s\" % (DH.sequence_to_sentence(sdp, show_dep=True), DH.sequence_to_sentence(target)))\n",
    "    print(int2label[label])\n",
    "    print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def confusion_matrix(preds, labels, label_set):\n",
    "    size = len(label_set)\n",
    "    matrix = np.zeros([size, size]) # rows are predictions, columns are truths\n",
    "    # fill in matrix\n",
    "    for p, l in zip(preds, labels):\n",
    "        matrix[p,l] += 1\n",
    "    # compute class specific scores\n",
    "    class_precision = np.zeros(size)\n",
    "    class_recall = np.zeros(size)\n",
    "    for label in range(size):\n",
    "        tp = matrix[label, label]\n",
    "        fp = np.sum(matrix[label, :]) - tp\n",
    "        fn = np.sum(matrix[:, label]) - tp\n",
    "        class_precision[label] = tp/float(tp + fp) if tp or fp else 0\n",
    "        class_recall[label] = tp/float(tp + fn) if tp or fn else 0\n",
    "    micro_f1 = np.array([2*(p*r)/(p+r) if p or r else 0 for (p, r) in zip(class_precision, class_recall)])\n",
    "    avg_precision = np.mean(class_precision)\n",
    "    avg_recall = np.mean(class_recall)\n",
    "    macro_f1 = (2*avg_precision*avg_recall) / (avg_precision + avg_recall) if avg_precision and avg_recall else 0\n",
    "    stats = {'micro_precision':class_precision*100,\n",
    "             'micro_recall':class_recall*100, \n",
    "             'micro_f1':micro_f1*100,\n",
    "             'macro_precision':avg_precision*100, \n",
    "             'macro_recall':avg_recall*100,\n",
    "             'macro_f1':macro_f1*100}\n",
    "    return matrix, stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0:0:1) s 0/142, e 0 avg class xent loss = 39.0514\n",
      "================================================================================\n",
      "(0:0:7) s 0/142, e 0 validation avg class xent loss = 39.0468\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-1\n",
      "New best validation\n",
      "(0:0:18) s 10/142, e 0 avg class xent loss = 39.0172\n",
      "(0:0:25) s 20/142, e 0 avg class xent loss = 38.9992\n",
      "(0:0:32) s 30/142, e 0 avg class xent loss = 38.9904\n",
      "(0:0:39) s 40/142, e 0 avg class xent loss = 38.9854\n",
      "(0:0:46) s 50/142, e 0 avg class xent loss = 38.9831\n",
      "================================================================================\n",
      "(0:0:52) s 50/142, e 0 validation avg class xent loss = 38.9826\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-51\n",
      "New best validation\n",
      "(0:1:4) s 60/142, e 0 avg class xent loss = 38.9812\n",
      "(0:1:11) s 70/142, e 0 avg class xent loss = 38.9811\n",
      "(0:1:18) s 80/142, e 0 avg class xent loss = 38.9804\n",
      "(0:1:26) s 90/142, e 0 avg class xent loss = 38.9808\n",
      "(0:1:34) s 100/142, e 0 avg class xent loss = 38.9806\n",
      "================================================================================\n",
      "(0:1:40) s 100/142, e 0 validation avg class xent loss = 38.9820\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-101\n",
      "New best validation\n",
      "(0:1:51) s 110/142, e 0 avg class xent loss = 38.9821\n",
      "(0:1:58) s 120/142, e 0 avg class xent loss = 38.9902\n",
      "(0:2:5) s 130/142, e 0 avg class xent loss = 39.0125\n",
      "(0:2:12) s 140/142, e 0 avg class xent loss = 39.3183\n",
      "Macro F1: 2.2434\n",
      "(0:2:20) s 0/142, e 1 avg class xent loss = 37.4744\n",
      "================================================================================\n",
      "(0:2:26) s 0/142, e 1 validation avg class xent loss = 40.1047\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-143\n",
      "(0:2:36) s 10/142, e 1 avg class xent loss = 38.9251\n",
      "(0:2:43) s 20/142, e 1 avg class xent loss = 41.8152\n",
      "(0:2:50) s 30/142, e 1 avg class xent loss = 37.9147\n",
      "(0:2:57) s 40/142, e 1 avg class xent loss = 38.3323\n",
      "(0:3:4) s 50/142, e 1 avg class xent loss = 40.3148\n",
      "================================================================================\n",
      "(0:3:10) s 50/142, e 1 validation avg class xent loss = 40.7196\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-193\n",
      "(0:3:22) s 60/142, e 1 avg class xent loss = 43.6506\n",
      "(0:3:31) s 70/142, e 1 avg class xent loss = 40.4953\n",
      "(0:3:38) s 80/142, e 1 avg class xent loss = 43.1467\n",
      "(0:3:45) s 90/142, e 1 avg class xent loss = 40.4702\n",
      "(0:3:53) s 100/142, e 1 avg class xent loss = 42.7458\n",
      "================================================================================\n",
      "(0:3:59) s 100/142, e 1 validation avg class xent loss = 41.9118\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-243\n",
      "(0:4:10) s 110/142, e 1 avg class xent loss = 39.0168\n",
      "(0:4:17) s 120/142, e 1 avg class xent loss = 37.5983\n",
      "(0:4:24) s 130/142, e 1 avg class xent loss = 39.6046\n",
      "(0:4:31) s 140/142, e 1 avg class xent loss = 44.4650\n",
      "Macro F1: 4.1345\n",
      "(0:4:39) s 0/142, e 2 avg class xent loss = 42.9829\n",
      "================================================================================\n",
      "(0:4:45) s 0/142, e 2 validation avg class xent loss = 43.5576\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-285\n",
      "(0:4:55) s 10/142, e 2 avg class xent loss = 42.3204\n",
      "(0:5:2) s 20/142, e 2 avg class xent loss = 38.3632\n",
      "(0:5:9) s 30/142, e 2 avg class xent loss = 42.3165\n",
      "(0:5:16) s 40/142, e 2 avg class xent loss = 45.2148\n",
      "(0:5:23) s 50/142, e 2 avg class xent loss = 43.9106\n",
      "================================================================================\n",
      "(0:5:29) s 50/142, e 2 validation avg class xent loss = 44.3042\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-335\n",
      "(0:5:40) s 60/142, e 2 avg class xent loss = 47.2979\n",
      "(0:5:46) s 70/142, e 2 avg class xent loss = 50.3949\n",
      "(0:5:53) s 80/142, e 2 avg class xent loss = 40.1292\n",
      "(0:6:0) s 90/142, e 2 avg class xent loss = 35.2667\n",
      "(0:6:7) s 100/142, e 2 avg class xent loss = 44.0855\n",
      "================================================================================\n",
      "(0:6:13) s 100/142, e 2 validation avg class xent loss = 46.0346\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-385\n",
      "(0:6:24) s 110/142, e 2 avg class xent loss = 46.7071\n",
      "(0:6:31) s 120/142, e 2 avg class xent loss = 48.2015\n",
      "(0:6:37) s 130/142, e 2 avg class xent loss = 49.9756\n",
      "(0:6:44) s 140/142, e 2 avg class xent loss = 49.5811\n",
      "Macro F1: 3.5134\n",
      "(0:6:52) s 0/142, e 3 avg class xent loss = 45.4519\n",
      "================================================================================\n",
      "(0:6:58) s 0/142, e 3 validation avg class xent loss = 46.3947\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-427\n",
      "(0:7:8) s 10/142, e 3 avg class xent loss = 45.6990\n",
      "(0:7:15) s 20/142, e 3 avg class xent loss = 41.5432\n",
      "(0:7:22) s 30/142, e 3 avg class xent loss = 46.3398\n",
      "(0:7:29) s 40/142, e 3 avg class xent loss = 46.3732\n",
      "(0:7:36) s 50/142, e 3 avg class xent loss = 51.8110\n",
      "================================================================================\n",
      "(0:7:43) s 50/142, e 3 validation avg class xent loss = 46.3393\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-477\n",
      "(0:7:54) s 60/142, e 3 avg class xent loss = 44.2141\n",
      "(0:8:0) s 70/142, e 3 avg class xent loss = 49.8820\n",
      "(0:8:7) s 80/142, e 3 avg class xent loss = 56.6119\n",
      "(0:8:14) s 90/142, e 3 avg class xent loss = 47.9871\n",
      "(0:8:21) s 100/142, e 3 avg class xent loss = 47.3175\n",
      "================================================================================\n",
      "(0:8:28) s 100/142, e 3 validation avg class xent loss = 48.1293\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-527\n",
      "(0:8:38) s 110/142, e 3 avg class xent loss = 46.5900\n",
      "(0:8:45) s 120/142, e 3 avg class xent loss = 48.8715\n",
      "(0:8:52) s 130/142, e 3 avg class xent loss = 46.3631\n",
      "(0:8:59) s 140/142, e 3 avg class xent loss = 47.8608\n",
      "Macro F1: 3.3726\n",
      "(0:9:7) s 0/142, e 4 avg class xent loss = 57.1932\n",
      "================================================================================\n",
      "(0:9:13) s 0/142, e 4 validation avg class xent loss = 47.5871\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-569\n",
      "(0:9:24) s 10/142, e 4 avg class xent loss = 54.4126\n",
      "(0:9:31) s 20/142, e 4 avg class xent loss = 57.2621\n",
      "(0:9:38) s 30/142, e 4 avg class xent loss = 47.6088\n",
      "(0:9:45) s 40/142, e 4 avg class xent loss = 48.5521\n",
      "(0:9:52) s 50/142, e 4 avg class xent loss = 51.8979\n",
      "================================================================================\n",
      "(0:9:58) s 50/142, e 4 validation avg class xent loss = 49.8869\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-619\n",
      "(0:10:9) s 60/142, e 4 avg class xent loss = 50.2432\n",
      "(0:10:16) s 70/142, e 4 avg class xent loss = 56.1168\n",
      "(0:10:22) s 80/142, e 4 avg class xent loss = 50.5867\n",
      "(0:10:29) s 90/142, e 4 avg class xent loss = 46.6266\n",
      "(0:10:37) s 100/142, e 4 avg class xent loss = 55.2680\n",
      "================================================================================\n",
      "(0:10:43) s 100/142, e 4 validation avg class xent loss = 48.1622\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-669\n",
      "(0:10:54) s 110/142, e 4 avg class xent loss = 52.4097\n",
      "(0:11:0) s 120/142, e 4 avg class xent loss = 57.4151\n",
      "(0:11:7) s 130/142, e 4 avg class xent loss = 50.0799\n",
      "(0:11:14) s 140/142, e 4 avg class xent loss = 47.6757\n",
      "Macro F1: 4.9900\n",
      "(0:11:22) s 0/142, e 5 avg class xent loss = 52.8926\n",
      "================================================================================\n",
      "(0:11:28) s 0/142, e 5 validation avg class xent loss = 48.3813\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-711\n",
      "(0:11:39) s 10/142, e 5 avg class xent loss = 47.0733\n",
      "(0:11:46) s 20/142, e 5 avg class xent loss = 51.7894\n",
      "(0:11:53) s 30/142, e 5 avg class xent loss = 57.7264\n",
      "(0:12:0) s 40/142, e 5 avg class xent loss = 43.5610\n",
      "(0:12:7) s 50/142, e 5 avg class xent loss = 47.4621\n",
      "================================================================================\n",
      "(0:12:13) s 50/142, e 5 validation avg class xent loss = 48.5487\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-761\n",
      "(0:12:24) s 60/142, e 5 avg class xent loss = 51.0691\n",
      "(0:12:31) s 70/142, e 5 avg class xent loss = 53.2131\n",
      "(0:12:38) s 80/142, e 5 avg class xent loss = 53.0358\n",
      "(0:12:45) s 90/142, e 5 avg class xent loss = 51.1145\n",
      "(0:12:52) s 100/142, e 5 avg class xent loss = 51.8817\n",
      "================================================================================\n",
      "(0:12:58) s 100/142, e 5 validation avg class xent loss = 49.6319\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-811\n",
      "(0:13:9) s 110/142, e 5 avg class xent loss = 66.1307\n",
      "(0:13:16) s 120/142, e 5 avg class xent loss = 55.0364\n",
      "(0:13:23) s 130/142, e 5 avg class xent loss = 57.9621\n",
      "(0:13:30) s 140/142, e 5 avg class xent loss = 52.9240\n",
      "Macro F1: 3.9499\n",
      "(0:13:38) s 0/142, e 6 avg class xent loss = 55.5250\n",
      "================================================================================\n",
      "(0:13:44) s 0/142, e 6 validation avg class xent loss = 49.2021\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-853\n",
      "(0:13:55) s 10/142, e 6 avg class xent loss = 62.0331\n",
      "(0:14:2) s 20/142, e 6 avg class xent loss = 50.6494\n",
      "(0:14:9) s 30/142, e 6 avg class xent loss = 52.0641\n",
      "(0:14:15) s 40/142, e 6 avg class xent loss = 52.8140\n",
      "(0:14:22) s 50/142, e 6 avg class xent loss = 57.4071\n",
      "================================================================================\n",
      "(0:14:29) s 50/142, e 6 validation avg class xent loss = 50.3652\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-903\n",
      "(0:14:40) s 60/142, e 6 avg class xent loss = 54.2053\n",
      "(0:14:47) s 70/142, e 6 avg class xent loss = 56.5192\n",
      "(0:14:54) s 80/142, e 6 avg class xent loss = 54.3999\n",
      "(0:15:1) s 90/142, e 6 avg class xent loss = 53.3353\n",
      "(0:15:8) s 100/142, e 6 avg class xent loss = 55.1072\n",
      "================================================================================\n",
      "(0:15:14) s 100/142, e 6 validation avg class xent loss = 50.4954\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-953\n",
      "(0:15:25) s 110/142, e 6 avg class xent loss = 50.7309\n",
      "(0:15:32) s 120/142, e 6 avg class xent loss = 43.4503\n",
      "(0:15:39) s 130/142, e 6 avg class xent loss = 50.6910\n",
      "(0:15:46) s 140/142, e 6 avg class xent loss = 64.9152\n",
      "Macro F1: 4.0994\n",
      "(0:15:54) s 0/142, e 7 avg class xent loss = 60.0806\n",
      "================================================================================\n",
      "(0:16:0) s 0/142, e 7 validation avg class xent loss = 50.4958\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-995\n",
      "(0:16:11) s 10/142, e 7 avg class xent loss = 64.4134\n",
      "(0:16:18) s 20/142, e 7 avg class xent loss = 52.2131\n",
      "(0:16:25) s 30/142, e 7 avg class xent loss = 55.5323\n",
      "(0:16:32) s 40/142, e 7 avg class xent loss = 52.0609\n",
      "(0:16:39) s 50/142, e 7 avg class xent loss = 66.8140\n",
      "================================================================================\n",
      "(0:16:45) s 50/142, e 7 validation avg class xent loss = 50.9022\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-1045\n",
      "(0:16:56) s 60/142, e 7 avg class xent loss = 51.4790\n",
      "(0:17:3) s 70/142, e 7 avg class xent loss = 62.8015\n",
      "(0:17:10) s 80/142, e 7 avg class xent loss = 54.6080\n",
      "(0:17:17) s 90/142, e 7 avg class xent loss = 51.8173\n",
      "(0:17:24) s 100/142, e 7 avg class xent loss = 56.4300\n",
      "================================================================================\n",
      "(0:17:30) s 100/142, e 7 validation avg class xent loss = 51.5651\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-1095\n",
      "(0:17:41) s 110/142, e 7 avg class xent loss = 45.6477\n",
      "(0:17:48) s 120/142, e 7 avg class xent loss = 56.5794\n",
      "(0:17:55) s 130/142, e 7 avg class xent loss = 53.6906\n",
      "(0:18:2) s 140/142, e 7 avg class xent loss = 73.2206\n",
      "Macro F1: 4.8260\n",
      "(0:18:10) s 0/142, e 8 avg class xent loss = 58.5060\n",
      "================================================================================\n",
      "(0:18:17) s 0/142, e 8 validation avg class xent loss = 51.0568\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-1137\n",
      "(0:18:27) s 10/142, e 8 avg class xent loss = 51.0704\n",
      "(0:18:34) s 20/142, e 8 avg class xent loss = 52.6454\n",
      "(0:18:41) s 30/142, e 8 avg class xent loss = 59.9763\n",
      "(0:18:48) s 40/142, e 8 avg class xent loss = 66.0577\n",
      "(0:18:55) s 50/142, e 8 avg class xent loss = 53.4634\n",
      "================================================================================\n",
      "(0:19:2) s 50/142, e 8 validation avg class xent loss = 51.6753\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-1187\n",
      "(0:19:13) s 60/142, e 8 avg class xent loss = 51.0588\n",
      "(0:19:20) s 70/142, e 8 avg class xent loss = 50.6399\n",
      "(0:19:27) s 80/142, e 8 avg class xent loss = 59.7863\n",
      "(0:19:33) s 90/142, e 8 avg class xent loss = 50.5021\n",
      "(0:19:40) s 100/142, e 8 avg class xent loss = 59.4356\n",
      "================================================================================\n",
      "(0:19:47) s 100/142, e 8 validation avg class xent loss = 50.1252\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-1237\n",
      "(0:19:58) s 110/142, e 8 avg class xent loss = 61.1191\n",
      "(0:20:5) s 120/142, e 8 avg class xent loss = 52.9615\n",
      "(0:20:12) s 130/142, e 8 avg class xent loss = 53.7919\n",
      "(0:20:19) s 140/142, e 8 avg class xent loss = 59.1034\n",
      "Macro F1: 6.5960\n",
      "(0:20:27) s 0/142, e 9 avg class xent loss = 67.2961\n",
      "================================================================================\n",
      "(0:20:33) s 0/142, e 9 validation avg class xent loss = 49.1725\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-1279\n",
      "(0:20:43) s 10/142, e 9 avg class xent loss = 52.0642\n",
      "(0:20:50) s 20/142, e 9 avg class xent loss = 47.6813\n",
      "(0:20:57) s 30/142, e 9 avg class xent loss = 53.7975\n",
      "(0:21:4) s 40/142, e 9 avg class xent loss = 56.2018\n",
      "(0:21:11) s 50/142, e 9 avg class xent loss = 49.5618\n",
      "================================================================================\n",
      "(0:21:18) s 50/142, e 9 validation avg class xent loss = 50.0005\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-1329\n",
      "(0:21:29) s 60/142, e 9 avg class xent loss = 61.0022\n",
      "(0:21:35) s 70/142, e 9 avg class xent loss = 57.4140\n",
      "(0:21:42) s 80/142, e 9 avg class xent loss = 57.2037\n",
      "(0:21:49) s 90/142, e 9 avg class xent loss = 58.4710\n",
      "(0:21:56) s 100/142, e 9 avg class xent loss = 55.9480\n",
      "================================================================================\n",
      "(0:22:3) s 100/142, e 9 validation avg class xent loss = 49.3821\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-1379\n",
      "(0:22:14) s 110/142, e 9 avg class xent loss = 56.4416\n",
      "(0:22:21) s 120/142, e 9 avg class xent loss = 48.2122\n",
      "(0:22:28) s 130/142, e 9 avg class xent loss = 57.6197\n",
      "(0:22:35) s 140/142, e 9 avg class xent loss = 50.2106\n",
      "Macro F1: 4.1417\n",
      "(0:22:43) s 0/142, e 10 avg class xent loss = 51.5318\n",
      "================================================================================\n",
      "(0:22:49) s 0/142, e 10 validation avg class xent loss = 50.2152\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-1421\n",
      "(0:22:59) s 10/142, e 10 avg class xent loss = 60.4130\n",
      "(0:23:6) s 20/142, e 10 avg class xent loss = 46.7075\n",
      "(0:23:13) s 30/142, e 10 avg class xent loss = 59.3532\n",
      "(0:23:20) s 40/142, e 10 avg class xent loss = 48.8493\n",
      "(0:23:27) s 50/142, e 10 avg class xent loss = 62.5756\n",
      "================================================================================\n",
      "(0:23:34) s 50/142, e 10 validation avg class xent loss = 51.0948\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-1471\n",
      "(0:23:44) s 60/142, e 10 avg class xent loss = 56.9719\n",
      "(0:23:51) s 70/142, e 10 avg class xent loss = 63.6766\n",
      "(0:23:58) s 80/142, e 10 avg class xent loss = 54.4017\n",
      "(0:24:5) s 90/142, e 10 avg class xent loss = 54.5706\n",
      "(0:24:12) s 100/142, e 10 avg class xent loss = 54.4464\n",
      "================================================================================\n",
      "(0:24:19) s 100/142, e 10 validation avg class xent loss = 51.5837\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-1521\n",
      "(0:24:30) s 110/142, e 10 avg class xent loss = 63.1586\n",
      "(0:24:37) s 120/142, e 10 avg class xent loss = 52.3014\n",
      "(0:24:44) s 130/142, e 10 avg class xent loss = 60.7190\n",
      "(0:24:51) s 140/142, e 10 avg class xent loss = 47.1613\n",
      "Macro F1: 4.6391\n",
      "(0:24:59) s 0/142, e 11 avg class xent loss = 60.1247\n",
      "================================================================================\n",
      "(0:25:5) s 0/142, e 11 validation avg class xent loss = 52.4132\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-1563\n",
      "(0:25:16) s 10/142, e 11 avg class xent loss = 60.7783\n",
      "(0:25:23) s 20/142, e 11 avg class xent loss = 57.7981\n",
      "(0:25:29) s 30/142, e 11 avg class xent loss = 52.8896\n",
      "(0:25:36) s 40/142, e 11 avg class xent loss = 52.9613\n",
      "(0:25:43) s 50/142, e 11 avg class xent loss = 52.3625\n",
      "================================================================================\n",
      "(0:25:50) s 50/142, e 11 validation avg class xent loss = 51.6178\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-1613\n",
      "(0:26:0) s 60/142, e 11 avg class xent loss = 61.0848\n",
      "(0:26:7) s 70/142, e 11 avg class xent loss = 61.7126\n",
      "(0:26:14) s 80/142, e 11 avg class xent loss = 60.4331\n",
      "(0:26:21) s 90/142, e 11 avg class xent loss = 57.4619\n",
      "(0:26:28) s 100/142, e 11 avg class xent loss = 54.6225\n",
      "================================================================================\n",
      "(0:26:35) s 100/142, e 11 validation avg class xent loss = 51.1297\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-1663\n",
      "(0:26:45) s 110/142, e 11 avg class xent loss = 70.1261\n",
      "(0:26:52) s 120/142, e 11 avg class xent loss = 65.0566\n",
      "(0:26:59) s 130/142, e 11 avg class xent loss = 63.6496\n",
      "(0:27:6) s 140/142, e 11 avg class xent loss = 59.7230\n",
      "Macro F1: 3.7664\n",
      "(0:27:14) s 0/142, e 12 avg class xent loss = 52.3389\n",
      "================================================================================\n",
      "(0:27:21) s 0/142, e 12 validation avg class xent loss = 52.2545\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-1705\n",
      "(0:27:31) s 10/142, e 12 avg class xent loss = 55.7356\n",
      "(0:27:38) s 20/142, e 12 avg class xent loss = 47.9704\n",
      "(0:27:45) s 30/142, e 12 avg class xent loss = 56.1494\n",
      "(0:27:52) s 40/142, e 12 avg class xent loss = 62.8407\n",
      "(0:27:59) s 50/142, e 12 avg class xent loss = 58.7307\n",
      "================================================================================\n",
      "(0:28:5) s 50/142, e 12 validation avg class xent loss = 52.0894\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-1755\n",
      "(0:28:16) s 60/142, e 12 avg class xent loss = 54.7226\n",
      "(0:28:23) s 70/142, e 12 avg class xent loss = 51.5922\n",
      "(0:28:30) s 80/142, e 12 avg class xent loss = 60.3874\n",
      "(0:28:37) s 90/142, e 12 avg class xent loss = 52.9544\n",
      "(0:28:44) s 100/142, e 12 avg class xent loss = 55.5120\n",
      "================================================================================\n",
      "(0:28:50) s 100/142, e 12 validation avg class xent loss = 51.0184\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-1805\n",
      "(0:29:1) s 110/142, e 12 avg class xent loss = 69.4139\n",
      "(0:29:8) s 120/142, e 12 avg class xent loss = 69.9062\n",
      "(0:29:15) s 130/142, e 12 avg class xent loss = 44.8936\n",
      "(0:29:22) s 140/142, e 12 avg class xent loss = 58.9335\n",
      "Macro F1: 4.6638\n",
      "(0:29:30) s 0/142, e 13 avg class xent loss = 68.6484\n",
      "================================================================================\n",
      "(0:29:37) s 0/142, e 13 validation avg class xent loss = 51.6501\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-1847\n",
      "(0:29:47) s 10/142, e 13 avg class xent loss = 53.6736\n",
      "(0:29:54) s 20/142, e 13 avg class xent loss = 62.6213\n",
      "(0:30:1) s 30/142, e 13 avg class xent loss = 51.4174\n",
      "(0:30:8) s 40/142, e 13 avg class xent loss = 72.1116\n",
      "(0:30:15) s 50/142, e 13 avg class xent loss = 57.3702\n",
      "================================================================================\n",
      "(0:30:22) s 50/142, e 13 validation avg class xent loss = 51.6618\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-1897\n",
      "(0:30:32) s 60/142, e 13 avg class xent loss = 57.1465\n",
      "(0:30:39) s 70/142, e 13 avg class xent loss = 53.0680\n",
      "(0:30:46) s 80/142, e 13 avg class xent loss = 47.7114\n",
      "(0:30:53) s 90/142, e 13 avg class xent loss = 60.6302\n",
      "(0:31:0) s 100/142, e 13 avg class xent loss = 64.5198\n",
      "================================================================================\n",
      "(0:31:6) s 100/142, e 13 validation avg class xent loss = 51.3407\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-1947\n",
      "(0:31:17) s 110/142, e 13 avg class xent loss = 63.7204\n",
      "(0:31:24) s 120/142, e 13 avg class xent loss = 60.9508\n",
      "(0:31:31) s 130/142, e 13 avg class xent loss = 55.8427\n",
      "(0:31:38) s 140/142, e 13 avg class xent loss = 61.5128\n",
      "Macro F1: 5.7937\n",
      "(0:31:46) s 0/142, e 14 avg class xent loss = 56.3685\n",
      "================================================================================\n",
      "(0:31:52) s 0/142, e 14 validation avg class xent loss = 52.3894\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-1989\n",
      "(0:32:2) s 10/142, e 14 avg class xent loss = 53.6440\n",
      "(0:32:9) s 20/142, e 14 avg class xent loss = 59.8439\n",
      "(0:32:16) s 30/142, e 14 avg class xent loss = 69.2703\n",
      "(0:32:23) s 40/142, e 14 avg class xent loss = 62.9196\n",
      "(0:32:30) s 50/142, e 14 avg class xent loss = 60.6741\n",
      "================================================================================\n",
      "(0:32:37) s 50/142, e 14 validation avg class xent loss = 53.1508\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-2039\n",
      "(0:32:48) s 60/142, e 14 avg class xent loss = 67.5594\n",
      "(0:32:55) s 70/142, e 14 avg class xent loss = 66.4227\n",
      "(0:33:2) s 80/142, e 14 avg class xent loss = 61.6803\n",
      "(0:33:8) s 90/142, e 14 avg class xent loss = 65.7393\n",
      "(0:33:15) s 100/142, e 14 avg class xent loss = 52.7518\n",
      "================================================================================\n",
      "(0:33:22) s 100/142, e 14 validation avg class xent loss = 50.2916\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-2089\n",
      "(0:33:33) s 110/142, e 14 avg class xent loss = 52.4779\n",
      "(0:33:39) s 120/142, e 14 avg class xent loss = 60.3289\n",
      "(0:33:46) s 130/142, e 14 avg class xent loss = 60.8481\n",
      "(0:33:53) s 140/142, e 14 avg class xent loss = 55.2228\n",
      "Macro F1: 5.3419\n",
      "(0:34:1) s 0/142, e 15 avg class xent loss = 60.9175\n",
      "================================================================================\n",
      "(0:34:8) s 0/142, e 15 validation avg class xent loss = 50.0687\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-2131\n",
      "(0:34:18) s 10/142, e 15 avg class xent loss = 68.9268\n",
      "(0:34:25) s 20/142, e 15 avg class xent loss = 58.1836\n",
      "(0:34:32) s 30/142, e 15 avg class xent loss = 54.3123\n",
      "(0:34:39) s 40/142, e 15 avg class xent loss = 53.3347\n",
      "(0:34:46) s 50/142, e 15 avg class xent loss = 57.6006\n",
      "================================================================================\n",
      "(0:34:53) s 50/142, e 15 validation avg class xent loss = 49.8542\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-2181\n",
      "(0:35:3) s 60/142, e 15 avg class xent loss = 52.9064\n",
      "(0:35:10) s 70/142, e 15 avg class xent loss = 62.6497\n",
      "(0:35:17) s 80/142, e 15 avg class xent loss = 56.4874\n",
      "(0:35:24) s 90/142, e 15 avg class xent loss = 61.2986\n",
      "(0:35:31) s 100/142, e 15 avg class xent loss = 66.4667\n",
      "================================================================================\n",
      "(0:35:37) s 100/142, e 15 validation avg class xent loss = 49.9750\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-2231\n",
      "(0:35:49) s 110/142, e 15 avg class xent loss = 57.7774\n",
      "(0:35:55) s 120/142, e 15 avg class xent loss = 59.0599\n",
      "(0:36:2) s 130/142, e 15 avg class xent loss = 63.8181\n",
      "(0:36:9) s 140/142, e 15 avg class xent loss = 67.2048\n",
      "Macro F1: 4.0670\n",
      "(0:36:17) s 0/142, e 16 avg class xent loss = 58.2373\n",
      "================================================================================\n",
      "(0:36:24) s 0/142, e 16 validation avg class xent loss = 50.1224\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-2273\n",
      "(0:36:34) s 10/142, e 16 avg class xent loss = 59.5366\n",
      "(0:36:41) s 20/142, e 16 avg class xent loss = 61.0622\n",
      "(0:36:48) s 30/142, e 16 avg class xent loss = 51.3028\n",
      "(0:36:55) s 40/142, e 16 avg class xent loss = 58.8825\n",
      "(0:37:2) s 50/142, e 16 avg class xent loss = 55.8095\n",
      "================================================================================\n",
      "(0:37:9) s 50/142, e 16 validation avg class xent loss = 50.1916\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-2323\n",
      "(0:37:20) s 60/142, e 16 avg class xent loss = 69.7837\n",
      "(0:37:26) s 70/142, e 16 avg class xent loss = 60.0033\n",
      "(0:37:33) s 80/142, e 16 avg class xent loss = 64.0209\n",
      "(0:37:40) s 90/142, e 16 avg class xent loss = 59.5944\n",
      "(0:37:47) s 100/142, e 16 avg class xent loss = 64.8564\n",
      "================================================================================\n",
      "(0:37:54) s 100/142, e 16 validation avg class xent loss = 50.1952\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-2373\n",
      "(0:38:5) s 110/142, e 16 avg class xent loss = 66.4748\n",
      "(0:38:12) s 120/142, e 16 avg class xent loss = 52.6248\n",
      "(0:38:18) s 130/142, e 16 avg class xent loss = 58.0574\n",
      "(0:38:25) s 140/142, e 16 avg class xent loss = 54.5058\n",
      "Macro F1: 4.6725\n",
      "(0:38:33) s 0/142, e 17 avg class xent loss = 62.0334\n",
      "================================================================================\n",
      "(0:38:40) s 0/142, e 17 validation avg class xent loss = 50.0567\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-2415\n",
      "(0:38:50) s 10/142, e 17 avg class xent loss = 50.7960\n",
      "(0:38:57) s 20/142, e 17 avg class xent loss = 63.7810\n",
      "(0:39:4) s 30/142, e 17 avg class xent loss = 56.1500\n",
      "(0:39:11) s 40/142, e 17 avg class xent loss = 71.4766\n",
      "(0:39:18) s 50/142, e 17 avg class xent loss = 59.2305\n",
      "================================================================================\n",
      "(0:39:24) s 50/142, e 17 validation avg class xent loss = 50.1222\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-2465\n",
      "(0:39:35) s 60/142, e 17 avg class xent loss = 61.6017\n",
      "(0:39:42) s 70/142, e 17 avg class xent loss = 62.7744\n",
      "(0:39:49) s 80/142, e 17 avg class xent loss = 55.7339\n",
      "(0:39:56) s 90/142, e 17 avg class xent loss = 56.6813\n",
      "(0:40:3) s 100/142, e 17 avg class xent loss = 53.3880\n",
      "================================================================================\n",
      "(0:40:10) s 100/142, e 17 validation avg class xent loss = 49.3809\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-2515\n",
      "(0:40:20) s 110/142, e 17 avg class xent loss = 64.5768\n",
      "(0:40:27) s 120/142, e 17 avg class xent loss = 67.6015\n",
      "(0:40:34) s 130/142, e 17 avg class xent loss = 48.8330\n",
      "(0:40:41) s 140/142, e 17 avg class xent loss = 50.3540\n",
      "Macro F1: 4.1015\n",
      "(0:40:49) s 0/142, e 18 avg class xent loss = 55.1487\n",
      "================================================================================\n",
      "(0:40:56) s 0/142, e 18 validation avg class xent loss = 51.2644\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-2557\n",
      "(0:41:6) s 10/142, e 18 avg class xent loss = 58.4915\n",
      "(0:41:13) s 20/142, e 18 avg class xent loss = 53.6535\n",
      "(0:41:20) s 30/142, e 18 avg class xent loss = 63.0165\n",
      "(0:41:27) s 40/142, e 18 avg class xent loss = 53.7071\n",
      "(0:41:33) s 50/142, e 18 avg class xent loss = 51.7797\n",
      "================================================================================\n",
      "(0:41:40) s 50/142, e 18 validation avg class xent loss = 51.6716\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-2607\n",
      "(0:41:51) s 60/142, e 18 avg class xent loss = 55.8746\n",
      "(0:41:58) s 70/142, e 18 avg class xent loss = 54.2085\n",
      "(0:42:5) s 80/142, e 18 avg class xent loss = 51.7037\n",
      "(0:42:12) s 90/142, e 18 avg class xent loss = 46.5603\n",
      "(0:42:19) s 100/142, e 18 avg class xent loss = 61.4976\n",
      "================================================================================\n",
      "(0:42:25) s 100/142, e 18 validation avg class xent loss = 50.4022\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-2657\n",
      "(0:42:36) s 110/142, e 18 avg class xent loss = 55.8942\n",
      "(0:42:42) s 120/142, e 18 avg class xent loss = 57.0748\n",
      "(0:42:49) s 130/142, e 18 avg class xent loss = 69.3953\n",
      "(0:42:56) s 140/142, e 18 avg class xent loss = 54.8788\n",
      "Macro F1: 3.8784\n",
      "(0:43:5) s 0/142, e 19 avg class xent loss = 65.8761\n",
      "================================================================================\n",
      "(0:43:11) s 0/142, e 19 validation avg class xent loss = 48.3614\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-2699\n",
      "(0:43:22) s 10/142, e 19 avg class xent loss = 63.4934\n",
      "(0:43:29) s 20/142, e 19 avg class xent loss = 49.8220\n",
      "(0:43:36) s 30/142, e 19 avg class xent loss = 63.8616\n",
      "(0:43:43) s 40/142, e 19 avg class xent loss = 49.6750\n",
      "(0:43:49) s 50/142, e 19 avg class xent loss = 58.1953\n",
      "================================================================================\n",
      "(0:43:56) s 50/142, e 19 validation avg class xent loss = 50.6104\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-2749\n",
      "(0:44:7) s 60/142, e 19 avg class xent loss = 66.1955\n",
      "(0:44:14) s 70/142, e 19 avg class xent loss = 57.5826\n",
      "(0:44:21) s 80/142, e 19 avg class xent loss = 57.0197\n",
      "(0:44:27) s 90/142, e 19 avg class xent loss = 67.7420\n",
      "(0:44:34) s 100/142, e 19 avg class xent loss = 58.6660\n",
      "================================================================================\n",
      "(0:44:41) s 100/142, e 19 validation avg class xent loss = 49.7479\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-2799\n",
      "(0:44:51) s 110/142, e 19 avg class xent loss = 52.2655\n",
      "(0:44:58) s 120/142, e 19 avg class xent loss = 54.7513\n",
      "(0:45:5) s 130/142, e 19 avg class xent loss = 54.0693\n",
      "(0:45:12) s 140/142, e 19 avg class xent loss = 67.9291\n",
      "Macro F1: 2.1658\n",
      "================================================================================\n",
      "(0:45:26) s 141/142, e 19 validation avg class xent loss = 50.8202\n",
      "================================================================================\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-2840\n",
      "best model was checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-0-101\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "num_steps = len(train['labels']) // batch_size\n",
    "num_epochs = 20\n",
    "display_mod = 10\n",
    "valid_mod = 50\n",
    "best_valid = 10e6\n",
    "early_stop_model = None\n",
    "start = time()\n",
    "for epoch in range(num_epochs):\n",
    "    random.shuffle(zip_train) # shuffling should only happen once per epoch\n",
    "    _, _, sdps, targets, labels = zip(*zip_train)\n",
    "    for step in range(num_steps): # num_steps\n",
    "        class_batch = DH.classification_batch(batch_size, sdps, targets, labels, \n",
    "                                              offset=step, shuffle=False)\n",
    "        xent = drnn.partial_class_fit(*class_batch)\n",
    "        if step % display_mod == 0:   \n",
    "            m,s = divmod(time()-start, 60)\n",
    "            h,m = divmod(m, 60)\n",
    "            print(\"(%i:%i:%i) s %i/%i, e %i avg class xent loss = %0.4f\" % (h,m,s, step, num_steps, epoch, xent))\n",
    "        if step % valid_mod == 0:\n",
    "            valid_batch = DH.classification_batch(len(valid['labels']), valid['sdps'], valid['targets'], valid['labels'])\n",
    "            valid_xent = drnn.validation_class_loss(*valid_batch)\n",
    "            m,s = divmod(time()-start, 60)\n",
    "            h,m = divmod(m, 60)\n",
    "            print(\"=\"*80)\n",
    "            print(\"(%i:%i:%i) s %i/%i, e %i validation avg class xent loss = %0.4f\" % (h,m,s, step, num_steps, epoch, valid_xent))\n",
    "            print(\"=\"*80)\n",
    "            model_file = drnn.checkpoint()\n",
    "            if valid_xent < best_valid:\n",
    "                print(\"New best validation\")\n",
    "                best_valid = valid_xent\n",
    "                early_stop_model = model_file\n",
    "    valid_batch = DH.classification_batch(len(valid['labels']), valid['sdps'], valid['targets'], valid['labels'])\n",
    "    label_set = set(train['labels'])\n",
    "    preds = drnn.predict(valid_batch[0], valid_batch[1], valid_batch[3])\n",
    "    cm, stats = confusion_matrix(preds, valid['labels'], label_set)\n",
    "    print(\"Macro F1: %2.4f\" % stats['macro_f1'])\n",
    "# do a final validation\n",
    "valid_batch = DH.classification_batch(len(valid['labels']), valid['sdps'], valid['targets'], valid['labels'])\n",
    "valid_xent = drnn.validation_class_loss(*valid_batch)\n",
    "m,s = divmod(time()-start, 60)\n",
    "h,m = divmod(m, 60)\n",
    "print(\"=\"*80)\n",
    "print(\"(%i:%i:%i) s %i/%i, e %i validation avg class xent loss = %0.4f\" % (h,m,s, step, num_steps, epoch, valid_xent))\n",
    "print(\"=\"*80)\n",
    "\n",
    "\n",
    "model_file = drnn.checkpoint()\n",
    "if valid_xent < best_valid:\n",
    "    best_valid = valid_xent\n",
    "    early_stop_model = model_file\n",
    "\n",
    "# now take the best of all\n",
    "print(\"best model was %s\" % early_stop_model)\n",
    "# drnn.restore(early_stop_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1: 2.8424\n",
      "18 0\n"
     ]
    }
   ],
   "source": [
    "# check out predictions\n",
    "# valid_batch = DH.classification_batch(len(train['labels']), train['sdps'], train['targets'], train['labels'])\n",
    "# drnn.restore('checkpoints/semeval_w2v_bi.ckpt-0-2130')\n",
    "\n",
    "valid_batch = DH.classification_batch(len(valid['labels']), valid['sdps'], valid['targets'], valid['labels'], shuffle=False)\n",
    "preds = drnn.predict(valid_batch[0], valid_batch[1], valid_batch[3])\n",
    "\n",
    "label_set = set(train['labels'])\n",
    "cm, stats = confusion_matrix(preds, valid['labels'], label_set)\n",
    "print(\"Macro F1: %2.4f\" % stats['macro_f1'])\n",
    "print(np.max(preds), np.min(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for i, p in enumerate(preds):\n",
    "#     print(p)\n",
    "#     print(\"%i, pred: %s, true: %s\" %(i, int2label[p], int2label[valid['labels'][i]]))\n",
    "#     target = DH.sequence_to_sentence(valid['targets'][i]).split(' ')\n",
    "#     sdp = DH.sequence_to_sentence(valid['sdps'][i], show_dep=True)\n",
    "#     print('<%s> \"%s\" <%s>' % (target[0], sdp, target[1]))\n",
    "#     print(valid['raws'][i])\n",
    "#     print(valid['comments'][i])\n",
    "#     print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 891)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds), len(valid['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_name = '' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter save name: (last was '') \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABa8AAAUgCAYAAABHG6udAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHSevzczMzMzMzMzMzKzf+X8T0+lINzwVLgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f7cc910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_confusion_matrix(cm, label_names, save_name=None, title='Normed Confusion matrix', cmap=plt.cm.Blues, stats=None):\n",
    "    fig, ax = plt.subplots(figsize=(20,20))\n",
    "    \n",
    "    # calc normalized cm\n",
    "    x, y = np.meshgrid(range(cm.shape[0]), range(cm.shape[1]))\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "    cm_normalized[np.isnan(cm_normalized)] = 0.0\n",
    "    cm_max = np.max(cm_normalized)\n",
    "    cm_min = np.min(cm_normalized)\n",
    "    half_way = (cm_max - cm_min)/2.\n",
    "    # print nonzero raw counts\n",
    "    for x_val, y_val in zip(x.flatten(), y.flatten()):\n",
    "        norm = cm_normalized[x_val, y_val]\n",
    "        c = \"%i\" % (cm.astype('int')[x_val, y_val])\n",
    "        if norm > 0.0:\n",
    "            color = 'white' if norm > half_way else 'black'\n",
    "            ax.text(y_val, x_val, c, va='center', ha='center', color=color, fontsize=14)\n",
    "    \n",
    "    # actual plot\n",
    "    im = ax.imshow(cm_normalized, interpolation='nearest', origin='upper', cmap=cmap)\n",
    "#     divider = plt.make_axes_locatable(ax)\n",
    "#     cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "    \n",
    "    # set ticks and offset grid\n",
    "    tick_marks = np.arange(len(label_names))\n",
    "    tick_marks_offset = np.arange(len(label_names)) - .5\n",
    "    ax.set_xticks(tick_marks, minor=False)\n",
    "    ax.set_yticks(tick_marks, minor=False)\n",
    "    ax.set_xticks(tick_marks_offset, minor=True)\n",
    "    ax.set_yticks(tick_marks_offset, minor=True)\n",
    "    ax.grid(which='minor')\n",
    "    if stats:\n",
    "        # include micro precisio, recall, and f1\n",
    "        aug_y_labels = []\n",
    "        for i in range(len(label_names)):\n",
    "            aug = (\"%s\\nP:%2.2f, R:%2.2f, F1:%2.2f\" \n",
    "                   % (label_names[i],\n",
    "                      stats['micro_precision'][i],\n",
    "                      stats['micro_recall'][i],\n",
    "                      stats['micro_f1'][i],))\n",
    "            aug_y_labels.append(aug)\n",
    "    else:\n",
    "        aug_x_labels = label_names\n",
    "    ax.set_xticklabels(label_names, rotation=45, horizontalalignment='left', x=1, fontsize=16)\n",
    "    ax.xaxis.tick_top()\n",
    "    ax.set_yticklabels(aug_y_labels, fontsize=16)\n",
    "    \n",
    "    # other stuff\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Predicted Labels', fontsize=18)\n",
    "    if stats:\n",
    "        # include macro \n",
    "        aug_x_label = (\"True Labels\\n Macro P:%2.2f, R:%2.2f, F1:%2.2f\" \n",
    "                       % (stats['macro_precision'], stats['macro_recall'], stats['macro_f1']))\n",
    "    else:\n",
    "        aug_x_label = \"True Label\"\n",
    "    plt.xlabel(aug_x_label, fontsize=18)\n",
    "    plt.title(title, y=1.15, fontsize=20)\n",
    "    if save_name:\n",
    "        plt.savefig('figures/'+save_name+'.pdf')\n",
    "        \n",
    "\n",
    "save_name = raw_input(\"Enter save name: (last was '%s') \" % save_name)\n",
    "plot_confusion_matrix(cm, int2label.values(), save_name=save_name, stats=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write out predictions for test set\n",
    "test_batch = DH.classification_batch(len(test['targets']), test['sdps'], test['targets'], \n",
    "                                     np.zeros(len(test['targets'])), shuffle=False)\n",
    "preds = drnn.predict(test_batch[0], test_batch[1], test_batch[3])\n",
    "# print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('SemEval2010_task8_all_data/test_pred.txt', 'w') as f:\n",
    "    i = 8001\n",
    "    for pred in preds:\n",
    "        f.write(\"%i\\t%s\\n\" % (i, int2label[pred]))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # reformat test keys because apparently that's broken...\n",
    "# test_keys =  open(\"SemEval2010_task8_all_data/SemEval2010_task8_testing_keys/TEST_FILE_FULL.TXT\", 'r').readlines()\n",
    "# with open(\"SemEval2010_task8_all_data/test_keys.txt\", 'w') as out:\n",
    "#     for i in range(len(test_keys) //4):\n",
    "#         nu\n",
    "m = test_keys[4*i].split()[0]\n",
    "#         label = test_keys[4*i+1]\n",
    "#         out.write(\"%s\\t%s\" % (num, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write out the training and validation as well\n",
    "with open('SemEval2010_task8_all_data/train_preds.txt', 'w') as f:\n",
    "    i = 1\n",
    "    for label in preds:\n",
    "        f.write(\"%s\\t%s\\n\" % (i, int2label[label]))\n",
    "        i += 1\n",
    "with open('SemEval2010_task8_all_data/valid_preds.txt', 'w') as f:\n",
    "    i = 8000 - 891 + 1\n",
    "    for label in train['labels']:\n",
    "        f.write(\"%s\\t%s\\n\" % (i, int2label[label]))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< (2*9+1)-WAY EVALUATION (USING DIRECTIONALITY)>>>:\n",
      "\n",
      "Confusion matrix:\n",
      "        C-E1 C-E2 C-W1 C-W2 C-C1 C-C2 E-D1 E-D2 E-O1 E-O2 I-A1 I-A2 M-C1 M-C2 M-T1 M-T2 P-P1 P-P2  _O_ <-- classified as\n",
      "      +-----------------------------------------------------------------------------------------------+ -SUM- skip ACTUAL\n",
      " C-E1 | 303    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 |  303    0  303\n",
      " C-E2 |   0  544    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 |  544    0  544\n",
      " C-W1 |   0    0  436    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 |  436    0  436\n",
      " C-W2 |   0    0    0  434    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 |  434    0  434\n",
      " C-C1 |   0    0    0    0  356    0    0    0    0    0    0    0    0    0    0    0    0    0    0 |  356    0  356\n",
      " C-C2 |   0    0    0    0    0  127    0    0    0    0    0    0    0    0    0    0    0    0    0 |  127    0  127\n",
      " E-D1 |   0    0    0    0    0    0  831    0    0    0    0    0    0    0    0    0    0    0    0 |  831    0  831\n",
      " E-D2 |   0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0 |    1    0    1\n",
      " E-O1 |   0    0    0    0    0    0    0    0  496    0    0    0    0    0    0    0    0    0    0 |  496    0  496\n",
      " E-O2 |   0    0    0    0    0    0    0    0    0  117    0    0    0    0    0    0    0    0    0 |  117    0  117\n",
      " I-A1 |   0    0    0    0    0    0    0    0    0    0   76    0    0    0    0    0    0    0    0 |   76    0   76\n",
      " I-A2 |   0    0    0    0    0    0    0    0    0    0    0  343    0    0    0    0    0    0    0 |  343    0  343\n",
      " M-C1 |   0    0    0    0    0    0    0    0    0    0    0    0   75    0    0    0    0    0    0 |   75    0   75\n",
      " M-C2 |   0    0    0    0    0    0    0    0    0    0    0    0    0  607    0    0    0    0    0 |  607    0  607\n",
      " M-T1 |   0    0    0    0    0    0    0    0    0    0    0    0    0    0  486    0    0    0    0 |  486    0  486\n",
      " M-T2 |   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  143    0    0    0 |  143    0  143\n",
      " P-P1 |   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  277    0    0 |  277    0  277\n",
      " P-P2 |   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  326    0 |  326    0  326\n",
      "  _O_ |   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 1130 | 1130    0 1130\n",
      "      +-----------------------------------------------------------------------------------------------+\n",
      " -SUM-  303  544  436  434  356  127  831    1  496  117   76  343   75  607  486  143  277  326 1130   7108    0 7108\n",
      "\n",
      "Coverage = 7108/7108 = 100.00%\n",
      "Accuracy (calculated for the above confusion matrix) = 7108/7108 = 100.00%\n",
      "Accuracy (considering all skipped examples as Wrong) = 7108/7108 = 100.00%\n",
      "Accuracy (considering all skipped examples as Other) = 7108/7108 = 100.00%\n",
      "\n",
      "Results for the individual relations:\n",
      "      Cause-Effect(e1,e2) :    P =  303/ 303 = 100.00%     R =  303/ 303 = 100.00%     F1 = 100.00%\n",
      "      Cause-Effect(e2,e1) :    P =  544/ 544 = 100.00%     R =  544/ 544 = 100.00%     F1 = 100.00%\n",
      "   Component-Whole(e1,e2) :    P =  436/ 436 = 100.00%     R =  436/ 436 = 100.00%     F1 = 100.00%\n",
      "   Component-Whole(e2,e1) :    P =  434/ 434 = 100.00%     R =  434/ 434 = 100.00%     F1 = 100.00%\n",
      " Content-Container(e1,e2) :    P =  356/ 356 = 100.00%     R =  356/ 356 = 100.00%     F1 = 100.00%\n",
      " Content-Container(e2,e1) :    P =  127/ 127 = 100.00%     R =  127/ 127 = 100.00%     F1 = 100.00%\n",
      "Entity-Destination(e1,e2) :    P =  831/ 831 = 100.00%     R =  831/ 831 = 100.00%     F1 = 100.00%\n",
      "Entity-Destination(e2,e1) :    P =    1/   1 = 100.00%     R =    1/   1 = 100.00%     F1 = 100.00%\n",
      "     Entity-Origin(e1,e2) :    P =  496/ 496 = 100.00%     R =  496/ 496 = 100.00%     F1 = 100.00%\n",
      "     Entity-Origin(e2,e1) :    P =  117/ 117 = 100.00%     R =  117/ 117 = 100.00%     F1 = 100.00%\n",
      " Instrument-Agency(e1,e2) :    P =   76/  76 = 100.00%     R =   76/  76 = 100.00%     F1 = 100.00%\n",
      " Instrument-Agency(e2,e1) :    P =  343/ 343 = 100.00%     R =  343/ 343 = 100.00%     F1 = 100.00%\n",
      " Member-Collection(e1,e2) :    P =   75/  75 = 100.00%     R =   75/  75 = 100.00%     F1 = 100.00%\n",
      " Member-Collection(e2,e1) :    P =  607/ 607 = 100.00%     R =  607/ 607 = 100.00%     F1 = 100.00%\n",
      "     Message-Topic(e1,e2) :    P =  486/ 486 = 100.00%     R =  486/ 486 = 100.00%     F1 = 100.00%\n",
      "     Message-Topic(e2,e1) :    P =  143/ 143 = 100.00%     R =  143/ 143 = 100.00%     F1 = 100.00%\n",
      "  Product-Producer(e1,e2) :    P =  277/ 277 = 100.00%     R =  277/ 277 = 100.00%     F1 = 100.00%\n",
      "  Product-Producer(e2,e1) :    P =  326/ 326 = 100.00%     R =  326/ 326 = 100.00%     F1 = 100.00%\n",
      "                   _Other :    P = 1130/1130 = 100.00%     R = 1130/1130 = 100.00%     F1 = 100.00%\n",
      "\n",
      "Micro-averaged result (excluding Other):\n",
      "P = 5978/5978 = 100.00%     R = 5978/5978 = 100.00%     F1 = 100.00%\n",
      "\n",
      "MACRO-averaged result (excluding Other):\n",
      "P = 100.00%\tR = 100.00%\tF1 = 100.00%\n",
      "\n",
      "\n",
      "\n",
      "<<< (9+1)-WAY EVALUATION IGNORING DIRECTIONALITY >>>:\n",
      "\n",
      "Confusion matrix:\n",
      "         C-E  C-W  C-C  E-D  E-O  I-A  M-C  M-T  P-P  _O_ <-- classified as\n",
      "      +--------------------------------------------------+ -SUM- skip ACTUAL\n",
      "  C-E | 847    0    0    0    0    0    0    0    0    0 |  847    0  847\n",
      "  C-W |   0  870    0    0    0    0    0    0    0    0 |  870    0  870\n",
      "  C-C |   0    0  483    0    0    0    0    0    0    0 |  483    0  483\n",
      "  E-D |   0    0    0  832    0    0    0    0    0    0 |  832    0  832\n",
      "  E-O |   0    0    0    0  613    0    0    0    0    0 |  613    0  613\n",
      "  I-A |   0    0    0    0    0  419    0    0    0    0 |  419    0  419\n",
      "  M-C |   0    0    0    0    0    0  682    0    0    0 |  682    0  682\n",
      "  M-T |   0    0    0    0    0    0    0  629    0    0 |  629    0  629\n",
      "  P-P |   0    0    0    0    0    0    0    0  603    0 |  603    0  603\n",
      "  _O_ |   0    0    0    0    0    0    0    0    0 1130 | 1130    0 1130\n",
      "      +--------------------------------------------------+\n",
      " -SUM-  847  870  483  832  613  419  682  629  603 1130   7108    0 7108\n",
      "\n",
      "Coverage = 7108/7108 = 100.00%\n",
      "Accuracy (calculated for the above confusion matrix) = 7108/7108 = 100.00%\n",
      "Accuracy (considering all skipped examples as Wrong) = 7108/7108 = 100.00%\n",
      "Accuracy (considering all skipped examples as Other) = 7108/7108 = 100.00%\n",
      "\n",
      "Results for the individual relations:\n",
      "             Cause-Effect :    P =  847/ 847 = 100.00%     R =  847/ 847 = 100.00%     F1 = 100.00%\n",
      "          Component-Whole :    P =  870/ 870 = 100.00%     R =  870/ 870 = 100.00%     F1 = 100.00%\n",
      "        Content-Container :    P =  483/ 483 = 100.00%     R =  483/ 483 = 100.00%     F1 = 100.00%\n",
      "       Entity-Destination :    P =  832/ 832 = 100.00%     R =  832/ 832 = 100.00%     F1 = 100.00%\n",
      "            Entity-Origin :    P =  613/ 613 = 100.00%     R =  613/ 613 = 100.00%     F1 = 100.00%\n",
      "        Instrument-Agency :    P =  419/ 419 = 100.00%     R =  419/ 419 = 100.00%     F1 = 100.00%\n",
      "        Member-Collection :    P =  682/ 682 = 100.00%     R =  682/ 682 = 100.00%     F1 = 100.00%\n",
      "            Message-Topic :    P =  629/ 629 = 100.00%     R =  629/ 629 = 100.00%     F1 = 100.00%\n",
      "         Product-Producer :    P =  603/ 603 = 100.00%     R =  603/ 603 = 100.00%     F1 = 100.00%\n",
      "                   _Other :    P = 1130/1130 = 100.00%     R = 1130/1130 = 100.00%     F1 = 100.00%\n",
      "\n",
      "Micro-averaged result (excluding Other):\n",
      "P = 5978/5978 = 100.00%     R = 5978/5978 = 100.00%     F1 = 100.00%\n",
      "\n",
      "MACRO-averaged result (excluding Other):\n",
      "P = 100.00%\tR = 100.00%\tF1 = 100.00%\n",
      "\n",
      "\n",
      "\n",
      "<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n",
      "\n",
      "Confusion matrix:\n",
      "         C-E  C-W  C-C  E-D  E-O  I-A  M-C  M-T  P-P  _O_ <-- classified as\n",
      "      +--------------------------------------------------+ -SUM- xDIRx skip  ACTUAL\n",
      "  C-E | 847    0    0    0    0    0    0    0    0    0 |  847     0     0    847\n",
      "  C-W |   0  870    0    0    0    0    0    0    0    0 |  870     0     0    870\n",
      "  C-C |   0    0  483    0    0    0    0    0    0    0 |  483     0     0    483\n",
      "  E-D |   0    0    0  832    0    0    0    0    0    0 |  832     0     0    832\n",
      "  E-O |   0    0    0    0  613    0    0    0    0    0 |  613     0     0    613\n",
      "  I-A |   0    0    0    0    0  419    0    0    0    0 |  419     0     0    419\n",
      "  M-C |   0    0    0    0    0    0  682    0    0    0 |  682     0     0    682\n",
      "  M-T |   0    0    0    0    0    0    0  629    0    0 |  629     0     0    629\n",
      "  P-P |   0    0    0    0    0    0    0    0  603    0 |  603     0     0    603\n",
      "  _O_ |   0    0    0    0    0    0    0    0    0 1130 | 1130     0     0   1130\n",
      "      +--------------------------------------------------+\n",
      " -SUM-  847  870  483  832  613  419  682  629  603 1130   7108     0     0   7108\n",
      "\n",
      "Coverage = 7108/7108 = 100.00%\n",
      "Accuracy (calculated for the above confusion matrix) = 7108/7108 = 100.00%\n",
      "Accuracy (considering all skipped examples as Wrong) = 7108/7108 = 100.00%\n",
      "Accuracy (considering all skipped examples as Other) = 7108/7108 = 100.00%\n",
      "\n",
      "Results for the individual relations:\n",
      "             Cause-Effect :    P =  847/( 847 +   0) = 100.00%     R =  847/ 847 = 100.00%     F1 = 100.00%\n",
      "          Component-Whole :    P =  870/( 870 +   0) = 100.00%     R =  870/ 870 = 100.00%     F1 = 100.00%\n",
      "        Content-Container :    P =  483/( 483 +   0) = 100.00%     R =  483/ 483 = 100.00%     F1 = 100.00%\n",
      "       Entity-Destination :    P =  832/( 832 +   0) = 100.00%     R =  832/ 832 = 100.00%     F1 = 100.00%\n",
      "            Entity-Origin :    P =  613/( 613 +   0) = 100.00%     R =  613/ 613 = 100.00%     F1 = 100.00%\n",
      "        Instrument-Agency :    P =  419/( 419 +   0) = 100.00%     R =  419/ 419 = 100.00%     F1 = 100.00%\n",
      "        Member-Collection :    P =  682/( 682 +   0) = 100.00%     R =  682/ 682 = 100.00%     F1 = 100.00%\n",
      "            Message-Topic :    P =  629/( 629 +   0) = 100.00%     R =  629/ 629 = 100.00%     F1 = 100.00%\n",
      "         Product-Producer :    P =  603/( 603 +   0) = 100.00%     R =  603/ 603 = 100.00%     F1 = 100.00%\n",
      "                   _Other :    P = 1130/(1130 +   0) = 100.00%     R = 1130/1130 = 100.00%     F1 = 100.00%\n",
      "\n",
      "Micro-averaged result (excluding Other):\n",
      "P = 5978/5978 = 100.00%     R = 5978/5978 = 100.00%     F1 = 100.00%\n",
      "\n",
      "MACRO-averaged result (excluding Other):\n",
      "P = 100.00%\tR = 100.00%\tF1 = 100.00%\n",
      "\n",
      "\n",
      "\n",
      "<<< The official score is (9+1)-way evaluation with directionality taken into account: macro-averaged F1 = 100.00% >>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Use of uninitialized value in subtraction (-) at ./SemEval2010_task8_all_data/SemEval2010_task8_scorer-v1.2/semeval2010_task8_scorer-v1.2.pl line 288.\n",
      "Use of uninitialized value in printf at ./SemEval2010_task8_all_data/SemEval2010_task8_scorer-v1.2/semeval2010_task8_scorer-v1.2.pl line 288.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./SemEval2010_task8_all_data/SemEval2010_task8_scorer-v1.2/semeval2010_task8_scorer-v1.2.pl \\\n",
    "SemEval2010_task8_all_data/train_preds.txt SemEval2010_task8_all_data/train_keys.txt;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<<< The file format is OK.\n",
      "\n",
      "<<< The file format is OK.\n",
      "<<< (2*9+1)-WAY EVALUATION (USING DIRECTIONALITY)>>>:\n",
      "\n",
      "Confusion matrix:\n",
      "        C-E1 C-E2 C-W1 C-W2 C-C1 C-C2 E-D1 E-D2 E-O1 E-O2 I-A1 I-A2 M-C1 M-C2 M-T1 M-T2 P-P1 P-P2  _O_ <-- classified as\n",
      "      +-----------------------------------------------------------------------------------------------+ -SUM- skip ACTUAL\n",
      " C-E1 |   3    5    2    1   12    0   39    0   12    0    0    8    0   16   16    3    2   13    2 |  134    0  134\n",
      " C-E2 |  10    7    6    3   21    0   54    0   10    1    0    9    0   12   29    1    9   21    1 |  194    0  194\n",
      " C-W1 |   3    8    5    4   16    0   53    0    9    1    3   15    0   14   16    0    0   15    0 |  162    0  162\n",
      " C-W2 |   5   12    3    3   16    0   46    0   10    0    3   12    0    8   19    0    2   10    1 |  150    0  150\n",
      " C-C1 |   2    7    8    2   23    0   43    0    6    0    1   10    0   15   22    1    1   12    0 |  153    0  153\n",
      " C-C2 |   2    1    1    1    4    0   11    0    0    1    1    1    0    6    6    1    0    3    0 |   39    0   39\n",
      " E-D1 |   7   28    5    6   28    0   87    0   19    3    2   19    0   26   33    1    6   21    0 |  291    0  291\n",
      " E-D2 |   0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0 |    1    0    1\n",
      " E-O1 |   9   11    6    4   18    0   60    0   13    3    0    9    0   17   29    4    6   20    2 |  211    0  211\n",
      " E-O2 |   3    6    0    2    5    0   12    0    5    0    0    1    0    3    6    1    1    1    1 |   47    0   47\n",
      " I-A1 |   0    1    1    0    1    0    8    0    3    0    0    1    0    2    3    1    1    0    0 |   22    0   22\n",
      " I-A2 |   2   13    1    4   19    0   37    0    8    1    2    3    0   10   13    2    3   13    3 |  134    0  134\n",
      " M-C1 |   2    2    1    1    4    0   11    0    3    0    0    0    0    2    2    0    2    2    0 |   32    0   32\n",
      " M-C2 |   7   17    8    3   27    0   53    0   17    2    2    7    0   21   21    1    2   11    2 |  201    0  201\n",
      " M-T1 |  10   15    3    6   24    0   58    0   15    1    0   20    0   10   28    2    4   14    0 |  210    0  210\n",
      " M-T2 |   5    3    1    1    5    0   13    0    2    1    0    0    0    4    6    0    1    7    2 |   51    0   51\n",
      " P-P1 |   6    3    2    3   15    0   36    0    8    0    1    8    0    7   13    0    2    4    0 |  108    0  108\n",
      " P-P2 |   3   16    7    2   12    0   38    0    8    1    0    6    0    7    9    0    4    9    1 |  123    0  123\n",
      "  _O_ |  16   35   16   11   54    0  139    0   23    4    4   23    0   29   51    1   11   33    4 |  454    0  454\n",
      "      +-----------------------------------------------------------------------------------------------+\n",
      " -SUM-   95  190   76   57  304    0  798    0  171   19   19  152    0  209  323   19   57  209   19   2717    0 2717\n",
      "\n",
      "Coverage = 2717/2717 = 100.00%\n",
      "Accuracy (calculated for the above confusion matrix) = 208/2717 =  7.66%\n",
      "Accuracy (considering all skipped examples as Wrong) = 208/2717 =  7.66%\n",
      "Accuracy (considering all skipped examples as Other) = 208/2717 =  7.66%\n",
      "\n",
      "Results for the individual relations:\n",
      "      Cause-Effect(e1,e2) :    P =    3/  95 =   3.16%     R =    3/ 134 =   2.24%     F1 =   2.62%\n",
      "      Cause-Effect(e2,e1) :    P =    7/ 190 =   3.68%     R =    7/ 194 =   3.61%     F1 =   3.65%\n",
      "   Component-Whole(e1,e2) :    P =    5/  76 =   6.58%     R =    5/ 162 =   3.09%     F1 =   4.20%\n",
      "   Component-Whole(e2,e1) :    P =    3/  57 =   5.26%     R =    3/ 150 =   2.00%     F1 =   2.90%\n",
      " Content-Container(e1,e2) :    P =   23/ 304 =   7.57%     R =   23/ 153 =  15.03%     F1 =  10.07%\n",
      " Content-Container(e2,e1) :    P =    0/   0 =   0.00%     R =    0/  39 =   0.00%     F1 =   0.00%\n",
      "Entity-Destination(e1,e2) :    P =   87/ 798 =  10.90%     R =   87/ 291 =  29.90%     F1 =  15.98%\n",
      "Entity-Destination(e2,e1) :    P =    0/   0 =   0.00%     R =    0/   1 =   0.00%     F1 =   0.00%\n",
      "     Entity-Origin(e1,e2) :    P =   13/ 171 =   7.60%     R =   13/ 211 =   6.16%     F1 =   6.81%\n",
      "     Entity-Origin(e2,e1) :    P =    0/  19 =   0.00%     R =    0/  47 =   0.00%     F1 =   0.00%\n",
      " Instrument-Agency(e1,e2) :    P =    0/  19 =   0.00%     R =    0/  22 =   0.00%     F1 =   0.00%\n",
      " Instrument-Agency(e2,e1) :    P =    3/ 152 =   1.97%     R =    3/ 134 =   2.24%     F1 =   2.10%\n",
      " Member-Collection(e1,e2) :    P =    0/   0 =   0.00%     R =    0/  32 =   0.00%     F1 =   0.00%\n",
      " Member-Collection(e2,e1) :    P =   21/ 209 =  10.05%     R =   21/ 201 =  10.45%     F1 =  10.24%\n",
      "     Message-Topic(e1,e2) :    P =   28/ 323 =   8.67%     R =   28/ 210 =  13.33%     F1 =  10.51%\n",
      "     Message-Topic(e2,e1) :    P =    0/  19 =   0.00%     R =    0/  51 =   0.00%     F1 =   0.00%\n",
      "  Product-Producer(e1,e2) :    P =    2/  57 =   3.51%     R =    2/ 108 =   1.85%     F1 =   2.42%\n",
      "  Product-Producer(e2,e1) :    P =    9/ 209 =   4.31%     R =    9/ 123 =   7.32%     F1 =   5.42%\n",
      "                   _Other :    P =    4/  19 =  21.05%     R =    4/ 454 =   0.88%     F1 =   1.69%\n",
      "\n",
      "Micro-averaged result (excluding Other):\n",
      "P =  204/2698 =   7.56%     R =  204/2263 =   9.01%     F1 =   8.22%\n",
      "\n",
      "MACRO-averaged result (excluding Other):\n",
      "P =   4.07%\tR =   5.40%\tF1 =   4.27%\n",
      "\n",
      "\n",
      "\n",
      "<<< (9+1)-WAY EVALUATION IGNORING DIRECTIONALITY >>>:\n",
      "\n",
      "Confusion matrix:\n",
      "         C-E  C-W  C-C  E-D  E-O  I-A  M-C  M-T  P-P  _O_ <-- classified as\n",
      "      +--------------------------------------------------+ -SUM- skip ACTUAL\n",
      "  C-E |  25   12   33   93   23   17   28   49   45    3 |  328    0  328\n",
      "  C-W |  28   15   32   99   20   33   22   35   27    1 |  312    0  312\n",
      "  C-C |  12   12   27   54    7   13   21   30   16    0 |  192    0  192\n",
      "  E-D |  35   11   28   87   22   21   26   35   27    0 |  292    0  292\n",
      "  E-O |  29   12   23   72   21   10   20   40   28    3 |  258    0  258\n",
      "  I-A |  16    6   20   45   12    6   12   19   17    3 |  156    0  156\n",
      "  M-C |  28   13   31   64   22    9   23   24   17    2 |  233    0  233\n",
      "  M-T |  33   11   29   71   19   20   14   36   26    2 |  261    0  261\n",
      "  P-P |  28   14   27   74   17   15   14   22   19    1 |  231    0  231\n",
      "  _O_ |  51   27   54  139   27   27   29   52   44    4 |  454    0  454\n",
      "      +--------------------------------------------------+\n",
      " -SUM-  285  133  304  798  190  171  209  342  266   19   2717    0 2717\n",
      "\n",
      "Coverage = 2717/2717 = 100.00%\n",
      "Accuracy (calculated for the above confusion matrix) = 263/2717 =  9.68%\n",
      "Accuracy (considering all skipped examples as Wrong) = 263/2717 =  9.68%\n",
      "Accuracy (considering all skipped examples as Other) = 263/2717 =  9.68%\n",
      "\n",
      "Results for the individual relations:\n",
      "             Cause-Effect :    P =   25/ 285 =   8.77%     R =   25/ 328 =   7.62%     F1 =   8.16%\n",
      "          Component-Whole :    P =   15/ 133 =  11.28%     R =   15/ 312 =   4.81%     F1 =   6.74%\n",
      "        Content-Container :    P =   27/ 304 =   8.88%     R =   27/ 192 =  14.06%     F1 =  10.89%\n",
      "       Entity-Destination :    P =   87/ 798 =  10.90%     R =   87/ 292 =  29.79%     F1 =  15.96%\n",
      "            Entity-Origin :    P =   21/ 190 =  11.05%     R =   21/ 258 =   8.14%     F1 =   9.38%\n",
      "        Instrument-Agency :    P =    6/ 171 =   3.51%     R =    6/ 156 =   3.85%     F1 =   3.67%\n",
      "        Member-Collection :    P =   23/ 209 =  11.00%     R =   23/ 233 =   9.87%     F1 =  10.41%\n",
      "            Message-Topic :    P =   36/ 342 =  10.53%     R =   36/ 261 =  13.79%     F1 =  11.94%\n",
      "         Product-Producer :    P =   19/ 266 =   7.14%     R =   19/ 231 =   8.23%     F1 =   7.65%\n",
      "                   _Other :    P =    4/  19 =  21.05%     R =    4/ 454 =   0.88%     F1 =   1.69%\n",
      "\n",
      "Micro-averaged result (excluding Other):\n",
      "P =  259/2698 =   9.60%     R =  259/2263 =  11.44%     F1 =  10.44%\n",
      "\n",
      "MACRO-averaged result (excluding Other):\n",
      "P =   9.23%\tR =  11.13%\tF1 =   9.42%\n",
      "\n",
      "\n",
      "\n",
      "<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n",
      "\n",
      "Confusion matrix:\n",
      "         C-E  C-W  C-C  E-D  E-O  I-A  M-C  M-T  P-P  _O_ <-- classified as\n",
      "      +--------------------------------------------------+ -SUM- xDIRx skip  ACTUAL\n",
      "  C-E |  10   12   33   93   23   17   28   49   45    3 |  313    15     0    328\n",
      "  C-W |  28    8   32   99   20   33   22   35   27    1 |  305     7     0    312\n",
      "  C-C |  12   12   23   54    7   13   21   30   16    0 |  188     4     0    192\n",
      "  E-D |  35   11   28   87   22   21   26   35   27    0 |  292     0     0    292\n",
      "  E-O |  29   12   23   72   13   10   20   40   28    3 |  250     8     0    258\n",
      "  I-A |  16    6   20   45   12    3   12   19   17    3 |  153     3     0    156\n",
      "  M-C |  28   13   31   64   22    9   21   24   17    2 |  231     2     0    233\n",
      "  M-T |  33   11   29   71   19   20   14   28   26    2 |  253     8     0    261\n",
      "  P-P |  28   14   27   74   17   15   14   22   11    1 |  223     8     0    231\n",
      "  _O_ |  51   27   54  139   27   27   29   52   44    4 |  454     0     0    454\n",
      "      +--------------------------------------------------+\n",
      " -SUM-  270  126  300  798  182  168  207  334  258   19   2662    55     0   2717\n",
      "\n",
      "Coverage = 2717/2717 = 100.00%\n",
      "Accuracy (calculated for the above confusion matrix) = 208/2717 =  7.66%\n",
      "Accuracy (considering all skipped examples as Wrong) = 208/2717 =  7.66%\n",
      "Accuracy (considering all skipped examples as Other) = 208/2717 =  7.66%\n",
      "\n",
      "Results for the individual relations:\n",
      "             Cause-Effect :    P =   10/( 270 +  15) =   3.51%     R =   10/ 328 =   3.05%     F1 =   3.26%\n",
      "          Component-Whole :    P =    8/( 126 +   7) =   6.02%     R =    8/ 312 =   2.56%     F1 =   3.60%\n",
      "        Content-Container :    P =   23/( 300 +   4) =   7.57%     R =   23/ 192 =  11.98%     F1 =   9.27%\n",
      "       Entity-Destination :    P =   87/( 798 +   0) =  10.90%     R =   87/ 292 =  29.79%     F1 =  15.96%\n",
      "            Entity-Origin :    P =   13/( 182 +   8) =   6.84%     R =   13/ 258 =   5.04%     F1 =   5.80%\n",
      "        Instrument-Agency :    P =    3/( 168 +   3) =   1.75%     R =    3/ 156 =   1.92%     F1 =   1.83%\n",
      "        Member-Collection :    P =   21/( 207 +   2) =  10.05%     R =   21/ 233 =   9.01%     F1 =   9.50%\n",
      "            Message-Topic :    P =   28/( 334 +   8) =   8.19%     R =   28/ 261 =  10.73%     F1 =   9.29%\n",
      "         Product-Producer :    P =   11/( 258 +   8) =   4.14%     R =   11/ 231 =   4.76%     F1 =   4.43%\n",
      "                   _Other :    P =    4/(  19 +   0) =  21.05%     R =    4/ 454 =   0.88%     F1 =   1.69%\n",
      "\n",
      "Micro-averaged result (excluding Other):\n",
      "P =  204/2698 =   7.56%     R =  204/2263 =   9.01%     F1 =   8.22%\n",
      "\n",
      "MACRO-averaged result (excluding Other):\n",
      "P =   6.55%\tR =   8.76%\tF1 =   6.99%\n",
      "\n",
      "\n",
      "\n",
      "<<< The official score is (9+1)-way evaluation with directionality taken into account: macro-averaged F1 = 6.99% >>>\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./SemEval2010_task8_all_data/SemEval2010_task8_scorer-v1.2/semeval2010_task8_format_checker.pl \\\n",
    "SemEval2010_task8_all_data/test_pred.txt;\n",
    "./SemEval2010_task8_all_data/SemEval2010_task8_scorer-v1.2/semeval2010_task8_format_checker.pl \\\n",
    "SemEval2010_task8_all_data/test_keys.txt;\n",
    "./SemEval2010_task8_all_data/SemEval2010_task8_scorer-v1.2/semeval2010_task8_scorer-v1.2.pl \\\n",
    "SemEval2010_task8_all_data/test_pred.txt SemEval2010_task8_all_data/test_keys.txt;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, valid, test, label2int, int2label = sdh.load_semeval_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = [ sent[0] for sent in train['sents']+valid['sents']+test['sents'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sentences[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def a():\n",
    "    data = (1,2,3)\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(a())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i, t, l = valid['sdps'][:3], valid['targets'][:3], valid['labels'][:3]\n",
    "d = zip(i,t,l)\n",
    "for a,b,c in d:\n",
    "    print(a,b,c)\n",
    "random.shuffle(d)\n",
    "for a,b,c in d:\n",
    "    print(a,b,c)\n",
    "j,r,m = zip(*d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "CYCLE 0\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "===== UNSUPERVISED TRAINING =====\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-2860-11522\n",
      "143\n",
      "***** SUPERVISED TRAINING *****\n",
      "(0:0:0) s 0/143, e 0 avg class xent loss = 38.7017\n",
      "================================================================================\n",
      "(0:0:7) s 0/143, e 0 validation avg class xent loss = 42.5642\n",
      "================================================================================\n",
      "(0:0:15) s 10/143, e 0 avg class xent loss = 38.1246\n",
      "(0:0:23) s 20/143, e 0 avg class xent loss = 44.9585\n",
      "(0:0:30) s 30/143, e 0 avg class xent loss = 38.1478\n",
      "(0:0:38) s 40/143, e 0 avg class xent loss = 45.2779\n",
      "(0:0:45) s 50/143, e 0 avg class xent loss = 39.5168\n",
      "================================================================================\n",
      "(0:0:53) s 50/143, e 0 validation avg class xent loss = 41.6482\n",
      "================================================================================\n",
      "(0:1:0) s 60/143, e 0 avg class xent loss = 42.9935\n",
      "(0:1:8) s 70/143, e 0 avg class xent loss = 39.4292\n",
      "(0:1:16) s 80/143, e 0 avg class xent loss = 37.6740\n",
      "(0:1:23) s 90/143, e 0 avg class xent loss = 43.5841\n",
      "(0:1:31) s 100/143, e 0 avg class xent loss = 45.2794\n",
      "================================================================================\n",
      "(0:1:38) s 100/143, e 0 validation avg class xent loss = 41.3902\n",
      "================================================================================\n",
      "(0:1:46) s 110/143, e 0 avg class xent loss = 42.2725\n",
      "(0:1:54) s 120/143, e 0 avg class xent loss = 40.5708\n",
      "(0:2:2) s 130/143, e 0 avg class xent loss = 36.5028\n",
      "(0:2:9) s 140/143, e 0 avg class xent loss = 40.8752\n",
      "Macro P: 6.3634, R: 5.3042, F1: 5.7857\n",
      "(0:2:17) s 0/143, e 1 avg class xent loss = 44.8538\n",
      "================================================================================\n",
      "(0:2:24) s 0/143, e 1 validation avg class xent loss = 41.0216\n",
      "================================================================================\n",
      "(0:2:32) s 10/143, e 1 avg class xent loss = 42.5515\n",
      "(0:2:39) s 20/143, e 1 avg class xent loss = 41.0063\n",
      "(0:2:47) s 30/143, e 1 avg class xent loss = 38.1096\n",
      "(0:2:55) s 40/143, e 1 avg class xent loss = 44.3870\n",
      "(0:3:3) s 50/143, e 1 avg class xent loss = 41.9982\n",
      "================================================================================\n",
      "(0:3:9) s 50/143, e 1 validation avg class xent loss = 41.3070\n",
      "================================================================================\n",
      "(0:3:17) s 60/143, e 1 avg class xent loss = 37.1442\n",
      "(0:3:24) s 70/143, e 1 avg class xent loss = 42.8246\n",
      "(0:3:32) s 80/143, e 1 avg class xent loss = 42.0300\n",
      "(0:3:40) s 90/143, e 1 avg class xent loss = 44.7828\n",
      "(0:3:47) s 100/143, e 1 avg class xent loss = 43.4250\n",
      "================================================================================\n",
      "(0:3:54) s 100/143, e 1 validation avg class xent loss = 41.2679\n",
      "================================================================================\n",
      "(0:4:2) s 110/143, e 1 avg class xent loss = 40.6952\n",
      "(0:4:9) s 120/143, e 1 avg class xent loss = 43.2496\n",
      "(0:4:17) s 130/143, e 1 avg class xent loss = 42.0837\n",
      "(0:4:24) s 140/143, e 1 avg class xent loss = 43.4534\n",
      "Macro P: 2.8844, R: 6.0312, F1: 3.9025\n",
      "(0:4:33) s 0/143, e 2 avg class xent loss = 38.5314\n",
      "================================================================================\n",
      "(0:4:39) s 0/143, e 2 validation avg class xent loss = 41.3498\n",
      "================================================================================\n",
      "(0:4:47) s 10/143, e 2 avg class xent loss = 38.6216\n",
      "(0:4:54) s 20/143, e 2 avg class xent loss = 46.9105\n",
      "(0:5:2) s 30/143, e 2 avg class xent loss = 40.1257\n",
      "(0:5:10) s 40/143, e 2 avg class xent loss = 42.3088\n",
      "(0:5:17) s 50/143, e 2 avg class xent loss = 39.1651\n",
      "================================================================================\n",
      "(0:5:24) s 50/143, e 2 validation avg class xent loss = 42.0999\n",
      "================================================================================\n",
      "(0:5:31) s 60/143, e 2 avg class xent loss = 41.3792\n",
      "(0:5:39) s 70/143, e 2 avg class xent loss = 38.2530\n",
      "(0:5:47) s 80/143, e 2 avg class xent loss = 43.1268\n",
      "(0:5:55) s 90/143, e 2 avg class xent loss = 40.6919\n",
      "(0:6:2) s 100/143, e 2 avg class xent loss = 41.6653\n",
      "================================================================================\n",
      "(0:6:9) s 100/143, e 2 validation avg class xent loss = 41.2707\n",
      "================================================================================\n",
      "(0:6:17) s 110/143, e 2 avg class xent loss = 43.8625\n",
      "(0:6:24) s 120/143, e 2 avg class xent loss = 43.6603\n",
      "(0:6:32) s 130/143, e 2 avg class xent loss = 41.1936\n",
      "(0:6:40) s 140/143, e 2 avg class xent loss = 44.0284\n",
      "Macro P: 7.7043, R: 5.5382, F1: 6.4441\n",
      "(0:6:48) s 0/143, e 3 avg class xent loss = 45.0412\n",
      "================================================================================\n",
      "(0:6:55) s 0/143, e 3 validation avg class xent loss = 41.6060\n",
      "================================================================================\n",
      "(0:7:2) s 10/143, e 3 avg class xent loss = 47.0325\n",
      "(0:7:10) s 20/143, e 3 avg class xent loss = 44.0508\n",
      "(0:7:18) s 30/143, e 3 avg class xent loss = 38.4714\n",
      "(0:7:25) s 40/143, e 3 avg class xent loss = 40.2195\n",
      "(0:7:33) s 50/143, e 3 avg class xent loss = 38.3387\n",
      "================================================================================\n",
      "(0:7:40) s 50/143, e 3 validation avg class xent loss = 42.2429\n",
      "================================================================================\n",
      "(0:7:47) s 60/143, e 3 avg class xent loss = 42.4404\n",
      "(0:7:55) s 70/143, e 3 avg class xent loss = 43.7174\n",
      "(0:8:2) s 80/143, e 3 avg class xent loss = 47.3518\n",
      "(0:8:10) s 90/143, e 3 avg class xent loss = 40.9602\n",
      "(0:8:18) s 100/143, e 3 avg class xent loss = 41.7206\n",
      "================================================================================\n",
      "(0:8:24) s 100/143, e 3 validation avg class xent loss = 41.6671\n",
      "================================================================================\n",
      "(0:8:32) s 110/143, e 3 avg class xent loss = 37.3431\n",
      "(0:8:39) s 120/143, e 3 avg class xent loss = 44.0715\n",
      "(0:8:47) s 130/143, e 3 avg class xent loss = 38.1681\n",
      "(0:8:54) s 140/143, e 3 avg class xent loss = 46.3226\n",
      "Macro P: 5.4359, R: 4.3710, F1: 4.8456\n",
      "(0:9:3) s 0/143, e 4 avg class xent loss = 47.0904\n",
      "================================================================================\n",
      "(0:9:9) s 0/143, e 4 validation avg class xent loss = 42.1272\n",
      "================================================================================\n",
      "(0:9:17) s 10/143, e 4 avg class xent loss = 46.2025\n",
      "(0:9:25) s 20/143, e 4 avg class xent loss = 42.9052\n",
      "(0:9:32) s 30/143, e 4 avg class xent loss = 42.3525\n",
      "(0:9:40) s 40/143, e 4 avg class xent loss = 40.0640\n",
      "(0:9:48) s 50/143, e 4 avg class xent loss = 39.6370\n",
      "================================================================================\n",
      "(0:9:54) s 50/143, e 4 validation avg class xent loss = 42.9383\n",
      "================================================================================\n",
      "(0:10:2) s 60/143, e 4 avg class xent loss = 43.2611\n",
      "(0:10:10) s 70/143, e 4 avg class xent loss = 41.9086\n",
      "(0:10:18) s 80/143, e 4 avg class xent loss = 42.1000\n",
      "(0:10:25) s 90/143, e 4 avg class xent loss = 41.8549\n",
      "(0:10:33) s 100/143, e 4 avg class xent loss = 47.3472\n",
      "================================================================================\n",
      "(0:10:39) s 100/143, e 4 validation avg class xent loss = 42.0715\n",
      "================================================================================\n",
      "(0:10:47) s 110/143, e 4 avg class xent loss = 40.1377\n",
      "(0:10:55) s 120/143, e 4 avg class xent loss = 43.2644\n",
      "(0:11:2) s 130/143, e 4 avg class xent loss = 42.4824\n",
      "(0:11:10) s 140/143, e 4 avg class xent loss = 44.2414\n",
      "Macro P: 3.5129, R: 4.8066, F1: 4.0592\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-2860-12232\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "CYCLE 1\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "===== UNSUPERVISED TRAINING =====\n",
      "(0:0:2) step 0/143, epoch 0 Training Loss = 11.83929 :: 1951.370 phrases/sec :: (0:1:33) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <slugs> '<X> snails cause <Y>' <holes>\n",
      "0: 1.000 : <slugs> '<X> snails cause <Y>' <holes>\n",
      "1: 0.938 : <colorants> '<X> preservatives cause dryness <Y>' <rashes>\n",
      "2: 0.937 : <fats> '<X> cause <Y>' <disease>\n",
      "3: 0.910 : <drugs> '<X> cause arrest <Y>' <unconsciousness>\n",
      "4: 0.904 : <measles> '<X> cause <Y>' <rashes>\n",
      "5: 0.901 : <builder> '<X> mortgaged <Y>' <land>\n",
      "6: 0.896 : <reagent> '<X> contained in dam <Y>' <holding>\n",
      "7: 0.891 : <letter> '<X> contained in <Y>' <envelope>\n",
      "8: 0.891 : <sample> '<X> contained in <Y>' <cup>\n",
      "9: 0.889 : <citations> '<X> references appear in <Y>' <book>\n",
      "10: 0.884 : <glomeruli> '<X> assist <Y>' <kidneys>\n",
      "11: 0.878 : <statute> '<X> covering <Y>' <matter>\n",
      "12: 0.878 : <supplies> '<X> regulate using <Y>' <regulator>\n",
      "13: 0.878 : <subsection> '<X> applies <Y>' <measure>\n",
      "14: 0.877 : <headhunter> '<X> <Y>' <company>\n",
      "15: 0.877 : <designer> '<X> <Y>' <hotel>\n",
      "16: 0.877 : <official> '<X> sacked drawn <Y>' <plans>\n",
      "17: 0.876 : <snake> '<X> <Y>' <tongue>\n",
      "18: 0.876 : <manufacturer> '<X> <Y>' <drug>\n",
      "19: 0.876 : <scientist> '<X> <Y>' <theories>\n",
      "================================================================================\n",
      "Validation loss: 12.2003\n",
      "(0:0:19) step 10/143, epoch 0 Training Loss = 11.06759 :: 1323.838 phrases/sec :: (0:2:1) hours left\n",
      "(0:0:37) step 20/143, epoch 0 Training Loss = 10.34579 :: 1265.717 phrases/sec :: (0:1:50) hours left\n",
      "(0:0:55) step 30/143, epoch 0 Training Loss = 9.75148 :: 1227.918 phrases/sec :: (0:1:36) hours left\n",
      "(0:1:13) step 40/143, epoch 0 Training Loss = 9.09643 :: 1213.304 phrases/sec :: (0:1:20) hours left\n",
      "(0:1:30) step 50/143, epoch 0 Training Loss = 8.54627 :: 1212.268 phrases/sec :: (0:1:3) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <sedge> '<X> of <Y>' <bitterns>\n",
      "0: 1.000 : <isle> '<X> of <Y>' <store>\n",
      "1: 1.000 : <array> '<X> of <Y>' <hedgehogs>\n",
      "2: 1.000 : <galaxy> '<X> of <Y>' <footballers>\n",
      "3: 1.000 : <rig> '<X> of <Y>' <vessel>\n",
      "4: 1.000 : <faction> '<X> of <Y>' <extremists>\n",
      "5: 1.000 : <creep> '<X> of <Y>' <tortoises>\n",
      "6: 1.000 : <rivet> '<X> of <Y>' <button>\n",
      "7: 1.000 : <sorority> '<X> of <Y>' <misfits>\n",
      "8: 1.000 : <brigade> '<X> of <Y>' <soldiers>\n",
      "9: 1.000 : <clique> '<X> of <Y>' <girls>\n",
      "10: 1.000 : <crowd> '<X> of <Y>' <protesters>\n",
      "11: 1.000 : <battery> '<X> of <Y>' <tests>\n",
      "12: 1.000 : <rangale> '<X> of <Y>' <deer>\n",
      "13: 1.000 : <handgrip> '<X> of <Y>' <camera>\n",
      "14: 1.000 : <glut> '<X> of <Y>' <startups>\n",
      "15: 1.000 : <riffraff> '<X> of <Y>' <liars>\n",
      "16: 1.000 : <hookup> '<X> of <Y>' <vessels>\n",
      "17: 1.000 : <sounder> '<X> of <Y>' <pigs>\n",
      "18: 1.000 : <paddle> '<X> of <Y>' <switch>\n",
      "19: 1.000 : <hood> '<X> of <Y>' <truck>\n",
      "================================================================================\n",
      "Validation loss: 10.3992\n",
      "(0:1:49) step 60/143, epoch 0 Training Loss = 8.03467 :: 1212.567 phrases/sec :: (0:0:44) hours left\n",
      "(0:2:6) step 70/143, epoch 0 Training Loss = 7.53034 :: 1210.751 phrases/sec :: (0:0:27) hours left\n",
      "(0:2:24) step 80/143, epoch 0 Training Loss = 7.09074 :: 1214.830 phrases/sec :: (0:0:9) hours left\n",
      "(0:2:41) step 90/143, epoch 0 Training Loss = 6.66565 :: 1218.380 phrases/sec :: (-1:59:51) hours left\n",
      "(0:2:59) step 100/143, epoch 0 Training Loss = 6.28101 :: 1212.255 phrases/sec :: (-1:59:34) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <slowdown> '<X> caused by <Y>' <recession>\n",
      "0: 1.000 : <damage> '<X> caused by <Y>' <storm>\n",
      "1: 1.000 : <death> '<X> caused by <Y>' <storm>\n",
      "2: 1.000 : <devastations> '<X> caused by <Y>' <storms>\n",
      "3: 1.000 : <emergency> '<X> caused by <Y>' <landslide>\n",
      "4: 1.000 : <slowdown> '<X> caused by <Y>' <recession>\n",
      "5: 1.000 : <devastation> '<X> caused by <Y>' <tornado>\n",
      "6: 1.000 : <suffering> '<X> caused by <Y>' <drinking>\n",
      "7: 1.000 : <sorrow> '<X> caused by <Y>' <attack>\n",
      "8: 1.000 : <disruption> '<X> caused by <Y>' <strike>\n",
      "9: 1.000 : <hardship> '<X> caused by <Y>' <recession>\n",
      "10: 0.998 : <inflammation> '<X> caused by <Y>' <growth>\n",
      "11: 0.998 : <cancer> '<X> caused by <Y>' <infection>\n",
      "12: 0.998 : <collapse> '<X> caused by <Y>' <consumers>\n",
      "13: 0.998 : <deficits> '<X> caused by <Y>' <people>\n",
      "14: 0.998 : <earthquake> '<X> caused by <Y>' <rupture>\n",
      "15: 0.998 : <unemployment> '<X> caused by <Y>' <people>\n",
      "16: 0.998 : <harm> '<X> caused by <Y>' <system>\n",
      "17: 0.998 : <injury> '<X> caused by <Y>' <intoxication>\n",
      "18: 0.998 : <problems> '<X> caused by <Y>' <overflows>\n",
      "19: 0.998 : <fevers> '<X> caused by <Y>' <colds>\n",
      "================================================================================\n",
      "Validation loss: 8.7915\n",
      "(0:3:16) step 110/143, epoch 0 Training Loss = 5.92226 :: 1212.828 phrases/sec :: (-1:59:16) hours left\n",
      "(0:3:34) step 120/143, epoch 0 Training Loss = 5.57410 :: 1213.629 phrases/sec :: (-1:58:59) hours left\n",
      "(0:3:52) step 130/143, epoch 0 Training Loss = 5.25559 :: 1213.941 phrases/sec :: (-1:58:41) hours left\n",
      "(0:4:10) step 140/143, epoch 0 Training Loss = 4.90559 :: 1211.073 phrases/sec :: (-1:58:23) hours left\n",
      "Macro P: 3.8993, R: 4.3036, F1: 4.0915\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-3003-12232\n",
      "143\n",
      "***** SUPERVISED TRAINING *****\n",
      "(0:0:0) s 0/143, e 0 avg class xent loss = 43.3653\n",
      "================================================================================\n",
      "(0:0:7) s 0/143, e 0 validation avg class xent loss = 42.5227\n",
      "================================================================================\n",
      "(0:0:15) s 10/143, e 0 avg class xent loss = 41.0075\n",
      "(0:0:22) s 20/143, e 0 avg class xent loss = 44.4138\n",
      "(0:0:30) s 30/143, e 0 avg class xent loss = 38.7267\n",
      "(0:0:37) s 40/143, e 0 avg class xent loss = 49.6924\n",
      "(0:0:45) s 50/143, e 0 avg class xent loss = 40.8558\n",
      "================================================================================\n",
      "(0:0:52) s 50/143, e 0 validation avg class xent loss = 42.8204\n",
      "================================================================================\n",
      "(0:0:59) s 60/143, e 0 avg class xent loss = 38.3666\n",
      "(0:1:7) s 70/143, e 0 avg class xent loss = 41.1779\n",
      "(0:1:15) s 80/143, e 0 avg class xent loss = 39.4566\n",
      "(0:1:22) s 90/143, e 0 avg class xent loss = 41.6162\n",
      "(0:1:30) s 100/143, e 0 avg class xent loss = 39.3072\n",
      "================================================================================\n",
      "(0:1:36) s 100/143, e 0 validation avg class xent loss = 41.9966\n",
      "================================================================================\n",
      "(0:1:44) s 110/143, e 0 avg class xent loss = 44.0523\n",
      "(0:1:52) s 120/143, e 0 avg class xent loss = 41.2659\n",
      "(0:1:59) s 130/143, e 0 avg class xent loss = 38.6698\n",
      "(0:2:10) s 140/143, e 0 avg class xent loss = 41.5981\n",
      "Macro P: 1.7160, R: 5.9079, F1: 2.6595\n",
      "(0:2:24) s 0/143, e 1 avg class xent loss = 44.9516\n",
      "================================================================================\n",
      "(0:2:35) s 0/143, e 1 validation avg class xent loss = 42.1721\n",
      "================================================================================\n",
      "(0:2:43) s 10/143, e 1 avg class xent loss = 38.8748\n",
      "(0:2:51) s 20/143, e 1 avg class xent loss = 44.3397\n",
      "(0:2:59) s 30/143, e 1 avg class xent loss = 39.5989\n",
      "(0:3:9) s 40/143, e 1 avg class xent loss = 46.7911\n",
      "(0:3:17) s 50/143, e 1 avg class xent loss = 38.6767\n",
      "================================================================================\n",
      "(0:3:26) s 50/143, e 1 validation avg class xent loss = 42.0432\n",
      "================================================================================\n",
      "(0:3:37) s 60/143, e 1 avg class xent loss = 34.9707\n",
      "(0:3:45) s 70/143, e 1 avg class xent loss = 41.1825\n",
      "(0:3:53) s 80/143, e 1 avg class xent loss = 36.4619\n",
      "(0:4:3) s 90/143, e 1 avg class xent loss = 41.7638\n",
      "(0:4:13) s 100/143, e 1 avg class xent loss = 43.8460\n",
      "================================================================================\n",
      "(0:4:21) s 100/143, e 1 validation avg class xent loss = 41.9645\n",
      "================================================================================\n",
      "(0:4:30) s 110/143, e 1 avg class xent loss = 45.6685\n",
      "(0:4:39) s 120/143, e 1 avg class xent loss = 35.4299\n",
      "(0:4:48) s 130/143, e 1 avg class xent loss = 40.9750\n",
      "(0:4:56) s 140/143, e 1 avg class xent loss = 41.9047\n",
      "Macro P: 5.0068, R: 6.1186, F1: 5.5072\n",
      "(0:5:5) s 0/143, e 2 avg class xent loss = 40.9203\n",
      "================================================================================\n",
      "(0:5:14) s 0/143, e 2 validation avg class xent loss = 41.3087\n",
      "================================================================================\n",
      "(0:5:23) s 10/143, e 2 avg class xent loss = 39.7515\n",
      "(0:5:30) s 20/143, e 2 avg class xent loss = 45.6505\n",
      "(0:5:38) s 30/143, e 2 avg class xent loss = 40.2501\n",
      "(0:5:46) s 40/143, e 2 avg class xent loss = 48.0110\n",
      "(0:5:56) s 50/143, e 2 avg class xent loss = 38.9105\n",
      "================================================================================\n",
      "(0:6:3) s 50/143, e 2 validation avg class xent loss = 41.8877\n",
      "================================================================================\n",
      "(0:6:12) s 60/143, e 2 avg class xent loss = 37.7549\n",
      "(0:6:20) s 70/143, e 2 avg class xent loss = 48.3712\n",
      "(0:6:28) s 80/143, e 2 avg class xent loss = 37.5185\n",
      "(0:6:38) s 90/143, e 2 avg class xent loss = 41.1953\n",
      "(0:6:47) s 100/143, e 2 avg class xent loss = 44.3717\n",
      "================================================================================\n",
      "(0:6:55) s 100/143, e 2 validation avg class xent loss = 41.0255\n",
      "================================================================================\n",
      "(0:7:3) s 110/143, e 2 avg class xent loss = 39.8189\n",
      "(0:7:12) s 120/143, e 2 avg class xent loss = 39.1270\n",
      "(0:7:22) s 130/143, e 2 avg class xent loss = 39.5187\n",
      "(0:7:30) s 140/143, e 2 avg class xent loss = 38.6034\n",
      "Macro P: 7.1847, R: 5.3656, F1: 6.1433\n",
      "(0:7:38) s 0/143, e 3 avg class xent loss = 44.9308\n",
      "================================================================================\n",
      "(0:7:44) s 0/143, e 3 validation avg class xent loss = 41.1145\n",
      "================================================================================\n",
      "(0:7:51) s 10/143, e 3 avg class xent loss = 39.4354\n",
      "(0:7:58) s 20/143, e 3 avg class xent loss = 43.5963\n",
      "(0:8:5) s 30/143, e 3 avg class xent loss = 40.9482\n",
      "(0:8:12) s 40/143, e 3 avg class xent loss = 46.1143\n",
      "(0:8:19) s 50/143, e 3 avg class xent loss = 43.3688\n",
      "================================================================================\n",
      "(0:8:25) s 50/143, e 3 validation avg class xent loss = 42.0047\n",
      "================================================================================\n",
      "(0:8:32) s 60/143, e 3 avg class xent loss = 38.5148\n",
      "(0:8:39) s 70/143, e 3 avg class xent loss = 39.8599\n",
      "(0:8:46) s 80/143, e 3 avg class xent loss = 42.2823\n",
      "(0:8:53) s 90/143, e 3 avg class xent loss = 38.2587\n",
      "(0:9:0) s 100/143, e 3 avg class xent loss = 39.5770\n",
      "================================================================================\n",
      "(0:9:7) s 100/143, e 3 validation avg class xent loss = 40.5255\n",
      "================================================================================\n",
      "(0:9:13) s 110/143, e 3 avg class xent loss = 40.7661\n",
      "(0:9:21) s 120/143, e 3 avg class xent loss = 47.8623\n",
      "(0:9:28) s 130/143, e 3 avg class xent loss = 41.6308\n",
      "(0:9:36) s 140/143, e 3 avg class xent loss = 38.7888\n",
      "Macro P: 6.6484, R: 10.0191, F1: 7.9929\n",
      "(0:9:44) s 0/143, e 4 avg class xent loss = 39.3564\n",
      "================================================================================\n",
      "(0:9:51) s 0/143, e 4 validation avg class xent loss = 40.7489\n",
      "================================================================================\n",
      "(0:9:59) s 10/143, e 4 avg class xent loss = 47.7771\n",
      "(0:10:6) s 20/143, e 4 avg class xent loss = 44.9794\n",
      "(0:10:14) s 30/143, e 4 avg class xent loss = 39.8626\n",
      "(0:10:22) s 40/143, e 4 avg class xent loss = 41.3944\n",
      "(0:10:29) s 50/143, e 4 avg class xent loss = 40.4990\n",
      "================================================================================\n",
      "(0:10:36) s 50/143, e 4 validation avg class xent loss = 41.3813\n",
      "================================================================================\n",
      "(0:10:43) s 60/143, e 4 avg class xent loss = 34.3178\n",
      "(0:10:51) s 70/143, e 4 avg class xent loss = 41.8648\n",
      "(0:10:59) s 80/143, e 4 avg class xent loss = 44.2576\n",
      "(0:11:7) s 90/143, e 4 avg class xent loss = 40.4859\n",
      "(0:11:14) s 100/143, e 4 avg class xent loss = 45.9081\n",
      "================================================================================\n",
      "(0:11:21) s 100/143, e 4 validation avg class xent loss = 41.8893\n",
      "================================================================================\n",
      "(0:11:29) s 110/143, e 4 avg class xent loss = 39.2711\n",
      "(0:11:36) s 120/143, e 4 avg class xent loss = 41.7109\n",
      "(0:11:44) s 130/143, e 4 avg class xent loss = 33.7541\n",
      "(0:11:51) s 140/143, e 4 avg class xent loss = 38.9298\n",
      "Macro P: 2.5984, R: 6.6427, F1: 3.7356\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-3003-12942\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "CYCLE 2\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "===== UNSUPERVISED TRAINING =====\n",
      "(0:0:1) step 0/143, epoch 0 Training Loss = 10.10803 :: 2549.315 phrases/sec :: (0:1:11) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <scientist> '<X> <Y>' <theories>\n",
      "0: 1.000 : <scientist> '<X> <Y>' <theories>\n",
      "1: 0.984 : <researches> '<X> pointing <Y>' <image>\n",
      "2: 0.979 : <hurdles> '<X> for <Y>' <drilling>\n",
      "3: 0.977 : <book> '<X> criticizing <Y>' <writings>\n",
      "4: 0.976 : <documentary> '<X> detailing <Y>' <stages>\n",
      "5: 0.974 : <headhunter> '<X> <Y>' <company>\n",
      "6: 0.974 : <designer> '<X> <Y>' <hotel>\n",
      "7: 0.955 : <mustering> '<X> have glad are visit <Y>' <stork>\n",
      "8: 0.951 : <subsection> '<X> applies <Y>' <measure>\n",
      "9: 0.943 : <painter> '<X> life treats <Y>' <works>\n",
      "10: 0.940 : <documents> '<X> illustrating <Y>' <history>\n",
      "11: 0.935 : <statute> '<X> covering <Y>' <matter>\n",
      "12: 0.929 : <work> '<X> <Y>' <food>\n",
      "13: 0.929 : <clergy> '<X> <Y>' <vestments>\n",
      "14: 0.929 : <maps> '<X> <Y>' <representations>\n",
      "15: 0.878 : <petroleum> '<X> <Y>' <company>\n",
      "16: 0.875 : <olive> '<X> <Y>' <oil>\n",
      "17: 0.854 : <committee> '<X> <Y>' <member>\n",
      "18: 0.828 : <plastic> '<X> <Y>' <bag>\n",
      "19: 0.827 : <welcome> '<X> speech of <Y>' <conference>\n",
      "================================================================================\n",
      "Validation loss: 10.3883\n",
      "(0:0:19) step 10/143, epoch 0 Training Loss = 9.40863 :: 1319.599 phrases/sec :: (0:2:1) hours left\n",
      "(0:0:37) step 20/143, epoch 0 Training Loss = 8.79917 :: 1264.556 phrases/sec :: (0:1:50) hours left\n",
      "(0:0:54) step 30/143, epoch 0 Training Loss = 8.24014 :: 1254.862 phrases/sec :: (0:1:34) hours left\n",
      "(0:1:13) step 40/143, epoch 0 Training Loss = 7.70591 :: 1222.967 phrases/sec :: (0:1:19) hours left\n",
      "(0:1:30) step 50/143, epoch 0 Training Loss = 7.27557 :: 1223.693 phrases/sec :: (0:1:2) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <stack> '<X> loading into <Y>' <carton>\n",
      "0: 1.000 : <stack> '<X> loading into <Y>' <carton>\n",
      "1: 1.000 : <system> '<X> translates into <Y>' <speech>\n",
      "2: 1.000 : <gallon> '<X> put into <Y>' <cart>\n",
      "3: 1.000 : <penny> '<X> put into <Y>' <machines>\n",
      "4: 1.000 : <supernatant> '<X> removed into <Y>' <tube>\n",
      "5: 1.000 : <keys> '<X> added into <Y>' <memory>\n",
      "6: 1.000 : <stores> '<X> draining into <Y>' <memory>\n",
      "7: 1.000 : <infrastructure> '<X> falling into <Y>' <disrepair>\n",
      "8: 1.000 : <cancer> '<X> spreads into <Y>' <areas>\n",
      "9: 1.000 : <empathy> '<X> poured into <Y>' <poetry>\n",
      "10: 1.000 : <billion> '<X> poured into <Y>' <economy>\n",
      "11: 1.000 : <concrete> '<X> poured into <Y>' <hull>\n",
      "12: 1.000 : <flour> '<X> poured into <Y>' <dragon>\n",
      "13: 1.000 : <aluminium> '<X> poured into <Y>' <ingots>\n",
      "14: 1.000 : <flour> '<X> poured into <Y>' <pan>\n",
      "15: 1.000 : <integration> '<X> released into <Y>' <networks>\n",
      "16: 1.000 : <surveys> '<X> entered into <Y>' <report>\n",
      "17: 1.000 : <water> '<X> drained into <Y>' <tank>\n",
      "18: 1.000 : <album> '<X> put into <Y>' <folder>\n",
      "19: 1.000 : <microprocessor> '<X> cluster migrated into <Y>' <applications>\n",
      "================================================================================\n",
      "Validation loss: 9.2301\n",
      "(0:1:48) step 60/143, epoch 0 Training Loss = 6.82858 :: 1218.563 phrases/sec :: (0:0:44) hours left\n",
      "(0:2:6) step 70/143, epoch 0 Training Loss = 6.40846 :: 1218.472 phrases/sec :: (0:0:27) hours left\n",
      "(0:2:23) step 80/143, epoch 0 Training Loss = 6.01593 :: 1217.802 phrases/sec :: (0:0:9) hours left\n",
      "(0:2:41) step 90/143, epoch 0 Training Loss = 5.68001 :: 1218.618 phrases/sec :: (-1:59:52) hours left\n",
      "(0:2:58) step 100/143, epoch 0 Training Loss = 5.33468 :: 1219.372 phrases/sec :: (-1:59:34) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <supernatant> '<X> removed into <Y>' <tube>\n",
      "0: 1.000 : <supernatant> '<X> removed into <Y>' <tube>\n",
      "1: 1.000 : <pellets> '<X> blown into <Y>' <cavities>\n",
      "2: 1.000 : <aircraft> '<X> dropped into <Y>' <landing>\n",
      "3: 1.000 : <album> '<X> put into <Y>' <folder>\n",
      "4: 1.000 : <metals> '<X> released into <Y>' <environment>\n",
      "5: 1.000 : <water> '<X> drained into <Y>' <tank>\n",
      "6: 0.999 : <bottom> '<X> welded into <Y>' <casket>\n",
      "7: 0.999 : <catheter> '<X> placed into <Y>' <stomach>\n",
      "8: 0.998 : <droxyapatite> '<X> implanted into <Y>' <gaps>\n",
      "9: 0.998 : <geodiversity> '<X> added into <Y>' <objective>\n",
      "10: 0.998 : <gallon> '<X> put into <Y>' <cart>\n",
      "11: 0.998 : <penny> '<X> put into <Y>' <machines>\n",
      "12: 0.998 : <system> '<X> translates into <Y>' <speech>\n",
      "13: 0.998 : <stack> '<X> loading into <Y>' <carton>\n",
      "14: 0.997 : <integration> '<X> released into <Y>' <networks>\n",
      "15: 0.997 : <coolant> '<X> leaked into <Y>' <oil>\n",
      "16: 0.997 : <surveys> '<X> entered into <Y>' <report>\n",
      "17: 0.997 : <empathy> '<X> poured into <Y>' <poetry>\n",
      "18: 0.997 : <billion> '<X> poured into <Y>' <economy>\n",
      "19: 0.997 : <concrete> '<X> poured into <Y>' <hull>\n",
      "================================================================================\n",
      "Validation loss: 8.0251\n",
      "(0:3:16) step 110/143, epoch 0 Training Loss = 5.04324 :: 1216.228 phrases/sec :: (-1:59:16) hours left\n",
      "(0:3:34) step 120/143, epoch 0 Training Loss = 4.73580 :: 1209.901 phrases/sec :: (-1:58:59) hours left\n",
      "(0:3:52) step 130/143, epoch 0 Training Loss = 4.48673 :: 1208.549 phrases/sec :: (-1:58:41) hours left\n",
      "(0:4:10) step 140/143, epoch 0 Training Loss = 4.21809 :: 1208.799 phrases/sec :: (-1:58:24) hours left\n",
      "Macro P: 2.9121, R: 3.8175, F1: 3.3039\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-3146-12942\n",
      "143\n",
      "***** SUPERVISED TRAINING *****\n",
      "(0:0:0) s 0/143, e 0 avg class xent loss = 50.3223\n",
      "================================================================================\n",
      "(0:0:7) s 0/143, e 0 validation avg class xent loss = 41.1391\n",
      "================================================================================\n",
      "(0:0:15) s 10/143, e 0 avg class xent loss = 43.4419\n",
      "(0:0:22) s 20/143, e 0 avg class xent loss = 38.9505\n",
      "(0:0:30) s 30/143, e 0 avg class xent loss = 37.4923\n",
      "(0:0:37) s 40/143, e 0 avg class xent loss = 43.2607\n",
      "(0:0:45) s 50/143, e 0 avg class xent loss = 37.3820\n",
      "================================================================================\n",
      "(0:0:52) s 50/143, e 0 validation avg class xent loss = 41.7337\n",
      "================================================================================\n",
      "(0:0:59) s 60/143, e 0 avg class xent loss = 38.6114\n",
      "(0:1:7) s 70/143, e 0 avg class xent loss = 40.1034\n",
      "(0:1:14) s 80/143, e 0 avg class xent loss = 37.9746\n",
      "(0:1:22) s 90/143, e 0 avg class xent loss = 41.4161\n",
      "(0:1:30) s 100/143, e 0 avg class xent loss = 43.3576\n",
      "================================================================================\n",
      "(0:1:36) s 100/143, e 0 validation avg class xent loss = 41.2205\n",
      "================================================================================\n",
      "(0:1:44) s 110/143, e 0 avg class xent loss = 35.7111\n",
      "(0:1:52) s 120/143, e 0 avg class xent loss = 42.0151\n",
      "(0:2:0) s 130/143, e 0 avg class xent loss = 38.2193\n",
      "(0:2:7) s 140/143, e 0 avg class xent loss = 39.1886\n",
      "Macro P: 4.4051, R: 4.9605, F1: 4.6663\n",
      "(0:2:15) s 0/143, e 1 avg class xent loss = 43.7476\n",
      "================================================================================\n",
      "(0:2:22) s 0/143, e 1 validation avg class xent loss = 41.6194\n",
      "================================================================================\n",
      "(0:2:30) s 10/143, e 1 avg class xent loss = 41.6278\n",
      "(0:2:37) s 20/143, e 1 avg class xent loss = 38.9293\n",
      "(0:2:45) s 30/143, e 1 avg class xent loss = 41.4302\n",
      "(0:2:53) s 40/143, e 1 avg class xent loss = 44.1432\n",
      "(0:3:0) s 50/143, e 1 avg class xent loss = 38.1042\n",
      "================================================================================\n",
      "(0:3:7) s 50/143, e 1 validation avg class xent loss = 41.4301\n",
      "================================================================================\n",
      "(0:3:14) s 60/143, e 1 avg class xent loss = 40.3138\n",
      "(0:3:22) s 70/143, e 1 avg class xent loss = 37.3283\n",
      "(0:3:30) s 80/143, e 1 avg class xent loss = 39.1501\n",
      "(0:3:37) s 90/143, e 1 avg class xent loss = 39.4822\n",
      "(0:3:45) s 100/143, e 1 avg class xent loss = 44.0714\n",
      "================================================================================\n",
      "(0:3:51) s 100/143, e 1 validation avg class xent loss = 41.8002\n",
      "================================================================================\n",
      "(0:3:59) s 110/143, e 1 avg class xent loss = 34.8226\n",
      "(0:4:7) s 120/143, e 1 avg class xent loss = 37.5690\n",
      "(0:4:15) s 130/143, e 1 avg class xent loss = 37.3396\n",
      "(0:4:22) s 140/143, e 1 avg class xent loss = 39.6829\n",
      "Macro P: 9.1616, R: 3.1721, F1: 4.7125\n",
      "(0:4:31) s 0/143, e 2 avg class xent loss = 37.9681\n",
      "================================================================================\n",
      "(0:4:37) s 0/143, e 2 validation avg class xent loss = 40.7604\n",
      "================================================================================\n",
      "(0:4:45) s 10/143, e 2 avg class xent loss = 37.6063\n",
      "(0:4:52) s 20/143, e 2 avg class xent loss = 36.5108\n",
      "(0:5:0) s 30/143, e 2 avg class xent loss = 39.7471\n",
      "(0:5:8) s 40/143, e 2 avg class xent loss = 42.0614\n",
      "(0:5:15) s 50/143, e 2 avg class xent loss = 40.0036\n",
      "================================================================================\n",
      "(0:5:22) s 50/143, e 2 validation avg class xent loss = 41.6087\n",
      "================================================================================\n",
      "(0:5:30) s 60/143, e 2 avg class xent loss = 38.0363\n",
      "(0:5:37) s 70/143, e 2 avg class xent loss = 37.8271\n",
      "(0:5:45) s 80/143, e 2 avg class xent loss = 41.3869\n",
      "(0:5:53) s 90/143, e 2 avg class xent loss = 41.2877\n",
      "(0:6:1) s 100/143, e 2 avg class xent loss = 41.6315\n",
      "================================================================================\n",
      "(0:6:7) s 100/143, e 2 validation avg class xent loss = 42.1039\n",
      "================================================================================\n",
      "(0:6:15) s 110/143, e 2 avg class xent loss = 37.7143\n",
      "(0:6:22) s 120/143, e 2 avg class xent loss = 40.3381\n",
      "(0:6:30) s 130/143, e 2 avg class xent loss = 38.6493\n",
      "(0:6:38) s 140/143, e 2 avg class xent loss = 44.4148\n",
      "Macro P: 4.0324, R: 6.2662, F1: 4.9071\n",
      "(0:6:46) s 0/143, e 3 avg class xent loss = 49.5412\n",
      "================================================================================\n",
      "(0:6:53) s 0/143, e 3 validation avg class xent loss = 41.8254\n",
      "================================================================================\n",
      "(0:7:0) s 10/143, e 3 avg class xent loss = 44.8866\n",
      "(0:7:8) s 20/143, e 3 avg class xent loss = 42.5511\n",
      "(0:7:16) s 30/143, e 3 avg class xent loss = 41.5274\n",
      "(0:7:23) s 40/143, e 3 avg class xent loss = 41.3725\n",
      "(0:7:31) s 50/143, e 3 avg class xent loss = 36.9522\n",
      "================================================================================\n",
      "(0:7:37) s 50/143, e 3 validation avg class xent loss = 42.0132\n",
      "================================================================================\n",
      "(0:7:45) s 60/143, e 3 avg class xent loss = 38.3937\n",
      "(0:7:53) s 70/143, e 3 avg class xent loss = 41.5468\n",
      "(0:8:0) s 80/143, e 3 avg class xent loss = 44.1795\n",
      "(0:8:8) s 90/143, e 3 avg class xent loss = 38.4354\n",
      "(0:8:16) s 100/143, e 3 avg class xent loss = 49.7041\n",
      "================================================================================\n",
      "(0:8:23) s 100/143, e 3 validation avg class xent loss = 42.6486\n",
      "================================================================================\n",
      "(0:8:30) s 110/143, e 3 avg class xent loss = 41.0735\n",
      "(0:8:38) s 120/143, e 3 avg class xent loss = 36.9262\n",
      "(0:8:46) s 130/143, e 3 avg class xent loss = 38.1305\n",
      "(0:8:53) s 140/143, e 3 avg class xent loss = 40.9849\n",
      "Macro P: 3.1055, R: 3.2824, F1: 3.1915\n",
      "(0:9:1) s 0/143, e 4 avg class xent loss = 41.5222\n",
      "================================================================================\n",
      "(0:9:8) s 0/143, e 4 validation avg class xent loss = 42.4989\n",
      "================================================================================\n",
      "(0:9:16) s 10/143, e 4 avg class xent loss = 38.5973\n",
      "(0:9:24) s 20/143, e 4 avg class xent loss = 41.9189\n",
      "(0:9:31) s 30/143, e 4 avg class xent loss = 38.5147\n",
      "(0:9:39) s 40/143, e 4 avg class xent loss = 44.8900\n",
      "(0:9:47) s 50/143, e 4 avg class xent loss = 42.3262\n",
      "================================================================================\n",
      "(0:9:53) s 50/143, e 4 validation avg class xent loss = 43.2595\n",
      "================================================================================\n",
      "(0:10:1) s 60/143, e 4 avg class xent loss = 34.8195\n",
      "(0:10:9) s 70/143, e 4 avg class xent loss = 39.4382\n",
      "(0:10:17) s 80/143, e 4 avg class xent loss = 40.6209\n",
      "(0:10:24) s 90/143, e 4 avg class xent loss = 43.2760\n",
      "(0:10:32) s 100/143, e 4 avg class xent loss = 45.7505\n",
      "================================================================================\n",
      "(0:10:39) s 100/143, e 4 validation avg class xent loss = 43.1728\n",
      "================================================================================\n",
      "(0:10:46) s 110/143, e 4 avg class xent loss = 38.8495\n",
      "(0:10:54) s 120/143, e 4 avg class xent loss = 42.4483\n",
      "(0:11:2) s 130/143, e 4 avg class xent loss = 39.2555\n",
      "(0:11:9) s 140/143, e 4 avg class xent loss = 40.4631\n",
      "Macro P: 3.9093, R: 6.1226, F1: 4.7718\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-3146-13652\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "CYCLE 3\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "===== UNSUPERVISED TRAINING =====\n",
      "(0:0:1) step 0/143, epoch 0 Training Loss = 9.15535 :: 2556.818 phrases/sec :: (0:1:11) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <kitchen> '<X> holds <Y>' <cooker>\n",
      "0: 1.000 : <kitchen> '<X> holds <Y>' <cooker>\n",
      "1: 0.958 : <tapir> '<X> snorgled <Y>' <snout>\n",
      "2: 0.941 : <statute> '<X> covering <Y>' <matter>\n",
      "3: 0.937 : <orienteering> '<X> combines <Y>' <skill>\n",
      "4: 0.936 : <drunk> '<X> uses <Y>' <lamppost>\n",
      "5: 0.931 : <girl> '<X> started <Y>' <blog>\n",
      "6: 0.929 : <student> '<X> provided <Y>' <request>\n",
      "7: 0.928 : <documents> '<X> illustrating <Y>' <history>\n",
      "8: 0.927 : <man> '<X> radiated <Y>' <jolliness>\n",
      "9: 0.927 : <hairdresser> '<X> prefers <Y>' <scissors>\n",
      "10: 0.927 : <engine> '<X> mated <Y>' <concept>\n",
      "11: 0.926 : <painting> '<X> represents <Y>' <meal>\n",
      "12: 0.926 : <book> '<X> traces <Y>' <history>\n",
      "13: 0.926 : <glomeruli> '<X> assist <Y>' <kidneys>\n",
      "14: 0.925 : <contents> '<X> included <Y>' <gender>\n",
      "15: 0.925 : <conclusion> '<X> highlights <Y>' <importance>\n",
      "16: 0.924 : <thermostat> '<X> keeps <Y>' <water>\n",
      "17: 0.924 : <works> '<X> criticize <Y>' <civilization>\n",
      "18: 0.922 : <man> '<X> written <Y>' <work>\n",
      "19: 0.921 : <findings> '<X> point <Y>' <interactions>\n",
      "================================================================================\n",
      "Validation loss: 9.5895\n",
      "(0:0:19) step 10/143, epoch 0 Training Loss = 8.53015 :: 1335.407 phrases/sec :: (0:2:0) hours left\n",
      "(0:0:37) step 20/143, epoch 0 Training Loss = 8.00379 :: 1270.835 phrases/sec :: (0:1:49) hours left\n",
      "(0:0:55) step 30/143, epoch 0 Training Loss = 7.47720 :: 1245.724 phrases/sec :: (0:1:34) hours left\n",
      "(0:1:12) step 40/143, epoch 0 Training Loss = 7.04317 :: 1238.466 phrases/sec :: (0:1:17) hours left\n",
      "(0:1:30) step 50/143, epoch 0 Training Loss = 6.61761 :: 1230.190 phrases/sec :: (0:1:1) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <stable> '<X> of <Y>' <horses>\n",
      "0: 1.000 : <congress> '<X> of <Y>' <nations>\n",
      "1: 1.000 : <crash> '<X> of <Y>' <hippopotami>\n",
      "2: 1.000 : <cabinet> '<X> of <Y>' <names>\n",
      "3: 1.000 : <unit> '<X> of <Y>' <musketeers>\n",
      "4: 1.000 : <pack> '<X> of <Y>' <hounds>\n",
      "5: 1.000 : <division> '<X> of <Y>' <musketeers>\n",
      "6: 1.000 : <round> '<X> of <Y>' <drinks>\n",
      "7: 1.000 : <legion> '<X> of <Y>' <marksmen>\n",
      "8: 1.000 : <heel> '<X> of <Y>' <shoes>\n",
      "9: 1.000 : <chapter> '<X> of <Y>' <canons>\n",
      "10: 1.000 : <cornucopia> '<X> of <Y>' <foods>\n",
      "11: 1.000 : <brigade> '<X> of <Y>' <riflemen>\n",
      "12: 1.000 : <pile> '<X> of <Y>' <junk>\n",
      "13: 1.000 : <hamper> '<X> of <Y>' <goodies>\n",
      "14: 1.000 : <scurry> '<X> of <Y>' <squirrels>\n",
      "15: 1.000 : <rookery> '<X> of <Y>' <herons>\n",
      "16: 1.000 : <stable> '<X> of <Y>' <horses>\n",
      "17: 1.000 : <eyrar> '<X> of <Y>' <swans>\n",
      "18: 1.000 : <nest> '<X> of <Y>' <grass>\n",
      "19: 1.000 : <bevy> '<X> of <Y>' <roebucks>\n",
      "================================================================================\n",
      "Validation loss: 8.7213\n",
      "(0:1:48) step 60/143, epoch 0 Training Loss = 6.20422 :: 1226.628 phrases/sec :: (0:0:43) hours left\n",
      "(0:2:6) step 70/143, epoch 0 Training Loss = 5.90053 :: 1214.611 phrases/sec :: (0:0:26) hours left\n",
      "(0:2:24) step 80/143, epoch 0 Training Loss = 5.49814 :: 1214.383 phrases/sec :: (0:0:9) hours left\n",
      "(0:2:42) step 90/143, epoch 0 Training Loss = 5.21765 :: 1212.139 phrases/sec :: (-1:59:51) hours left\n",
      "(0:3:1) step 100/143, epoch 0 Training Loss = 4.88919 :: 1201.106 phrases/sec :: (-1:59:33) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <media> '<X> makes <Y>' <mistake>\n",
      "0: 1.000 : <media> '<X> makes <Y>' <mistake>\n",
      "1: 1.000 : <caller> '<X> makes <Y>' <mistake>\n",
      "2: 0.992 : <physician> '<X> brought <Y>' <stethoscope>\n",
      "3: 0.971 : <exhibition> '<X> considers <Y>' <origins>\n",
      "4: 0.967 : <playwright> '<X> uses <Y>' <names>\n",
      "5: 0.967 : <owner> '<X> uses <Y>' <information>\n",
      "6: 0.967 : <dolphin> '<X> uses <Y>' <flukes>\n",
      "7: 0.965 : <silver> '<X> <Y>' <ring>\n",
      "8: 0.965 : <pork> '<X> <Y>' <stew>\n",
      "9: 0.965 : <gold> '<X> <Y>' <bracelet>\n",
      "10: 0.965 : <silver> '<X> <Y>' <ring>\n",
      "11: 0.965 : <picture> '<X> <Y>' <frame>\n",
      "12: 0.965 : <diamond> '<X> <Y>' <necklace>\n",
      "13: 0.965 : <door> '<X> <Y>' <handle>\n",
      "14: 0.963 : <caravan> '<X> left <Y>' <depo>\n",
      "15: 0.962 : <steam> '<X> set <Y>' <alarm>\n",
      "16: 0.962 : <girl> '<X> started <Y>' <blog>\n",
      "17: 0.960 : <socialists> '<X> left <Y>' <room>\n",
      "18: 0.959 : <base> '<X> encloses <Y>' <seedpod>\n",
      "19: 0.958 : <surgeon> '<X> cuts <Y>' <hole>\n",
      "================================================================================\n",
      "Validation loss: 7.4673\n",
      "(0:3:22) step 110/143, epoch 0 Training Loss = 4.59137 :: 1181.499 phrases/sec :: (-1:59:15) hours left\n",
      "(0:3:42) step 120/143, epoch 0 Training Loss = 4.33638 :: 1172.012 phrases/sec :: (-1:58:56) hours left\n",
      "(0:4:4) step 130/143, epoch 0 Training Loss = 4.11205 :: 1157.952 phrases/sec :: (-1:58:36) hours left\n",
      "(0:4:25) step 140/143, epoch 0 Training Loss = 3.88683 :: 1144.968 phrases/sec :: (-1:58:17) hours left\n",
      "Macro P: 2.0244, R: 3.9887, F1: 2.6857\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-3289-13652\n",
      "143\n",
      "***** SUPERVISED TRAINING *****\n",
      "(0:0:0) s 0/143, e 0 avg class xent loss = 42.3166\n",
      "================================================================================\n",
      "(0:0:8) s 0/143, e 0 validation avg class xent loss = 43.3803\n",
      "================================================================================\n",
      "(0:0:18) s 10/143, e 0 avg class xent loss = 46.8644\n",
      "(0:0:26) s 20/143, e 0 avg class xent loss = 40.5622\n",
      "(0:0:35) s 30/143, e 0 avg class xent loss = 44.9868\n",
      "(0:0:44) s 40/143, e 0 avg class xent loss = 37.8896\n",
      "(0:0:53) s 50/143, e 0 avg class xent loss = 39.5217\n",
      "================================================================================\n",
      "(0:0:59) s 50/143, e 0 validation avg class xent loss = 43.1226\n",
      "================================================================================\n",
      "(0:1:10) s 60/143, e 0 avg class xent loss = 39.0840\n",
      "(0:1:18) s 70/143, e 0 avg class xent loss = 38.8958\n",
      "(0:1:26) s 80/143, e 0 avg class xent loss = 43.7655\n",
      "(0:1:35) s 90/143, e 0 avg class xent loss = 41.7560\n",
      "(0:1:42) s 100/143, e 0 avg class xent loss = 40.3496\n",
      "================================================================================\n",
      "(0:1:49) s 100/143, e 0 validation avg class xent loss = 43.3772\n",
      "================================================================================\n",
      "(0:1:56) s 110/143, e 0 avg class xent loss = 38.3919\n",
      "(0:2:4) s 120/143, e 0 avg class xent loss = 47.3195\n",
      "(0:2:11) s 130/143, e 0 avg class xent loss = 40.3961\n",
      "(0:2:19) s 140/143, e 0 avg class xent loss = 40.0881\n",
      "Macro P: 5.1658, R: 5.3129, F1: 5.2383\n",
      "(0:2:28) s 0/143, e 1 avg class xent loss = 42.2107\n",
      "================================================================================\n",
      "(0:2:34) s 0/143, e 1 validation avg class xent loss = 42.7027\n",
      "================================================================================\n",
      "(0:2:42) s 10/143, e 1 avg class xent loss = 41.2965\n",
      "(0:2:49) s 20/143, e 1 avg class xent loss = 46.9543\n",
      "(0:2:57) s 30/143, e 1 avg class xent loss = 37.7201\n",
      "(0:3:4) s 40/143, e 1 avg class xent loss = 45.2331\n",
      "(0:3:12) s 50/143, e 1 avg class xent loss = 40.1011\n",
      "================================================================================\n",
      "(0:3:19) s 50/143, e 1 validation avg class xent loss = 42.6383\n",
      "================================================================================\n",
      "(0:3:26) s 60/143, e 1 avg class xent loss = 37.3300\n",
      "(0:3:34) s 70/143, e 1 avg class xent loss = 43.1409\n",
      "(0:3:41) s 80/143, e 1 avg class xent loss = 43.0618\n",
      "(0:3:49) s 90/143, e 1 avg class xent loss = 48.3382\n",
      "(0:3:56) s 100/143, e 1 avg class xent loss = 42.4069\n",
      "================================================================================\n",
      "(0:4:3) s 100/143, e 1 validation avg class xent loss = 42.4844\n",
      "================================================================================\n",
      "(0:4:11) s 110/143, e 1 avg class xent loss = 42.8439\n",
      "(0:4:18) s 120/143, e 1 avg class xent loss = 45.4930\n",
      "(0:4:26) s 130/143, e 1 avg class xent loss = 37.6682\n",
      "(0:4:33) s 140/143, e 1 avg class xent loss = 42.0404\n",
      "Macro P: 3.1017, R: 3.7440, F1: 3.3927\n",
      "(0:4:42) s 0/143, e 2 avg class xent loss = 43.9997\n",
      "================================================================================\n",
      "(0:4:48) s 0/143, e 2 validation avg class xent loss = 42.3030\n",
      "================================================================================\n",
      "(0:4:56) s 10/143, e 2 avg class xent loss = 39.9497\n",
      "(0:5:3) s 20/143, e 2 avg class xent loss = 41.9135\n",
      "(0:5:11) s 30/143, e 2 avg class xent loss = 41.5975\n",
      "(0:5:18) s 40/143, e 2 avg class xent loss = 43.5716\n",
      "(0:5:26) s 50/143, e 2 avg class xent loss = 41.4368\n",
      "================================================================================\n",
      "(0:5:33) s 50/143, e 2 validation avg class xent loss = 42.2009\n",
      "================================================================================\n",
      "(0:5:41) s 60/143, e 2 avg class xent loss = 44.6807\n",
      "(0:5:48) s 70/143, e 2 avg class xent loss = 45.6869\n",
      "(0:5:56) s 80/143, e 2 avg class xent loss = 41.4554\n",
      "(0:6:3) s 90/143, e 2 avg class xent loss = 41.7671\n",
      "(0:6:11) s 100/143, e 2 avg class xent loss = 42.9438\n",
      "================================================================================\n",
      "(0:6:18) s 100/143, e 2 validation avg class xent loss = 42.1080\n",
      "================================================================================\n",
      "(0:6:25) s 110/143, e 2 avg class xent loss = 36.7330\n",
      "(0:6:33) s 120/143, e 2 avg class xent loss = 42.8677\n",
      "(0:6:40) s 130/143, e 2 avg class xent loss = 43.0715\n",
      "(0:6:48) s 140/143, e 2 avg class xent loss = 43.7273\n",
      "Macro P: 2.9105, R: 7.5490, F1: 4.2012\n",
      "(0:6:56) s 0/143, e 3 avg class xent loss = 41.8978\n",
      "================================================================================\n",
      "(0:7:3) s 0/143, e 3 validation avg class xent loss = 42.1513\n",
      "================================================================================\n",
      "(0:7:10) s 10/143, e 3 avg class xent loss = 40.2783\n",
      "(0:7:18) s 20/143, e 3 avg class xent loss = 47.6617\n",
      "(0:7:25) s 30/143, e 3 avg class xent loss = 40.9884\n",
      "(0:7:33) s 40/143, e 3 avg class xent loss = 49.6258\n",
      "(0:7:41) s 50/143, e 3 avg class xent loss = 45.1252\n",
      "================================================================================\n",
      "(0:7:47) s 50/143, e 3 validation avg class xent loss = 42.3723\n",
      "================================================================================\n",
      "(0:7:55) s 60/143, e 3 avg class xent loss = 36.9016\n",
      "(0:8:2) s 70/143, e 3 avg class xent loss = 42.3615\n",
      "(0:8:10) s 80/143, e 3 avg class xent loss = 40.9287\n",
      "(0:8:18) s 90/143, e 3 avg class xent loss = 41.2031\n",
      "(0:8:25) s 100/143, e 3 avg class xent loss = 38.9038\n",
      "================================================================================\n",
      "(0:8:32) s 100/143, e 3 validation avg class xent loss = 42.0775\n",
      "================================================================================\n",
      "(0:8:39) s 110/143, e 3 avg class xent loss = 44.8780\n",
      "(0:8:47) s 120/143, e 3 avg class xent loss = 39.1970\n",
      "(0:8:54) s 130/143, e 3 avg class xent loss = 38.9728\n",
      "(0:9:2) s 140/143, e 3 avg class xent loss = 44.8363\n",
      "Macro P: 2.2433, R: 4.4735, F1: 2.9882\n",
      "(0:9:10) s 0/143, e 4 avg class xent loss = 41.1208\n",
      "================================================================================\n",
      "(0:9:16) s 0/143, e 4 validation avg class xent loss = 42.2659\n",
      "================================================================================\n",
      "(0:9:24) s 10/143, e 4 avg class xent loss = 43.2722\n",
      "(0:9:34) s 20/143, e 4 avg class xent loss = 45.4104\n",
      "(0:9:46) s 30/143, e 4 avg class xent loss = 39.0182\n",
      "(0:9:56) s 40/143, e 4 avg class xent loss = 43.1885\n",
      "(0:10:4) s 50/143, e 4 avg class xent loss = 41.5689\n",
      "================================================================================\n",
      "(0:10:10) s 50/143, e 4 validation avg class xent loss = 42.5245\n",
      "================================================================================\n",
      "(0:10:18) s 60/143, e 4 avg class xent loss = 34.1939\n",
      "(0:10:26) s 70/143, e 4 avg class xent loss = 48.0965\n",
      "(0:10:33) s 80/143, e 4 avg class xent loss = 43.3419\n",
      "(0:10:41) s 90/143, e 4 avg class xent loss = 45.6122\n",
      "(0:10:49) s 100/143, e 4 avg class xent loss = 43.3937\n",
      "================================================================================\n",
      "(0:10:55) s 100/143, e 4 validation avg class xent loss = 42.0009\n",
      "================================================================================\n",
      "(0:11:3) s 110/143, e 4 avg class xent loss = 37.4411\n",
      "(0:11:11) s 120/143, e 4 avg class xent loss = 40.0891\n",
      "(0:11:18) s 130/143, e 4 avg class xent loss = 42.6506\n",
      "(0:11:26) s 140/143, e 4 avg class xent loss = 43.6897\n",
      "Macro P: 4.4126, R: 5.8768, F1: 5.0405\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-3289-14362\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "CYCLE 4\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "===== UNSUPERVISED TRAINING =====\n",
      "(0:0:1) step 0/143, epoch 0 Training Loss = 8.71764 :: 2423.355 phrases/sec :: (0:1:14) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <results> '<X> presented in <Y>' <report>\n",
      "0: 1.000 : <results> '<X> presented in <Y>' <report>\n",
      "1: 1.000 : <standards> '<X> criticised in <Y>' <report>\n",
      "2: 1.000 : <identifier> '<X> stored in <Y>' <cookie>\n",
      "3: 1.000 : <yarn> '<X> stored in <Y>' <bins>\n",
      "4: 1.000 : <group> '<X> stored in <Y>' <refrigerator>\n",
      "5: 1.000 : <record> '<X> documented in <Y>' <book>\n",
      "6: 1.000 : <guns> '<X> locked in <Y>' <room>\n",
      "7: 1.000 : <conclusions> '<X> set in <Y>' <document>\n",
      "8: 1.000 : <letter> '<X> contained in <Y>' <envelope>\n",
      "9: 1.000 : <sample> '<X> contained in <Y>' <cup>\n",
      "10: 1.000 : <cover> '<X> analysed in <Y>' <article>\n",
      "11: 1.000 : <methods> '<X> analysed in <Y>' <section>\n",
      "12: 1.000 : <converter> '<X> manufactured in <Y>' <process>\n",
      "13: 1.000 : <bomb> '<X> used in <Y>' <diplomacy>\n",
      "14: 1.000 : <market> '<X> rooted in <Y>' <structure>\n",
      "15: 0.995 : <linoleum> '<X> cleaning in <Y>' <kitchen>\n",
      "16: 0.994 : <body> '<X> in <Y>' <casket>\n",
      "17: 0.994 : <qualifications> '<X> in <Y>' <care>\n",
      "18: 0.994 : <ceremony> '<X> hold in <Y>' <building>\n",
      "19: 0.994 : <tooth> '<X> implanted in <Y>' <eye>\n",
      "================================================================================\n",
      "Validation loss: 9.0339\n",
      "(0:0:20) step 10/143, epoch 0 Training Loss = 8.11040 :: 1235.792 phrases/sec :: (0:2:10) hours left\n",
      "(0:0:38) step 20/143, epoch 0 Training Loss = 7.58130 :: 1223.097 phrases/sec :: (0:1:54) hours left\n",
      "(0:0:56) step 30/143, epoch 0 Training Loss = 7.10563 :: 1207.159 phrases/sec :: (0:1:38) hours left\n",
      "(0:1:14) step 40/143, epoch 0 Training Loss = 6.63591 :: 1193.175 phrases/sec :: (0:1:21) hours left\n",
      "(0:1:32) step 50/143, epoch 0 Training Loss = 6.26197 :: 1195.964 phrases/sec :: (0:1:3) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <flight> '<X> of <Y>' <aircrafts>\n",
      "0: 1.000 : <brotherhood> '<X> of <Y>' <rogues>\n",
      "1: 1.000 : <handful> '<X> of <Y>' <images>\n",
      "2: 1.000 : <squad> '<X> of <Y>' <policemen>\n",
      "3: 1.000 : <charm> '<X> of <Y>' <goldfinches>\n",
      "4: 1.000 : <phalanx> '<X> of <Y>' <umbrellas>\n",
      "5: 1.000 : <chin> '<X> of <Y>' <rockfish>\n",
      "6: 1.000 : <maze> '<X> of <Y>' <jurisdictions>\n",
      "7: 1.000 : <wheel> '<X> of <Y>' <panel>\n",
      "8: 1.000 : <devision> '<X> of <Y>' <crossbowmen>\n",
      "9: 1.000 : <minority> '<X> of <Y>' <physicians>\n",
      "10: 1.000 : <flight> '<X> of <Y>' <aircrafts>\n",
      "11: 1.000 : <fit> '<X> of <Y>' <jacket>\n",
      "12: 1.000 : <indicator> '<X> of <Y>' <transmitter>\n",
      "13: 1.000 : <bore> '<X> of <Y>' <trumpet>\n",
      "14: 1.000 : <rope> '<X> of <Y>' <swing>\n",
      "15: 1.000 : <bratpack> '<X> of <Y>' <pornographers>\n",
      "16: 1.000 : <huddle> '<X> of <Y>' <photographers>\n",
      "17: 1.000 : <unkindness> '<X> of <Y>' <ravens>\n",
      "18: 1.000 : <weather> '<X> is topic of <Y>' <conversation>\n",
      "19: 1.000 : <relationship> '<X> is subject of <Y>' <controversy>\n",
      "================================================================================\n",
      "Validation loss: 8.0876\n",
      "(0:1:51) step 60/143, epoch 0 Training Loss = 5.91560 :: 1191.557 phrases/sec :: (0:0:45) hours left\n",
      "(0:2:7) step 70/143, epoch 0 Training Loss = 5.51786 :: 1198.545 phrases/sec :: (0:0:27) hours left\n",
      "(0:2:25) step 80/143, epoch 0 Training Loss = 5.22957 :: 1199.045 phrases/sec :: (0:0:9) hours left\n",
      "(0:2:42) step 90/143, epoch 0 Training Loss = 4.93964 :: 1201.529 phrases/sec :: (-1:59:52) hours left\n",
      "(0:3:0) step 100/143, epoch 0 Training Loss = 4.59909 :: 1204.711 phrases/sec :: (-1:59:34) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <trauma> '<X> caused by <Y>' <arrival>\n",
      "0: 1.000 : <fevers> '<X> caused by <Y>' <colds>\n",
      "1: 1.000 : <trauma> '<X> caused by <Y>' <arrival>\n",
      "2: 1.000 : <frustration> '<X> caused by <Y>' <system>\n",
      "3: 0.990 : <sound> '<X> produced by <Y>' <drum>\n",
      "4: 0.988 : <meal> '<X> cooked by <Y>' <chef>\n",
      "5: 0.988 : <conflict> '<X> of interest created by <Y>' <charges>\n",
      "6: 0.988 : <problem> '<X> caused by <Y>' <state>\n",
      "7: 0.988 : <tools> '<X> developed by <Y>' <team>\n",
      "8: 0.985 : <inflammation> '<X> caused by <Y>' <growth>\n",
      "9: 0.985 : <cancer> '<X> caused by <Y>' <infection>\n",
      "10: 0.985 : <collapse> '<X> caused by <Y>' <consumers>\n",
      "11: 0.985 : <deficits> '<X> caused by <Y>' <people>\n",
      "12: 0.985 : <earthquake> '<X> caused by <Y>' <rupture>\n",
      "13: 0.985 : <unemployment> '<X> caused by <Y>' <people>\n",
      "14: 0.985 : <harm> '<X> caused by <Y>' <system>\n",
      "15: 0.985 : <injury> '<X> caused by <Y>' <intoxication>\n",
      "16: 0.985 : <problems> '<X> caused by <Y>' <overflows>\n",
      "17: 0.983 : <cancers> '<X> head of portion caused by <Y>' <papillomavirus>\n",
      "18: 0.983 : <grief> '<X> experiencing after <Y>' <death>\n",
      "19: 0.982 : <injection> '<X> receiving after fell along with thousands of <Y>' <pupils>\n",
      "================================================================================\n",
      "Validation loss: 6.9625\n",
      "(0:3:18) step 110/143, epoch 0 Training Loss = 4.35743 :: 1203.857 phrases/sec :: (-1:59:16) hours left\n",
      "(0:3:35) step 120/143, epoch 0 Training Loss = 4.12336 :: 1204.833 phrases/sec :: (-1:58:58) hours left\n",
      "(0:3:53) step 130/143, epoch 0 Training Loss = 3.88022 :: 1204.663 phrases/sec :: (-1:58:40) hours left\n",
      "(0:4:11) step 140/143, epoch 0 Training Loss = 3.64466 :: 1207.256 phrases/sec :: (-1:58:23) hours left\n",
      "Macro P: 5.6957, R: 4.2033, F1: 4.8370\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-3432-14362\n",
      "143\n",
      "***** SUPERVISED TRAINING *****\n",
      "(0:0:0) s 0/143, e 0 avg class xent loss = 44.2828\n",
      "================================================================================\n",
      "(0:0:7) s 0/143, e 0 validation avg class xent loss = 40.2877\n",
      "================================================================================\n",
      "(0:0:15) s 10/143, e 0 avg class xent loss = 49.1179\n",
      "(0:0:22) s 20/143, e 0 avg class xent loss = 41.6279\n",
      "(0:0:30) s 30/143, e 0 avg class xent loss = 36.3359\n",
      "(0:0:37) s 40/143, e 0 avg class xent loss = 42.0533\n",
      "(0:0:45) s 50/143, e 0 avg class xent loss = 44.3743\n",
      "================================================================================\n",
      "(0:0:52) s 50/143, e 0 validation avg class xent loss = 41.1640\n",
      "================================================================================\n",
      "(0:0:59) s 60/143, e 0 avg class xent loss = 37.9359\n",
      "(0:1:7) s 70/143, e 0 avg class xent loss = 42.9972\n",
      "(0:1:14) s 80/143, e 0 avg class xent loss = 40.3323\n",
      "(0:1:22) s 90/143, e 0 avg class xent loss = 39.6891\n",
      "(0:1:30) s 100/143, e 0 avg class xent loss = 46.1936\n",
      "================================================================================\n",
      "(0:1:36) s 100/143, e 0 validation avg class xent loss = 41.3680\n",
      "================================================================================\n",
      "(0:1:44) s 110/143, e 0 avg class xent loss = 41.2093\n",
      "(0:1:52) s 120/143, e 0 avg class xent loss = 39.8548\n",
      "(0:1:59) s 130/143, e 0 avg class xent loss = 39.8594\n",
      "(0:2:7) s 140/143, e 0 avg class xent loss = 42.2057\n",
      "Macro P: 4.7897, R: 5.0967, F1: 4.9384\n",
      "(0:2:15) s 0/143, e 1 avg class xent loss = 40.2279\n",
      "================================================================================\n",
      "(0:2:22) s 0/143, e 1 validation avg class xent loss = 41.9042\n",
      "================================================================================\n",
      "(0:2:30) s 10/143, e 1 avg class xent loss = 42.2739\n",
      "(0:2:37) s 20/143, e 1 avg class xent loss = 43.8877\n",
      "(0:2:45) s 30/143, e 1 avg class xent loss = 37.1741\n",
      "(0:2:52) s 40/143, e 1 avg class xent loss = 45.1875\n",
      "(0:3:0) s 50/143, e 1 avg class xent loss = 40.7286\n",
      "================================================================================\n",
      "(0:3:7) s 50/143, e 1 validation avg class xent loss = 41.8397\n",
      "================================================================================\n",
      "(0:3:14) s 60/143, e 1 avg class xent loss = 38.7605\n",
      "(0:3:22) s 70/143, e 1 avg class xent loss = 40.1694\n",
      "(0:3:30) s 80/143, e 1 avg class xent loss = 40.8758\n",
      "(0:3:37) s 90/143, e 1 avg class xent loss = 44.2750\n",
      "(0:3:45) s 100/143, e 1 avg class xent loss = 42.3654\n",
      "================================================================================\n",
      "(0:3:51) s 100/143, e 1 validation avg class xent loss = 42.0383\n",
      "================================================================================\n",
      "(0:3:59) s 110/143, e 1 avg class xent loss = 35.1469\n",
      "(0:4:7) s 120/143, e 1 avg class xent loss = 42.4051\n",
      "(0:4:14) s 130/143, e 1 avg class xent loss = 35.7686\n",
      "(0:4:22) s 140/143, e 1 avg class xent loss = 39.0833\n",
      "Macro P: 5.5004, R: 4.4333, F1: 4.9095\n",
      "(0:4:30) s 0/143, e 2 avg class xent loss = 41.6897\n",
      "================================================================================\n",
      "(0:4:37) s 0/143, e 2 validation avg class xent loss = 41.9310\n",
      "================================================================================\n",
      "(0:4:45) s 10/143, e 2 avg class xent loss = 42.0453\n",
      "(0:4:52) s 20/143, e 2 avg class xent loss = 43.1114\n",
      "(0:5:0) s 30/143, e 2 avg class xent loss = 40.9969\n",
      "(0:5:8) s 40/143, e 2 avg class xent loss = 40.5379\n",
      "(0:5:15) s 50/143, e 2 avg class xent loss = 34.8387\n",
      "================================================================================\n",
      "(0:5:22) s 50/143, e 2 validation avg class xent loss = 41.6874\n",
      "================================================================================\n",
      "(0:5:29) s 60/143, e 2 avg class xent loss = 37.5251\n",
      "(0:5:37) s 70/143, e 2 avg class xent loss = 43.6026\n",
      "(0:5:45) s 80/143, e 2 avg class xent loss = 47.5249\n",
      "(0:5:52) s 90/143, e 2 avg class xent loss = 41.4978\n",
      "(0:6:0) s 100/143, e 2 avg class xent loss = 44.6092\n",
      "================================================================================\n",
      "(0:6:7) s 100/143, e 2 validation avg class xent loss = 42.0993\n",
      "================================================================================\n",
      "(0:6:15) s 110/143, e 2 avg class xent loss = 37.9627\n",
      "(0:6:22) s 120/143, e 2 avg class xent loss = 41.3083\n",
      "(0:6:30) s 130/143, e 2 avg class xent loss = 40.4125\n",
      "(0:6:38) s 140/143, e 2 avg class xent loss = 40.1840\n",
      "Macro P: 8.4428, R: 7.6056, F1: 8.0023\n",
      "(0:6:46) s 0/143, e 3 avg class xent loss = 42.2473\n",
      "================================================================================\n",
      "(0:6:52) s 0/143, e 3 validation avg class xent loss = 42.3997\n",
      "================================================================================\n",
      "(0:7:0) s 10/143, e 3 avg class xent loss = 40.1390\n",
      "(0:7:8) s 20/143, e 3 avg class xent loss = 40.8564\n",
      "(0:7:16) s 30/143, e 3 avg class xent loss = 40.1362\n",
      "(0:7:23) s 40/143, e 3 avg class xent loss = 44.0803\n",
      "(0:7:31) s 50/143, e 3 avg class xent loss = 37.5694\n",
      "================================================================================\n",
      "(0:7:37) s 50/143, e 3 validation avg class xent loss = 42.6002\n",
      "================================================================================\n",
      "(0:7:45) s 60/143, e 3 avg class xent loss = 39.3592\n",
      "(0:7:52) s 70/143, e 3 avg class xent loss = 39.5458\n",
      "(0:8:0) s 80/143, e 3 avg class xent loss = 43.6924\n",
      "(0:8:8) s 90/143, e 3 avg class xent loss = 40.7234\n",
      "(0:8:16) s 100/143, e 3 avg class xent loss = 46.0306\n",
      "================================================================================\n",
      "(0:8:22) s 100/143, e 3 validation avg class xent loss = 42.9395\n",
      "================================================================================\n",
      "(0:8:30) s 110/143, e 3 avg class xent loss = 42.9312\n",
      "(0:8:37) s 120/143, e 3 avg class xent loss = 43.3051\n",
      "(0:8:45) s 130/143, e 3 avg class xent loss = 45.8585\n",
      "(0:8:53) s 140/143, e 3 avg class xent loss = 39.5436\n",
      "Macro P: 8.0599, R: 5.6205, F1: 6.6227\n",
      "(0:9:1) s 0/143, e 4 avg class xent loss = 41.9194\n",
      "================================================================================\n",
      "(0:9:8) s 0/143, e 4 validation avg class xent loss = 42.7228\n",
      "================================================================================\n",
      "(0:9:15) s 10/143, e 4 avg class xent loss = 46.4694\n",
      "(0:9:23) s 20/143, e 4 avg class xent loss = 41.9357\n",
      "(0:9:31) s 30/143, e 4 avg class xent loss = 36.8855\n",
      "(0:9:38) s 40/143, e 4 avg class xent loss = 49.0174\n",
      "(0:9:46) s 50/143, e 4 avg class xent loss = 40.8028\n",
      "================================================================================\n",
      "(0:9:53) s 50/143, e 4 validation avg class xent loss = 41.8227\n",
      "================================================================================\n",
      "(0:10:0) s 60/143, e 4 avg class xent loss = 38.5156\n",
      "(0:10:8) s 70/143, e 4 avg class xent loss = 37.9148\n",
      "(0:10:16) s 80/143, e 4 avg class xent loss = 37.1151\n",
      "(0:10:23) s 90/143, e 4 avg class xent loss = 46.2391\n",
      "(0:10:31) s 100/143, e 4 avg class xent loss = 41.1446\n",
      "================================================================================\n",
      "(0:10:38) s 100/143, e 4 validation avg class xent loss = 43.0235\n",
      "================================================================================\n",
      "(0:10:45) s 110/143, e 4 avg class xent loss = 39.2850\n",
      "(0:10:53) s 120/143, e 4 avg class xent loss = 45.2673\n",
      "(0:11:0) s 130/143, e 4 avg class xent loss = 43.0001\n",
      "(0:11:8) s 140/143, e 4 avg class xent loss = 38.3951\n",
      "Macro P: 2.0036, R: 4.9550, F1: 2.8534\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-3432-15072\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "CYCLE 5\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "===== UNSUPERVISED TRAINING =====\n",
      "(0:0:1) step 0/143, epoch 0 Training Loss = 8.53424 :: 2250.542 phrases/sec :: (0:1:20) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <catastrophe> '<X> narrated through <Y>' <metaphor>\n",
      "0: 1.000 : <catastrophe> '<X> narrated through <Y>' <metaphor>\n",
      "1: 1.000 : <peeler> '<X> glides through <Y>' <foods>\n",
      "2: 1.000 : <governments> '<X> resolved through <Y>' <subsidization>\n",
      "3: 1.000 : <parties> '<X> resolved through <Y>' <decree>\n",
      "4: 0.994 : <resetting> '<X> through <Y>' <signal>\n",
      "5: 0.949 : <people> '<X> described through <Y>' <caricatures>\n",
      "6: 0.919 : <receipt> '<X> through mail <Y>' <air>\n",
      "7: 0.780 : <grenade> '<X> was inside <Y>' <tin>\n",
      "8: 0.779 : <patient> '<X> sawed using <Y>' <toothbrush>\n",
      "9: 0.779 : <supplies> '<X> regulate using <Y>' <regulator>\n",
      "10: 0.747 : <documents> '<X> illustrating <Y>' <history>\n",
      "11: 0.725 : <playwright> '<X> uses <Y>' <names>\n",
      "12: 0.725 : <owner> '<X> uses <Y>' <information>\n",
      "13: 0.725 : <dolphin> '<X> uses <Y>' <flukes>\n",
      "14: 0.724 : <tapir> '<X> snorgled <Y>' <snout>\n",
      "15: 0.722 : <customer> '<X> picks chooses by using <Y>' <podcasting>\n",
      "16: 0.722 : <antacids> '<X> work by using <Y>' <base>\n",
      "17: 0.721 : <cleaner> '<X> retains by using <Y>' <water>\n",
      "18: 0.720 : <researchers> '<X> formed mold using <Y>' <process>\n",
      "19: 0.716 : <kitchen> '<X> holds <Y>' <cooker>\n",
      "================================================================================\n",
      "Validation loss: 8.8460\n",
      "(0:0:19) step 10/143, epoch 0 Training Loss = 7.93616 :: 1342.213 phrases/sec :: (0:1:59) hours left\n",
      "(0:0:37) step 20/143, epoch 0 Training Loss = 7.45550 :: 1275.573 phrases/sec :: (0:1:49) hours left\n",
      "(0:0:54) step 30/143, epoch 0 Training Loss = 6.98727 :: 1253.206 phrases/sec :: (0:1:34) hours left\n",
      "(0:1:12) step 40/143, epoch 0 Training Loss = 6.54176 :: 1239.345 phrases/sec :: (0:1:18) hours left\n",
      "(0:1:30) step 50/143, epoch 0 Training Loss = 6.14655 :: 1230.195 phrases/sec :: (0:1:1) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <measures> '<X> published with regard to <Y>' <procedures>\n",
      "0: 1.000 : <measures> '<X> published with regard to <Y>' <procedures>\n",
      "1: 1.000 : <disease> '<X> spreads to <Y>' <dogs>\n",
      "2: 0.997 : <plight> '<X> put to <Y>' <dwellers>\n",
      "3: 0.985 : <television> '<X> network devoted to <Y>' <arts>\n",
      "4: 0.985 : <funds> '<X> donated to <Y>' <candidate>\n",
      "5: 0.984 : <cargo> '<X> shipped to <Y>' <factory>\n",
      "6: 0.982 : <comma> '<X> to changed by <Y>' <scribe>\n",
      "7: 0.980 : <complaints> '<X> take to <Y>' <door>\n",
      "8: 0.980 : <report> '<X> released to <Y>' <public>\n",
      "9: 0.976 : <infertility> '<X> on passed to <Y>' <generations>\n",
      "10: 0.974 : <special> '<X> dedicated to explaining <Y>' <term>\n",
      "11: 0.971 : <answers> '<X> to <Y>' <website>\n",
      "12: 0.971 : <guide> '<X> to <Y>' <resources>\n",
      "13: 0.969 : <letters> '<X> sent to <Y>' <government>\n",
      "14: 0.965 : <tutorial> '<X> introduced to <Y>' <methods>\n",
      "15: 0.962 : <hay> '<X> bins to delivered is put inside part of <Y>' <barn>\n",
      "16: 0.958 : <parents> '<X> wind accompanying to <Y>' <factory>\n",
      "17: 0.957 : <statute> '<X> applied to <Y>' <dominions>\n",
      "18: 0.954 : <injection> '<X> receiving after fell along with thousands of <Y>' <pupils>\n",
      "19: 0.951 : <electroscope> '<X> of top consists of <Y>' <plate>\n",
      "================================================================================\n",
      "Validation loss: 8.1892\n",
      "(0:1:49) step 60/143, epoch 0 Training Loss = 5.77704 :: 1216.471 phrases/sec :: (0:0:43) hours left\n",
      "(0:2:7) step 70/143, epoch 0 Training Loss = 5.45341 :: 1212.804 phrases/sec :: (0:0:26) hours left\n",
      "(0:2:25) step 80/143, epoch 0 Training Loss = 5.14260 :: 1209.274 phrases/sec :: (0:0:9) hours left\n",
      "(0:2:42) step 90/143, epoch 0 Training Loss = 4.85261 :: 1211.084 phrases/sec :: (-1:59:51) hours left\n",
      "(0:3:0) step 100/143, epoch 0 Training Loss = 4.55529 :: 1207.744 phrases/sec :: (-1:59:34) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <man> '<X> put <Y>' <monument>\n",
      "0: 1.000 : <man> '<X> put <Y>' <monument>\n",
      "1: 0.999 : <geology> '<X> comprises <Y>' <granite>\n",
      "2: 0.999 : <campus> '<X> comprises <Y>' <buildings>\n",
      "3: 0.999 : <resort> '<X> comprises <Y>' <hotel>\n",
      "4: 0.999 : <protesters> '<X> chose <Y>' <road>\n",
      "5: 0.999 : <lady> '<X> made <Y>' <photocopies>\n",
      "6: 0.999 : <reindeer> '<X> made <Y>' <debut>\n",
      "7: 0.999 : <troops> '<X> made <Y>' <incursion>\n",
      "8: 0.998 : <book> '<X> traces <Y>' <history>\n",
      "9: 0.998 : <plans> '<X> take <Y>' <needs>\n",
      "10: 0.998 : <man> '<X> grew <Y>' <ear>\n",
      "11: 0.998 : <person> '<X> makes <Y>' <will>\n",
      "12: 0.998 : <crew> '<X> dug <Y>' <trench>\n",
      "13: 0.997 : <shoemaker> '<X> invented <Y>' <machine>\n",
      "14: 0.997 : <thermostat> '<X> keeps <Y>' <water>\n",
      "15: 0.997 : <motor> '<X> makes <Y>' <sound>\n",
      "16: 0.997 : <painting> '<X> represents <Y>' <meal>\n",
      "17: 0.996 : <regiment> '<X> composed <Y>' <reserve>\n",
      "18: 0.996 : <builder> '<X> mortgaged <Y>' <land>\n",
      "19: 0.995 : <findings> '<X> point <Y>' <interactions>\n",
      "================================================================================\n",
      "Validation loss: 7.0760\n",
      "(0:3:18) step 110/143, epoch 0 Training Loss = 4.28778 :: 1207.518 phrases/sec :: (-1:59:16) hours left\n",
      "(0:3:35) step 120/143, epoch 0 Training Loss = 4.08441 :: 1208.240 phrases/sec :: (-1:58:58) hours left\n",
      "(0:3:53) step 130/143, epoch 0 Training Loss = 3.82854 :: 1209.605 phrases/sec :: (-1:58:40) hours left\n",
      "(0:4:11) step 140/143, epoch 0 Training Loss = 3.58689 :: 1208.980 phrases/sec :: (-1:58:23) hours left\n",
      "Macro P: 3.3859, R: 2.3112, F1: 2.7472\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-3575-15072\n",
      "143\n",
      "***** SUPERVISED TRAINING *****\n",
      "(0:0:0) s 0/143, e 0 avg class xent loss = 36.6853\n",
      "================================================================================\n",
      "(0:0:7) s 0/143, e 0 validation avg class xent loss = 42.1014\n",
      "================================================================================\n",
      "(0:0:15) s 10/143, e 0 avg class xent loss = 37.8745\n",
      "(0:0:22) s 20/143, e 0 avg class xent loss = 47.4963\n",
      "(0:0:30) s 30/143, e 0 avg class xent loss = 37.6627\n",
      "(0:0:37) s 40/143, e 0 avg class xent loss = 46.7550\n",
      "(0:0:45) s 50/143, e 0 avg class xent loss = 40.5629\n",
      "================================================================================\n",
      "(0:0:52) s 50/143, e 0 validation avg class xent loss = 42.0477\n",
      "================================================================================\n",
      "(0:0:59) s 60/143, e 0 avg class xent loss = 39.3803\n",
      "(0:1:7) s 70/143, e 0 avg class xent loss = 39.1794\n",
      "(0:1:15) s 80/143, e 0 avg class xent loss = 40.5392\n",
      "(0:1:22) s 90/143, e 0 avg class xent loss = 41.3031\n",
      "(0:1:30) s 100/143, e 0 avg class xent loss = 43.9522\n",
      "================================================================================\n",
      "(0:1:37) s 100/143, e 0 validation avg class xent loss = 43.0659\n",
      "================================================================================\n",
      "(0:1:44) s 110/143, e 0 avg class xent loss = 41.2228\n",
      "(0:1:52) s 120/143, e 0 avg class xent loss = 44.8249\n",
      "(0:2:0) s 130/143, e 0 avg class xent loss = 36.7120\n",
      "(0:2:7) s 140/143, e 0 avg class xent loss = 39.7007\n",
      "Macro P: 2.6656, R: 4.3634, F1: 3.3095\n",
      "(0:2:15) s 0/143, e 1 avg class xent loss = 43.8671\n",
      "================================================================================\n",
      "(0:2:22) s 0/143, e 1 validation avg class xent loss = 42.5865\n",
      "================================================================================\n",
      "(0:2:30) s 10/143, e 1 avg class xent loss = 42.7752\n",
      "(0:2:37) s 20/143, e 1 avg class xent loss = 43.3155\n",
      "(0:2:45) s 30/143, e 1 avg class xent loss = 41.2811\n",
      "(0:2:53) s 40/143, e 1 avg class xent loss = 46.8934\n",
      "(0:3:0) s 50/143, e 1 avg class xent loss = 39.5254\n",
      "================================================================================\n",
      "(0:3:7) s 50/143, e 1 validation avg class xent loss = 42.7866\n",
      "================================================================================\n",
      "(0:3:14) s 60/143, e 1 avg class xent loss = 38.8710\n",
      "(0:3:22) s 70/143, e 1 avg class xent loss = 39.1485\n",
      "(0:3:30) s 80/143, e 1 avg class xent loss = 40.6892\n",
      "(0:3:37) s 90/143, e 1 avg class xent loss = 36.6001\n",
      "(0:3:45) s 100/143, e 1 avg class xent loss = 40.3478\n",
      "================================================================================\n",
      "(0:3:52) s 100/143, e 1 validation avg class xent loss = 42.6597\n",
      "================================================================================\n",
      "(0:4:0) s 110/143, e 1 avg class xent loss = 36.3116\n",
      "(0:4:7) s 120/143, e 1 avg class xent loss = 44.0177\n",
      "(0:4:15) s 130/143, e 1 avg class xent loss = 37.1708\n",
      "(0:4:22) s 140/143, e 1 avg class xent loss = 39.4646\n",
      "Macro P: 1.5132, R: 2.0474, F1: 1.7402\n",
      "(0:4:31) s 0/143, e 2 avg class xent loss = 38.7634\n",
      "================================================================================\n",
      "(0:4:37) s 0/143, e 2 validation avg class xent loss = 42.9750\n",
      "================================================================================\n",
      "(0:4:45) s 10/143, e 2 avg class xent loss = 39.2597\n",
      "(0:4:53) s 20/143, e 2 avg class xent loss = 45.6672\n",
      "(0:5:0) s 30/143, e 2 avg class xent loss = 40.9497\n",
      "(0:5:8) s 40/143, e 2 avg class xent loss = 42.3509\n",
      "(0:5:15) s 50/143, e 2 avg class xent loss = 39.7076\n",
      "================================================================================\n",
      "(0:5:22) s 50/143, e 2 validation avg class xent loss = 43.0453\n",
      "================================================================================\n",
      "(0:5:30) s 60/143, e 2 avg class xent loss = 35.6051\n",
      "(0:5:37) s 70/143, e 2 avg class xent loss = 40.6656\n",
      "(0:5:45) s 80/143, e 2 avg class xent loss = 41.5643\n",
      "(0:5:52) s 90/143, e 2 avg class xent loss = 39.2561\n",
      "(0:6:0) s 100/143, e 2 avg class xent loss = 39.0950\n",
      "================================================================================\n",
      "(0:6:7) s 100/143, e 2 validation avg class xent loss = 41.7663\n",
      "================================================================================\n",
      "(0:6:15) s 110/143, e 2 avg class xent loss = 37.9231\n",
      "(0:6:22) s 120/143, e 2 avg class xent loss = 41.4873\n",
      "(0:6:30) s 130/143, e 2 avg class xent loss = 34.4002\n",
      "(0:6:38) s 140/143, e 2 avg class xent loss = 39.8604\n",
      "Macro P: 3.4424, R: 3.6011, F1: 3.5200\n",
      "(0:6:46) s 0/143, e 3 avg class xent loss = 42.8378\n",
      "================================================================================\n",
      "(0:6:52) s 0/143, e 3 validation avg class xent loss = 40.8987\n",
      "================================================================================\n",
      "(0:7:0) s 10/143, e 3 avg class xent loss = 46.4174\n",
      "(0:7:8) s 20/143, e 3 avg class xent loss = 42.3410\n",
      "(0:7:16) s 30/143, e 3 avg class xent loss = 37.4621\n",
      "(0:7:23) s 40/143, e 3 avg class xent loss = 44.3222\n",
      "(0:7:31) s 50/143, e 3 avg class xent loss = 41.9693\n",
      "================================================================================\n",
      "(0:7:38) s 50/143, e 3 validation avg class xent loss = 42.3500\n",
      "================================================================================\n",
      "(0:7:45) s 60/143, e 3 avg class xent loss = 36.9292\n",
      "(0:7:53) s 70/143, e 3 avg class xent loss = 37.7442\n",
      "(0:8:0) s 80/143, e 3 avg class xent loss = 41.1059\n",
      "(0:8:8) s 90/143, e 3 avg class xent loss = 44.1890\n",
      "(0:8:16) s 100/143, e 3 avg class xent loss = 40.5070\n",
      "================================================================================\n",
      "(0:8:22) s 100/143, e 3 validation avg class xent loss = 42.4014\n",
      "================================================================================\n",
      "(0:8:30) s 110/143, e 3 avg class xent loss = 35.9487\n",
      "(0:8:38) s 120/143, e 3 avg class xent loss = 47.9846\n",
      "(0:8:45) s 130/143, e 3 avg class xent loss = 36.0767\n",
      "(0:8:53) s 140/143, e 3 avg class xent loss = 43.9310\n",
      "Macro P: 2.0240, R: 3.5260, F1: 2.5718\n",
      "(0:9:1) s 0/143, e 4 avg class xent loss = 43.2815\n",
      "================================================================================\n",
      "(0:9:8) s 0/143, e 4 validation avg class xent loss = 41.8556\n",
      "================================================================================\n",
      "(0:9:16) s 10/143, e 4 avg class xent loss = 42.9541\n",
      "(0:9:23) s 20/143, e 4 avg class xent loss = 46.3334\n",
      "(0:9:31) s 30/143, e 4 avg class xent loss = 40.3295\n",
      "(0:9:39) s 40/143, e 4 avg class xent loss = 50.1431\n",
      "(0:9:47) s 50/143, e 4 avg class xent loss = 39.9140\n",
      "================================================================================\n",
      "(0:9:53) s 50/143, e 4 validation avg class xent loss = 42.4176\n",
      "================================================================================\n",
      "(0:10:1) s 60/143, e 4 avg class xent loss = 38.3754\n",
      "(0:10:9) s 70/143, e 4 avg class xent loss = 40.2355\n",
      "(0:10:16) s 80/143, e 4 avg class xent loss = 43.7430\n",
      "(0:10:24) s 90/143, e 4 avg class xent loss = 41.9804\n",
      "(0:10:32) s 100/143, e 4 avg class xent loss = 45.1604\n",
      "================================================================================\n",
      "(0:10:39) s 100/143, e 4 validation avg class xent loss = 42.4396\n",
      "================================================================================\n",
      "(0:10:46) s 110/143, e 4 avg class xent loss = 36.5428\n",
      "(0:10:54) s 120/143, e 4 avg class xent loss = 42.1161\n",
      "(0:11:1) s 130/143, e 4 avg class xent loss = 37.0670\n",
      "(0:11:9) s 140/143, e 4 avg class xent loss = 45.3495\n",
      "Macro P: 9.9024, R: 4.8084, F1: 6.4734\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-3575-15782\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "CYCLE 6\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "===== UNSUPERVISED TRAINING =====\n",
      "(0:0:1) step 0/143, epoch 0 Training Loss = 8.34841 :: 2225.246 phrases/sec :: (0:1:21) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <awards> '<X> for apply in <Y>' <areas>\n",
      "0: 1.000 : <awards> '<X> for apply in <Y>' <areas>\n",
      "1: 0.818 : <factory> '<X> for <Y>' <cars>\n",
      "2: 0.817 : <suit> '<X> for <Y>' <scene>\n",
      "3: 0.811 : <notebook> '<X> for <Y>' <astronomers>\n",
      "4: 0.809 : <land> '<X> farmed for <Y>' <olives>\n",
      "5: 0.809 : <site> '<X> farmed for <Y>' <wheat>\n",
      "6: 0.809 : <island> '<X> farmed for <Y>' <oats>\n",
      "7: 0.761 : <hurdles> '<X> for <Y>' <drilling>\n",
      "8: 0.753 : <species> '<X> in <Y>' <forest>\n",
      "9: 0.753 : <wall> '<X> in <Y>' <shop>\n",
      "10: 0.753 : <switchboard> '<X> in <Y>' <engine>\n",
      "11: 0.742 : <guns> '<X> locked in <Y>' <room>\n",
      "12: 0.739 : <results> '<X> presented in <Y>' <report>\n",
      "13: 0.735 : <standards> '<X> criticised in <Y>' <report>\n",
      "14: 0.733 : <cover> '<X> analysed in <Y>' <article>\n",
      "15: 0.733 : <methods> '<X> analysed in <Y>' <section>\n",
      "16: 0.732 : <geoid> '<X> as known mss to closest surface departs from <Y>' <ellipsoid>\n",
      "17: 0.728 : <phone> '<X> placed in <Y>' <cradle>\n",
      "18: 0.728 : <linoleum> '<X> cleaning in <Y>' <kitchen>\n",
      "19: 0.727 : <nostrils> '<X> opened in <Y>' <nose>\n",
      "================================================================================\n",
      "Validation loss: 8.5969\n",
      "(0:0:19) step 10/143, epoch 0 Training Loss = 7.71470 :: 1327.483 phrases/sec :: (0:2:0) hours left\n",
      "(0:0:37) step 20/143, epoch 0 Training Loss = 7.20098 :: 1277.094 phrases/sec :: (0:1:48) hours left\n",
      "(0:0:55) step 30/143, epoch 0 Training Loss = 6.81624 :: 1253.777 phrases/sec :: (0:1:33) hours left\n",
      "(0:1:12) step 40/143, epoch 0 Training Loss = 6.37193 :: 1239.236 phrases/sec :: (0:1:17) hours left\n",
      "(0:1:30) step 50/143, epoch 0 Training Loss = 6.02645 :: 1229.370 phrases/sec :: (0:1:1) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <centerboard> '<X> inspecting on <Y>' <yacht>\n",
      "0: 1.000 : <centerboard> '<X> inspecting on <Y>' <yacht>\n",
      "1: 0.999 : <stack> '<X> loading into <Y>' <carton>\n",
      "2: 0.996 : <system> '<X> translates into <Y>' <speech>\n",
      "3: 0.990 : <grief> '<X> experiencing after <Y>' <death>\n",
      "4: 0.982 : <city> '<X> thrown into <Y>' <darkness>\n",
      "5: 0.980 : <suitcase> '<X> full of <Y>' <cocaine>\n",
      "6: 0.980 : <bottle> '<X> full of <Y>' <teeth>\n",
      "7: 0.978 : <congress> '<X> of <Y>' <nations>\n",
      "8: 0.978 : <crash> '<X> of <Y>' <hippopotami>\n",
      "9: 0.978 : <cabinet> '<X> of <Y>' <names>\n",
      "10: 0.978 : <unit> '<X> of <Y>' <musketeers>\n",
      "11: 0.978 : <pack> '<X> of <Y>' <hounds>\n",
      "12: 0.978 : <division> '<X> of <Y>' <musketeers>\n",
      "13: 0.978 : <round> '<X> of <Y>' <drinks>\n",
      "14: 0.978 : <legion> '<X> of <Y>' <marksmen>\n",
      "15: 0.978 : <heel> '<X> of <Y>' <shoes>\n",
      "16: 0.978 : <chapter> '<X> of <Y>' <canons>\n",
      "17: 0.978 : <cornucopia> '<X> of <Y>' <foods>\n",
      "18: 0.978 : <brigade> '<X> of <Y>' <riflemen>\n",
      "19: 0.978 : <pile> '<X> of <Y>' <junk>\n",
      "================================================================================\n",
      "Validation loss: 7.6743\n",
      "(0:1:48) step 60/143, epoch 0 Training Loss = 5.62477 :: 1219.711 phrases/sec :: (0:0:44) hours left\n",
      "(0:2:5) step 70/143, epoch 0 Training Loss = 5.33818 :: 1215.901 phrases/sec :: (0:0:27) hours left\n",
      "(0:2:23) step 80/143, epoch 0 Training Loss = 4.99365 :: 1214.165 phrases/sec :: (0:0:10) hours left\n",
      "(0:2:41) step 90/143, epoch 0 Training Loss = 4.70043 :: 1212.195 phrases/sec :: (-1:59:52) hours left\n",
      "(0:2:59) step 100/143, epoch 0 Training Loss = 4.43040 :: 1209.042 phrases/sec :: (-1:59:35) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <fraud> '<X> of percent caused by banks <Y>' <institutions>\n",
      "0: 1.000 : <fraud> '<X> of percent caused by banks <Y>' <institutions>\n",
      "1: 0.978 : <ruins> '<X> identified as built as house <Y>' <inhabitants>\n",
      "2: 0.976 : <rashes> '<X> discomfort from ticks <Y>' <fleas>\n",
      "3: 0.975 : <mason> '<X> removed left <Y>' <edges>\n",
      "4: 0.968 : <recession> '<X> caused by bubble <Y>' <stock>\n",
      "5: 0.962 : <companies> '<X> of variety manufacture bopet <Y>' <films>\n",
      "6: 0.960 : <weathering> '<X> processes lead to consolidation <Y>' <cementation>\n",
      "7: 0.959 : <spam> '<X> arrives into folder <Y>' <inbox>\n",
      "8: 0.958 : <directors> '<X> journeyed into television <Y>' <series>\n",
      "9: 0.957 : <afterglow> '<X> produced by waves <Y>' <shock>\n",
      "10: 0.957 : <comments> '<X> are parts of code <Y>' <source>\n",
      "11: 0.956 : <colorants> '<X> preservatives cause dryness <Y>' <rashes>\n",
      "12: 0.955 : <toothache> '<X> coming from problem <Y>' <jaw>\n",
      "13: 0.954 : <data> '<X> of some presented in read <Y>' <paper>\n",
      "14: 0.953 : <paleogene> '<X> horizons migrated into blocks <Y>' <basement>\n",
      "15: 0.953 : <experiment> '<X> of run produced number <Y>' <state>\n",
      "16: 0.952 : <agar> '<X> contained in tube <Y>' <polyethylene>\n",
      "17: 0.952 : <sample> '<X> contained in tube <Y>' <glass>\n",
      "18: 0.952 : <insurance> '<X> cost added into price <Y>' <shipping>\n",
      "19: 0.952 : <fats> '<X> cause <Y>' <disease>\n",
      "================================================================================\n",
      "Validation loss: 6.6981\n",
      "(0:3:17) step 110/143, epoch 0 Training Loss = 4.17973 :: 1208.424 phrases/sec :: (-1:59:17) hours left\n",
      "(0:3:35) step 120/143, epoch 0 Training Loss = 3.93040 :: 1207.947 phrases/sec :: (-1:58:59) hours left\n",
      "(0:3:52) step 130/143, epoch 0 Training Loss = 3.72432 :: 1208.012 phrases/sec :: (-1:58:41) hours left\n",
      "(0:4:10) step 140/143, epoch 0 Training Loss = 3.51767 :: 1209.503 phrases/sec :: (-1:58:24) hours left\n",
      "Macro P: 6.9260, R: 4.4941, F1: 5.4511\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-3718-15782\n",
      "143\n",
      "***** SUPERVISED TRAINING *****\n",
      "(0:0:0) s 0/143, e 0 avg class xent loss = 44.4295\n",
      "================================================================================\n",
      "(0:0:7) s 0/143, e 0 validation avg class xent loss = 42.9514\n",
      "================================================================================\n",
      "(0:0:15) s 10/143, e 0 avg class xent loss = 44.3555\n",
      "(0:0:22) s 20/143, e 0 avg class xent loss = 41.7761\n",
      "(0:0:30) s 30/143, e 0 avg class xent loss = 34.7483\n",
      "(0:0:38) s 40/143, e 0 avg class xent loss = 48.8040\n",
      "(0:0:45) s 50/143, e 0 avg class xent loss = 42.4721\n",
      "================================================================================\n",
      "(0:0:52) s 50/143, e 0 validation avg class xent loss = 43.2421\n",
      "================================================================================\n",
      "(0:1:0) s 60/143, e 0 avg class xent loss = 38.7378\n",
      "(0:1:7) s 70/143, e 0 avg class xent loss = 40.0218\n",
      "(0:1:15) s 80/143, e 0 avg class xent loss = 38.4788\n",
      "(0:1:23) s 90/143, e 0 avg class xent loss = 43.1182\n",
      "(0:1:30) s 100/143, e 0 avg class xent loss = 42.5617\n",
      "================================================================================\n",
      "(0:1:37) s 100/143, e 0 validation avg class xent loss = 43.2647\n",
      "================================================================================\n",
      "(0:1:45) s 110/143, e 0 avg class xent loss = 40.2386\n",
      "(0:1:52) s 120/143, e 0 avg class xent loss = 41.9023\n",
      "(0:2:0) s 130/143, e 0 avg class xent loss = 38.5245\n",
      "(0:2:7) s 140/143, e 0 avg class xent loss = 45.3446\n",
      "Macro P: 3.7090, R: 5.5821, F1: 4.4568\n",
      "(0:2:16) s 0/143, e 1 avg class xent loss = 41.5665\n",
      "================================================================================\n",
      "(0:2:22) s 0/143, e 1 validation avg class xent loss = 42.7929\n",
      "================================================================================\n",
      "(0:2:30) s 10/143, e 1 avg class xent loss = 41.1200\n",
      "(0:2:38) s 20/143, e 1 avg class xent loss = 43.2854\n",
      "(0:2:45) s 30/143, e 1 avg class xent loss = 40.4606\n",
      "(0:2:53) s 40/143, e 1 avg class xent loss = 41.5225\n",
      "(0:3:1) s 50/143, e 1 avg class xent loss = 41.3258\n",
      "================================================================================\n",
      "(0:3:7) s 50/143, e 1 validation avg class xent loss = 43.7776\n",
      "================================================================================\n",
      "(0:3:15) s 60/143, e 1 avg class xent loss = 39.3583\n",
      "(0:3:22) s 70/143, e 1 avg class xent loss = 38.5226\n",
      "(0:3:30) s 80/143, e 1 avg class xent loss = 43.3240\n",
      "(0:3:38) s 90/143, e 1 avg class xent loss = 42.0085\n",
      "(0:3:46) s 100/143, e 1 avg class xent loss = 41.9851\n",
      "================================================================================\n",
      "(0:3:52) s 100/143, e 1 validation avg class xent loss = 43.8147\n",
      "================================================================================\n",
      "(0:4:0) s 110/143, e 1 avg class xent loss = 39.3770\n",
      "(0:4:8) s 120/143, e 1 avg class xent loss = 38.1298\n",
      "(0:4:15) s 130/143, e 1 avg class xent loss = 39.8992\n",
      "(0:4:23) s 140/143, e 1 avg class xent loss = 39.4259\n",
      "Macro P: 8.8216, R: 4.7956, F1: 6.2135\n",
      "(0:4:31) s 0/143, e 2 avg class xent loss = 43.2782\n",
      "================================================================================\n",
      "(0:4:38) s 0/143, e 2 validation avg class xent loss = 42.7669\n",
      "================================================================================\n",
      "(0:4:45) s 10/143, e 2 avg class xent loss = 43.6289\n",
      "(0:4:53) s 20/143, e 2 avg class xent loss = 44.4061\n",
      "(0:5:1) s 30/143, e 2 avg class xent loss = 41.2883\n",
      "(0:5:8) s 40/143, e 2 avg class xent loss = 43.9702\n",
      "(0:5:16) s 50/143, e 2 avg class xent loss = 40.8047\n",
      "================================================================================\n",
      "(0:5:23) s 50/143, e 2 validation avg class xent loss = 42.2544\n",
      "================================================================================\n",
      "(0:5:30) s 60/143, e 2 avg class xent loss = 44.1850\n",
      "(0:5:37) s 70/143, e 2 avg class xent loss = 45.1492\n",
      "(0:5:44) s 80/143, e 2 avg class xent loss = 42.9653\n",
      "(0:5:51) s 90/143, e 2 avg class xent loss = 40.7261\n",
      "(0:5:58) s 100/143, e 2 avg class xent loss = 45.0058\n",
      "================================================================================\n",
      "(0:6:5) s 100/143, e 2 validation avg class xent loss = 41.4905\n",
      "================================================================================\n",
      "(0:6:12) s 110/143, e 2 avg class xent loss = 37.2514\n",
      "(0:6:18) s 120/143, e 2 avg class xent loss = 41.6101\n",
      "(0:6:25) s 130/143, e 2 avg class xent loss = 38.8934\n",
      "(0:6:32) s 140/143, e 2 avg class xent loss = 42.5072\n",
      "Macro P: 9.5275, R: 4.8473, F1: 6.4255\n",
      "(0:6:40) s 0/143, e 3 avg class xent loss = 44.1058\n",
      "================================================================================\n",
      "(0:6:46) s 0/143, e 3 validation avg class xent loss = 41.2957\n",
      "================================================================================\n",
      "(0:6:53) s 10/143, e 3 avg class xent loss = 43.3053\n",
      "(0:7:0) s 20/143, e 3 avg class xent loss = 47.1248\n",
      "(0:7:7) s 30/143, e 3 avg class xent loss = 40.4852\n",
      "(0:7:14) s 40/143, e 3 avg class xent loss = 49.1734\n",
      "(0:7:21) s 50/143, e 3 avg class xent loss = 39.3208\n",
      "================================================================================\n",
      "(0:7:27) s 50/143, e 3 validation avg class xent loss = 41.5059\n",
      "================================================================================\n",
      "(0:7:34) s 60/143, e 3 avg class xent loss = 38.6006\n",
      "(0:7:41) s 70/143, e 3 avg class xent loss = 38.1250\n",
      "(0:7:48) s 80/143, e 3 avg class xent loss = 42.7203\n",
      "(0:7:55) s 90/143, e 3 avg class xent loss = 46.5040\n",
      "(0:8:2) s 100/143, e 3 avg class xent loss = 45.4516\n",
      "================================================================================\n",
      "(0:8:8) s 100/143, e 3 validation avg class xent loss = 41.7032\n",
      "================================================================================\n",
      "(0:8:15) s 110/143, e 3 avg class xent loss = 38.1941\n",
      "(0:8:22) s 120/143, e 3 avg class xent loss = 41.3130\n",
      "(0:8:28) s 130/143, e 3 avg class xent loss = 39.9821\n",
      "(0:8:35) s 140/143, e 3 avg class xent loss = 43.2904\n",
      "Macro P: 3.1465, R: 5.5148, F1: 4.0068\n",
      "(0:8:43) s 0/143, e 4 avg class xent loss = 43.1857\n",
      "================================================================================\n",
      "(0:8:49) s 0/143, e 4 validation avg class xent loss = 41.3172\n",
      "================================================================================\n",
      "(0:8:56) s 10/143, e 4 avg class xent loss = 44.1404\n",
      "(0:9:3) s 20/143, e 4 avg class xent loss = 44.5339\n",
      "(0:9:10) s 30/143, e 4 avg class xent loss = 41.1967\n",
      "(0:9:17) s 40/143, e 4 avg class xent loss = 42.7214\n",
      "(0:9:23) s 50/143, e 4 avg class xent loss = 36.5308\n",
      "================================================================================\n",
      "(0:9:30) s 50/143, e 4 validation avg class xent loss = 41.9229\n",
      "================================================================================\n",
      "(0:9:37) s 60/143, e 4 avg class xent loss = 37.3628\n",
      "(0:9:44) s 70/143, e 4 avg class xent loss = 41.5715\n",
      "(0:9:50) s 80/143, e 4 avg class xent loss = 37.3381\n",
      "(0:9:57) s 90/143, e 4 avg class xent loss = 38.5634\n",
      "(0:10:4) s 100/143, e 4 avg class xent loss = 38.6397\n",
      "================================================================================\n",
      "(0:10:10) s 100/143, e 4 validation avg class xent loss = 42.4126\n",
      "================================================================================\n",
      "(0:10:17) s 110/143, e 4 avg class xent loss = 38.6725\n",
      "(0:10:24) s 120/143, e 4 avg class xent loss = 39.0062\n",
      "(0:10:31) s 130/143, e 4 avg class xent loss = 39.6789\n",
      "(0:10:38) s 140/143, e 4 avg class xent loss = 37.2198\n",
      "Macro P: 10.7588, R: 4.4804, F1: 6.3262\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-3718-16492\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "CYCLE 7\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "===== UNSUPERVISED TRAINING =====\n",
      "(0:0:1) step 0/143, epoch 0 Training Loss = 8.08637 :: 2609.553 phrases/sec :: (0:1:9) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <microscopes> '<X> are instruments use <Y>' <beam>\n",
      "0: 1.000 : <microscopes> '<X> are instruments use <Y>' <beam>\n",
      "1: 0.969 : <women> '<X> use <Y>' <pump>\n",
      "2: 0.926 : <paper> '<X> received <Y>' <comments>\n",
      "3: 0.866 : <computer> '<X> chip enclosed in case <Y>' <steel>\n",
      "4: 0.858 : <disc> '<X> in box <Y>' <music>\n",
      "5: 0.851 : <seeds> '<X> stored in unit <Y>' <stratification>\n",
      "6: 0.849 : <suspect> '<X> placed in car <Y>' <patrol>\n",
      "7: 0.842 : <guard> '<X> participates in <Y>' <ceremony>\n",
      "8: 0.842 : <experts> '<X> created <Y>' <aircraft>\n",
      "9: 0.840 : <cocaine> '<X> was in <Y>' <crate>\n",
      "10: 0.840 : <blazer> '<X> was in <Y>' <bin>\n",
      "11: 0.839 : <staff> '<X> in <Y>' <shop>\n",
      "12: 0.839 : <play> '<X> starts in <Y>' <state>\n",
      "13: 0.837 : <place> '<X> was in <Y>' <desk>\n",
      "14: 0.837 : <model> '<X> was in <Y>' <jar>\n",
      "15: 0.837 : <anthrax> '<X> was in <Y>' <suitcase>\n",
      "16: 0.837 : <jewelry> '<X> was in <Y>' <cabinet>\n",
      "17: 0.837 : <sink> '<X> was in <Y>' <desk>\n",
      "18: 0.837 : <sink> '<X> was in <Y>' <stand>\n",
      "19: 0.837 : <nostrils> '<X> opened in <Y>' <nose>\n",
      "================================================================================\n",
      "Validation loss: 8.5024\n",
      "(0:0:18) step 10/143, epoch 0 Training Loss = 7.52680 :: 1433.924 phrases/sec :: (0:1:51) hours left\n",
      "(0:0:33) step 20/143, epoch 0 Training Loss = 7.03060 :: 1387.737 phrases/sec :: (0:1:40) hours left\n",
      "(0:0:49) step 30/143, epoch 0 Training Loss = 6.62880 :: 1360.304 phrases/sec :: (0:1:27) hours left\n",
      "(0:1:5) step 40/143, epoch 0 Training Loss = 6.20331 :: 1341.642 phrases/sec :: (0:1:13) hours left\n",
      "(0:1:22) step 50/143, epoch 0 Training Loss = 5.87405 :: 1328.343 phrases/sec :: (0:0:58) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <fraud> '<X> of percent caused by banks <Y>' <institutions>\n",
      "0: 1.000 : <fraud> '<X> of percent caused by banks <Y>' <institutions>\n",
      "1: 0.983 : <chaos> '<X> urgency caused by <Y>' <hurricanes>\n",
      "2: 0.983 : <damage> '<X> caused by <Y>' <storm>\n",
      "3: 0.983 : <death> '<X> caused by <Y>' <storm>\n",
      "4: 0.983 : <devastations> '<X> caused by <Y>' <storms>\n",
      "5: 0.983 : <emergency> '<X> caused by <Y>' <landslide>\n",
      "6: 0.983 : <slowdown> '<X> caused by <Y>' <recession>\n",
      "7: 0.983 : <devastation> '<X> caused by <Y>' <tornado>\n",
      "8: 0.983 : <suffering> '<X> caused by <Y>' <drinking>\n",
      "9: 0.983 : <sorrow> '<X> caused by <Y>' <attack>\n",
      "10: 0.962 : <cancers> '<X> head of portion caused by <Y>' <papillomavirus>\n",
      "11: 0.961 : <fevers> '<X> caused by <Y>' <colds>\n",
      "12: 0.961 : <trauma> '<X> caused by <Y>' <arrival>\n",
      "13: 0.961 : <frustration> '<X> caused by <Y>' <system>\n",
      "14: 0.953 : <problem> '<X> caused by <Y>' <state>\n",
      "15: 0.952 : <symptoms> '<X> caused by changes <Y>' <chemical>\n",
      "16: 0.952 : <granules> '<X> caused by force <Y>' <magnetic>\n",
      "17: 0.952 : <recession> '<X> caused by bubble <Y>' <stock>\n",
      "18: 0.952 : <inflammation> '<X> caused by <Y>' <growth>\n",
      "19: 0.952 : <cancer> '<X> caused by <Y>' <infection>\n",
      "================================================================================\n",
      "Validation loss: 7.4408\n",
      "(0:1:38) step 60/143, epoch 0 Training Loss = 5.48335 :: 1322.474 phrases/sec :: (0:0:42) hours left\n",
      "(0:1:54) step 70/143, epoch 0 Training Loss = 5.20640 :: 1324.996 phrases/sec :: (0:0:26) hours left\n",
      "(0:2:10) step 80/143, epoch 0 Training Loss = 4.88287 :: 1317.994 phrases/sec :: (0:0:10) hours left\n",
      "(0:2:27) step 90/143, epoch 0 Training Loss = 4.58158 :: 1313.301 phrases/sec :: (-1:59:54) hours left\n",
      "(0:2:43) step 100/143, epoch 0 Training Loss = 4.35207 :: 1308.578 phrases/sec :: (-1:59:38) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <plastic> '<X> <Y>' <bag>\n",
      "0: 1.000 : <plastic> '<X> <Y>' <bag>\n",
      "1: 0.998 : <vegetable> '<X> <Y>' <oil>\n",
      "2: 0.998 : <famine> '<X> <Y>' <drought>\n",
      "3: 0.996 : <olive> '<X> <Y>' <oil>\n",
      "4: 0.990 : <toy> '<X> <Y>' <factory>\n",
      "5: 0.990 : <apricot> '<X> <Y>' <nectar>\n",
      "6: 0.990 : <straw> '<X> <Y>' <stack>\n",
      "7: 0.990 : <rye> '<X> <Y>' <spirits>\n",
      "8: 0.990 : <jatropha> '<X> <Y>' <plant>\n",
      "9: 0.990 : <country> '<X> <Y>' <girl>\n",
      "10: 0.990 : <herb> '<X> <Y>' <butter>\n",
      "11: 0.990 : <bed> '<X> <Y>' <post>\n",
      "12: 0.989 : <silver> '<X> <Y>' <ring>\n",
      "13: 0.989 : <pork> '<X> <Y>' <stew>\n",
      "14: 0.989 : <gold> '<X> <Y>' <bracelet>\n",
      "15: 0.989 : <silver> '<X> <Y>' <ring>\n",
      "16: 0.989 : <picture> '<X> <Y>' <frame>\n",
      "17: 0.989 : <diamond> '<X> <Y>' <necklace>\n",
      "18: 0.989 : <door> '<X> <Y>' <handle>\n",
      "19: 0.989 : <manhole> '<X> <Y>' <cover>\n",
      "================================================================================\n",
      "Validation loss: 6.3017\n",
      "(0:3:0) step 110/143, epoch 0 Training Loss = 4.08165 :: 1305.984 phrases/sec :: (-1:59:22) hours left\n",
      "(0:3:16) step 120/143, epoch 0 Training Loss = 3.87719 :: 1307.148 phrases/sec :: (-1:59:6) hours left\n",
      "(0:3:31) step 130/143, epoch 0 Training Loss = 3.66299 :: 1311.267 phrases/sec :: (-1:58:51) hours left\n",
      "(0:3:47) step 140/143, epoch 0 Training Loss = 3.44460 :: 1311.406 phrases/sec :: (-1:58:34) hours left\n",
      "Macro P: 10.0092, R: 4.4013, F1: 6.1141\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-3861-16492\n",
      "143\n",
      "***** SUPERVISED TRAINING *****\n",
      "(0:0:0) s 0/143, e 0 avg class xent loss = 42.9155\n",
      "================================================================================\n",
      "(0:0:6) s 0/143, e 0 validation avg class xent loss = 41.2724\n",
      "================================================================================\n",
      "(0:0:13) s 10/143, e 0 avg class xent loss = 44.5886\n",
      "(0:0:20) s 20/143, e 0 avg class xent loss = 36.5102\n",
      "(0:0:27) s 30/143, e 0 avg class xent loss = 37.8981\n",
      "(0:0:34) s 40/143, e 0 avg class xent loss = 44.8556\n",
      "(0:0:41) s 50/143, e 0 avg class xent loss = 40.7715\n",
      "================================================================================\n",
      "(0:0:47) s 50/143, e 0 validation avg class xent loss = 41.9833\n",
      "================================================================================\n",
      "(0:0:54) s 60/143, e 0 avg class xent loss = 36.3543\n",
      "(0:1:1) s 70/143, e 0 avg class xent loss = 47.4146\n",
      "(0:1:8) s 80/143, e 0 avg class xent loss = 39.7453\n",
      "(0:1:15) s 90/143, e 0 avg class xent loss = 40.0316\n",
      "(0:1:22) s 100/143, e 0 avg class xent loss = 46.3162\n",
      "================================================================================\n",
      "(0:1:28) s 100/143, e 0 validation avg class xent loss = 43.5735\n",
      "================================================================================\n",
      "(0:1:34) s 110/143, e 0 avg class xent loss = 40.3113\n",
      "(0:1:41) s 120/143, e 0 avg class xent loss = 39.4062\n",
      "(0:1:48) s 130/143, e 0 avg class xent loss = 40.8984\n",
      "(0:1:55) s 140/143, e 0 avg class xent loss = 39.5118\n",
      "Macro P: 6.0237, R: 4.7358, F1: 5.3027\n",
      "(0:2:2) s 0/143, e 1 avg class xent loss = 45.8569\n",
      "================================================================================\n",
      "(0:2:8) s 0/143, e 1 validation avg class xent loss = 43.0114\n",
      "================================================================================\n",
      "(0:2:15) s 10/143, e 1 avg class xent loss = 46.6297\n",
      "(0:2:22) s 20/143, e 1 avg class xent loss = 39.8606\n",
      "(0:2:29) s 30/143, e 1 avg class xent loss = 43.4621\n",
      "(0:2:36) s 40/143, e 1 avg class xent loss = 41.5040\n",
      "(0:2:43) s 50/143, e 1 avg class xent loss = 37.3627\n",
      "================================================================================\n",
      "(0:2:49) s 50/143, e 1 validation avg class xent loss = 44.0465\n",
      "================================================================================\n",
      "(0:2:56) s 60/143, e 1 avg class xent loss = 40.4661\n",
      "(0:3:3) s 70/143, e 1 avg class xent loss = 42.1109\n",
      "(0:3:9) s 80/143, e 1 avg class xent loss = 35.6938\n",
      "(0:3:16) s 90/143, e 1 avg class xent loss = 43.4894\n",
      "(0:3:23) s 100/143, e 1 avg class xent loss = 45.2626\n",
      "================================================================================\n",
      "(0:3:29) s 100/143, e 1 validation avg class xent loss = 43.6808\n",
      "================================================================================\n",
      "(0:3:36) s 110/143, e 1 avg class xent loss = 37.6732\n",
      "(0:3:43) s 120/143, e 1 avg class xent loss = 44.5166\n",
      "(0:3:50) s 130/143, e 1 avg class xent loss = 39.7124\n",
      "(0:3:57) s 140/143, e 1 avg class xent loss = 41.3701\n",
      "Macro P: 2.5263, R: 4.9177, F1: 3.3379\n",
      "(0:4:4) s 0/143, e 2 avg class xent loss = 45.7859\n",
      "================================================================================\n",
      "(0:4:10) s 0/143, e 2 validation avg class xent loss = 43.0017\n",
      "================================================================================\n",
      "(0:4:17) s 10/143, e 2 avg class xent loss = 43.6753\n",
      "(0:4:24) s 20/143, e 2 avg class xent loss = 46.1705\n",
      "(0:4:31) s 30/143, e 2 avg class xent loss = 38.6230\n",
      "(0:4:38) s 40/143, e 2 avg class xent loss = 43.7589\n",
      "(0:4:45) s 50/143, e 2 avg class xent loss = 42.2804\n",
      "================================================================================\n",
      "(0:4:51) s 50/143, e 2 validation avg class xent loss = 43.7488\n",
      "================================================================================\n",
      "(0:4:58) s 60/143, e 2 avg class xent loss = 39.7969\n",
      "(0:5:4) s 70/143, e 2 avg class xent loss = 43.6011\n",
      "(0:5:11) s 80/143, e 2 avg class xent loss = 37.6521\n",
      "(0:5:18) s 90/143, e 2 avg class xent loss = 43.7336\n",
      "(0:5:25) s 100/143, e 2 avg class xent loss = 43.0468\n",
      "================================================================================\n",
      "(0:5:31) s 100/143, e 2 validation avg class xent loss = 43.0915\n",
      "================================================================================\n",
      "(0:5:38) s 110/143, e 2 avg class xent loss = 38.7547\n",
      "(0:5:45) s 120/143, e 2 avg class xent loss = 40.9213\n",
      "(0:5:52) s 130/143, e 2 avg class xent loss = 38.3990\n",
      "(0:5:59) s 140/143, e 2 avg class xent loss = 43.9010\n",
      "Macro P: 5.3713, R: 1.9550, F1: 2.8666\n",
      "(0:6:6) s 0/143, e 3 avg class xent loss = 44.9425\n",
      "================================================================================\n",
      "(0:6:12) s 0/143, e 3 validation avg class xent loss = 43.0649\n",
      "================================================================================\n",
      "(0:6:19) s 10/143, e 3 avg class xent loss = 41.7697\n",
      "(0:6:26) s 20/143, e 3 avg class xent loss = 49.1981\n",
      "(0:6:33) s 30/143, e 3 avg class xent loss = 38.0391\n",
      "(0:6:40) s 40/143, e 3 avg class xent loss = 44.0790\n",
      "(0:6:47) s 50/143, e 3 avg class xent loss = 40.6861\n",
      "================================================================================\n",
      "(0:6:53) s 50/143, e 3 validation avg class xent loss = 42.9049\n",
      "================================================================================\n",
      "(0:7:0) s 60/143, e 3 avg class xent loss = 40.3315\n",
      "(0:7:7) s 70/143, e 3 avg class xent loss = 41.1118\n",
      "(0:7:14) s 80/143, e 3 avg class xent loss = 35.7715\n",
      "(0:7:20) s 90/143, e 3 avg class xent loss = 41.6848\n",
      "(0:7:27) s 100/143, e 3 avg class xent loss = 41.3286\n",
      "================================================================================\n",
      "(0:7:34) s 100/143, e 3 validation avg class xent loss = 42.5039\n",
      "================================================================================\n",
      "(0:7:41) s 110/143, e 3 avg class xent loss = 39.2934\n",
      "(0:7:48) s 120/143, e 3 avg class xent loss = 45.6551\n",
      "(0:7:55) s 130/143, e 3 avg class xent loss = 39.5114\n",
      "(0:8:1) s 140/143, e 3 avg class xent loss = 43.9319\n",
      "Macro P: 5.6421, R: 6.1890, F1: 5.9029\n",
      "(0:8:9) s 0/143, e 4 avg class xent loss = 44.8304\n",
      "================================================================================\n",
      "(0:8:15) s 0/143, e 4 validation avg class xent loss = 42.5549\n",
      "================================================================================\n",
      "(0:8:22) s 10/143, e 4 avg class xent loss = 42.2827\n",
      "(0:8:29) s 20/143, e 4 avg class xent loss = 43.1003\n",
      "(0:8:36) s 30/143, e 4 avg class xent loss = 38.8209\n",
      "(0:8:42) s 40/143, e 4 avg class xent loss = 44.2891\n",
      "(0:8:49) s 50/143, e 4 avg class xent loss = 45.3009\n",
      "================================================================================\n",
      "(0:8:55) s 50/143, e 4 validation avg class xent loss = 42.7435\n",
      "================================================================================\n",
      "(0:9:2) s 60/143, e 4 avg class xent loss = 39.0956\n",
      "(0:9:9) s 70/143, e 4 avg class xent loss = 42.3909\n",
      "(0:9:16) s 80/143, e 4 avg class xent loss = 40.1705\n",
      "(0:9:23) s 90/143, e 4 avg class xent loss = 40.8071\n",
      "(0:9:30) s 100/143, e 4 avg class xent loss = 40.7839\n",
      "================================================================================\n",
      "(0:9:36) s 100/143, e 4 validation avg class xent loss = 43.3399\n",
      "================================================================================\n",
      "(0:9:43) s 110/143, e 4 avg class xent loss = 37.8024\n",
      "(0:9:50) s 120/143, e 4 avg class xent loss = 45.2250\n",
      "(0:9:57) s 130/143, e 4 avg class xent loss = 35.9938\n",
      "(0:10:4) s 140/143, e 4 avg class xent loss = 43.9106\n",
      "Macro P: 5.4459, R: 4.2125, F1: 4.7504\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-3861-17202\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "CYCLE 8\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "===== UNSUPERVISED TRAINING =====\n",
      "(0:0:1) step 0/143, epoch 0 Training Loss = 8.05384 :: 2759.610 phrases/sec :: (0:1:5) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <eggs> '<X> come out of <Y>' <body>\n",
      "0: 1.000 : <eggs> '<X> come out of <Y>' <body>\n",
      "1: 0.999 : <lid> '<X> of <Y>' <coffin>\n",
      "2: 0.999 : <suitcase> '<X> full of <Y>' <cocaine>\n",
      "3: 0.999 : <bottle> '<X> full of <Y>' <teeth>\n",
      "4: 0.999 : <congress> '<X> of <Y>' <nations>\n",
      "5: 0.999 : <crash> '<X> of <Y>' <hippopotami>\n",
      "6: 0.999 : <cabinet> '<X> of <Y>' <names>\n",
      "7: 0.999 : <unit> '<X> of <Y>' <musketeers>\n",
      "8: 0.999 : <pack> '<X> of <Y>' <hounds>\n",
      "9: 0.999 : <division> '<X> of <Y>' <musketeers>\n",
      "10: 0.999 : <round> '<X> of <Y>' <drinks>\n",
      "11: 0.999 : <legion> '<X> of <Y>' <marksmen>\n",
      "12: 0.999 : <heel> '<X> of <Y>' <shoes>\n",
      "13: 0.999 : <chapter> '<X> of <Y>' <canons>\n",
      "14: 0.999 : <cornucopia> '<X> of <Y>' <foods>\n",
      "15: 0.999 : <brigade> '<X> of <Y>' <riflemen>\n",
      "16: 0.999 : <pile> '<X> of <Y>' <junk>\n",
      "17: 0.999 : <hamper> '<X> of <Y>' <goodies>\n",
      "18: 0.999 : <scurry> '<X> of <Y>' <squirrels>\n",
      "19: 0.999 : <rookery> '<X> of <Y>' <herons>\n",
      "================================================================================\n",
      "Validation loss: 8.4120\n",
      "(0:0:18) step 10/143, epoch 0 Training Loss = 7.53152 :: 1430.134 phrases/sec :: (0:1:52) hours left\n",
      "(0:0:33) step 20/143, epoch 0 Training Loss = 7.03955 :: 1395.013 phrases/sec :: (0:1:40) hours left\n",
      "(0:0:49) step 30/143, epoch 0 Training Loss = 6.57807 :: 1371.176 phrases/sec :: (0:1:26) hours left\n",
      "(0:1:5) step 40/143, epoch 0 Training Loss = 6.18921 :: 1353.134 phrases/sec :: (0:1:12) hours left\n",
      "(0:1:21) step 50/143, epoch 0 Training Loss = 5.82073 :: 1346.070 phrases/sec :: (0:0:57) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <princess> '<X> married descended from <Y>' <family>\n",
      "0: 1.000 : <princess> '<X> married descended from <Y>' <family>\n",
      "1: 1.000 : <court> '<X> started from <Y>' <assumption>\n",
      "2: 0.999 : <families> '<X> descended from <Y>' <immigrants>\n",
      "3: 0.999 : <flight> '<X> departs from <Y>' <airport>\n",
      "4: 0.998 : <centerboard> '<X> inspecting on <Y>' <yacht>\n",
      "5: 0.997 : <explosive> '<X> hidden in <Y>' <condom>\n",
      "6: 0.997 : <ark> '<X> hidden in <Y>' <cave>\n",
      "7: 0.997 : <image> '<X> hidden in <Y>' <carafe>\n",
      "8: 0.997 : <birds> '<X> descended from <Y>' <parent>\n",
      "9: 0.997 : <series> '<X> reflected on <Y>' <changes>\n",
      "10: 0.997 : <players> '<X> flew on <Y>' <plane>\n",
      "11: 0.996 : <conflicts> '<X> of some arose from <Y>' <development>\n",
      "12: 0.996 : <system> '<X> of prototype constructed from <Y>' <design>\n",
      "13: 0.996 : <ingredients> '<X> of many in <Y>' <basket>\n",
      "14: 0.995 : <cell> '<X> mass measuring in <Y>' <flask>\n",
      "15: 0.995 : <bomb> '<X> used in <Y>' <diplomacy>\n",
      "16: 0.993 : <play> '<X> starts in <Y>' <state>\n",
      "17: 0.993 : <transmission> '<X> of commencement of time mark from <Y>' <transmitter>\n",
      "18: 0.992 : <popcorn> '<X> stirring in <Y>' <kettle>\n",
      "19: 0.991 : <fire> '<X> caught after <Y>' <collision>\n",
      "================================================================================\n",
      "Validation loss: 7.7681\n",
      "(0:1:37) step 60/143, epoch 0 Training Loss = 5.47004 :: 1338.911 phrases/sec :: (0:0:41) hours left\n",
      "(0:1:53) step 70/143, epoch 0 Training Loss = 5.18473 :: 1332.908 phrases/sec :: (0:0:26) hours left\n",
      "(0:2:9) step 80/143, epoch 0 Training Loss = 4.88459 :: 1326.069 phrases/sec :: (0:0:11) hours left\n",
      "(0:2:25) step 90/143, epoch 0 Training Loss = 4.59264 :: 1324.119 phrases/sec :: (-1:59:55) hours left\n",
      "(0:2:41) step 100/143, epoch 0 Training Loss = 4.31308 :: 1320.197 phrases/sec :: (-1:59:39) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <arsenic> '<X> originated in <Y>' <coatings>\n",
      "0: 1.000 : <arsenic> '<X> originated in <Y>' <coatings>\n",
      "1: 1.000 : <staff> '<X> in <Y>' <shop>\n",
      "2: 1.000 : <killings> '<X> resulted in <Y>' <firing>\n",
      "3: 1.000 : <place> '<X> was in <Y>' <desk>\n",
      "4: 1.000 : <model> '<X> was in <Y>' <jar>\n",
      "5: 1.000 : <anthrax> '<X> was in <Y>' <suitcase>\n",
      "6: 1.000 : <jewelry> '<X> was in <Y>' <cabinet>\n",
      "7: 1.000 : <sink> '<X> was in <Y>' <desk>\n",
      "8: 1.000 : <sink> '<X> was in <Y>' <stand>\n",
      "9: 1.000 : <guard> '<X> participates in <Y>' <ceremony>\n",
      "10: 1.000 : <cocaine> '<X> was in <Y>' <crate>\n",
      "11: 1.000 : <blazer> '<X> was in <Y>' <bin>\n",
      "12: 1.000 : <difficulties> '<X> stemmed from <Y>' <structure>\n",
      "13: 1.000 : <citations> '<X> references appear in <Y>' <book>\n",
      "14: 1.000 : <folder> '<X> went away from <Y>' <shell>\n",
      "15: 1.000 : <student> '<X> went away from <Y>' <interview>\n",
      "16: 1.000 : <production> '<X> arose from <Y>' <sensitivity>\n",
      "17: 1.000 : <recurrence> '<X> arose from <Y>' <radiation>\n",
      "18: 1.000 : <applicability> '<X> arose from <Y>' <linearity>\n",
      "19: 1.000 : <defendant> '<X> acting from <Y>' <computer>\n",
      "================================================================================\n",
      "Validation loss: 6.6502\n",
      "(0:2:57) step 110/143, epoch 0 Training Loss = 4.07507 :: 1321.571 phrases/sec :: (-1:59:23) hours left\n",
      "(0:3:13) step 120/143, epoch 0 Training Loss = 3.83386 :: 1322.145 phrases/sec :: (-1:59:7) hours left\n",
      "(0:3:29) step 130/143, epoch 0 Training Loss = 3.62093 :: 1319.808 phrases/sec :: (-1:58:52) hours left\n",
      "(0:3:45) step 140/143, epoch 0 Training Loss = 3.42040 :: 1317.981 phrases/sec :: (-1:58:35) hours left\n",
      "Macro P: 5.2146, R: 5.3634, F1: 5.2880\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-4004-17202\n",
      "143\n",
      "***** SUPERVISED TRAINING *****\n",
      "(0:0:0) s 0/143, e 0 avg class xent loss = 41.9174\n",
      "================================================================================\n",
      "(0:0:6) s 0/143, e 0 validation avg class xent loss = 42.6559\n",
      "================================================================================\n",
      "(0:0:13) s 10/143, e 0 avg class xent loss = 43.0399\n",
      "(0:0:20) s 20/143, e 0 avg class xent loss = 45.7642\n",
      "(0:0:27) s 30/143, e 0 avg class xent loss = 38.6699\n",
      "(0:0:34) s 40/143, e 0 avg class xent loss = 47.6847\n",
      "(0:0:40) s 50/143, e 0 avg class xent loss = 38.3946\n",
      "================================================================================\n",
      "(0:0:46) s 50/143, e 0 validation avg class xent loss = 42.6369\n",
      "================================================================================\n",
      "(0:0:53) s 60/143, e 0 avg class xent loss = 36.6233\n",
      "(0:1:0) s 70/143, e 0 avg class xent loss = 44.0910\n",
      "(0:1:7) s 80/143, e 0 avg class xent loss = 37.3063\n",
      "(0:1:14) s 90/143, e 0 avg class xent loss = 40.5365\n",
      "(0:1:21) s 100/143, e 0 avg class xent loss = 42.9318\n",
      "================================================================================\n",
      "(0:1:27) s 100/143, e 0 validation avg class xent loss = 43.3015\n",
      "================================================================================\n",
      "(0:1:34) s 110/143, e 0 avg class xent loss = 38.7499\n",
      "(0:1:41) s 120/143, e 0 avg class xent loss = 38.3409\n",
      "(0:1:48) s 130/143, e 0 avg class xent loss = 40.6071\n",
      "(0:1:54) s 140/143, e 0 avg class xent loss = 41.0162\n",
      "Macro P: 4.7049, R: 4.7701, F1: 4.7373\n",
      "(0:2:2) s 0/143, e 1 avg class xent loss = 43.8718\n",
      "================================================================================\n",
      "(0:2:8) s 0/143, e 1 validation avg class xent loss = 42.7089\n",
      "================================================================================\n",
      "(0:2:15) s 10/143, e 1 avg class xent loss = 46.0791\n",
      "(0:2:22) s 20/143, e 1 avg class xent loss = 44.6729\n",
      "(0:2:28) s 30/143, e 1 avg class xent loss = 39.3212\n",
      "(0:2:35) s 40/143, e 1 avg class xent loss = 42.0382\n",
      "(0:2:42) s 50/143, e 1 avg class xent loss = 42.1128\n",
      "================================================================================\n",
      "(0:2:48) s 50/143, e 1 validation avg class xent loss = 43.0756\n",
      "================================================================================\n",
      "(0:2:55) s 60/143, e 1 avg class xent loss = 38.3951\n",
      "(0:3:2) s 70/143, e 1 avg class xent loss = 37.4338\n",
      "(0:3:9) s 80/143, e 1 avg class xent loss = 40.8705\n",
      "(0:3:16) s 90/143, e 1 avg class xent loss = 42.6763\n",
      "(0:3:22) s 100/143, e 1 avg class xent loss = 42.8544\n",
      "================================================================================\n",
      "(0:3:28) s 100/143, e 1 validation avg class xent loss = 42.6505\n",
      "================================================================================\n",
      "(0:3:35) s 110/143, e 1 avg class xent loss = 39.6570\n",
      "(0:3:42) s 120/143, e 1 avg class xent loss = 43.3041\n",
      "(0:3:49) s 130/143, e 1 avg class xent loss = 39.6319\n",
      "(0:3:56) s 140/143, e 1 avg class xent loss = 39.7825\n",
      "Macro P: 2.6741, R: 2.5261, F1: 2.5980\n",
      "(0:4:4) s 0/143, e 2 avg class xent loss = 40.2293\n",
      "================================================================================\n",
      "(0:4:10) s 0/143, e 2 validation avg class xent loss = 41.6781\n",
      "================================================================================\n",
      "(0:4:17) s 10/143, e 2 avg class xent loss = 39.9968\n",
      "(0:4:24) s 20/143, e 2 avg class xent loss = 43.6453\n",
      "(0:4:30) s 30/143, e 2 avg class xent loss = 39.4966\n",
      "(0:4:37) s 40/143, e 2 avg class xent loss = 43.6246\n",
      "(0:4:45) s 50/143, e 2 avg class xent loss = 40.8383\n",
      "================================================================================\n",
      "(0:4:51) s 50/143, e 2 validation avg class xent loss = 42.8738\n",
      "================================================================================\n",
      "(0:4:57) s 60/143, e 2 avg class xent loss = 40.8703\n",
      "(0:5:4) s 70/143, e 2 avg class xent loss = 41.0301\n",
      "(0:5:11) s 80/143, e 2 avg class xent loss = 36.8304\n",
      "(0:5:18) s 90/143, e 2 avg class xent loss = 43.2969\n",
      "(0:5:25) s 100/143, e 2 avg class xent loss = 44.8100\n",
      "================================================================================\n",
      "(0:5:31) s 100/143, e 2 validation avg class xent loss = 42.6801\n",
      "================================================================================\n",
      "(0:5:38) s 110/143, e 2 avg class xent loss = 40.1084\n",
      "(0:5:45) s 120/143, e 2 avg class xent loss = 39.6048\n",
      "(0:5:52) s 130/143, e 2 avg class xent loss = 38.0288\n",
      "(0:5:59) s 140/143, e 2 avg class xent loss = 36.2998\n",
      "Macro P: 5.9151, R: 3.8279, F1: 4.6479\n",
      "(0:6:7) s 0/143, e 3 avg class xent loss = 41.9606\n",
      "================================================================================\n",
      "(0:6:13) s 0/143, e 3 validation avg class xent loss = 41.9656\n",
      "================================================================================\n",
      "(0:6:20) s 10/143, e 3 avg class xent loss = 42.6479\n",
      "(0:6:26) s 20/143, e 3 avg class xent loss = 42.9550\n",
      "(0:6:33) s 30/143, e 3 avg class xent loss = 34.8963\n",
      "(0:6:40) s 40/143, e 3 avg class xent loss = 39.8227\n",
      "(0:6:47) s 50/143, e 3 avg class xent loss = 41.7722\n",
      "================================================================================\n",
      "(0:6:53) s 50/143, e 3 validation avg class xent loss = 42.2615\n",
      "================================================================================\n",
      "(0:7:0) s 60/143, e 3 avg class xent loss = 38.2692\n",
      "(0:7:7) s 70/143, e 3 avg class xent loss = 39.7982\n",
      "(0:7:14) s 80/143, e 3 avg class xent loss = 36.5284\n",
      "(0:7:20) s 90/143, e 3 avg class xent loss = 40.0351\n",
      "(0:7:27) s 100/143, e 3 avg class xent loss = 42.7349\n",
      "================================================================================\n",
      "(0:7:33) s 100/143, e 3 validation avg class xent loss = 42.8817\n",
      "================================================================================\n",
      "(0:7:40) s 110/143, e 3 avg class xent loss = 40.1576\n",
      "(0:7:47) s 120/143, e 3 avg class xent loss = 39.0423\n",
      "(0:7:54) s 130/143, e 3 avg class xent loss = 37.9536\n",
      "(0:8:1) s 140/143, e 3 avg class xent loss = 38.4127\n",
      "Macro P: 4.8224, R: 3.8448, F1: 4.2785\n",
      "(0:8:9) s 0/143, e 4 avg class xent loss = 43.6628\n",
      "================================================================================\n",
      "(0:8:15) s 0/143, e 4 validation avg class xent loss = 42.9567\n",
      "================================================================================\n",
      "(0:8:22) s 10/143, e 4 avg class xent loss = 41.6422\n",
      "(0:8:28) s 20/143, e 4 avg class xent loss = 43.5018\n",
      "(0:8:35) s 30/143, e 4 avg class xent loss = 38.9627\n",
      "(0:8:42) s 40/143, e 4 avg class xent loss = 45.9395\n",
      "(0:8:49) s 50/143, e 4 avg class xent loss = 41.7805\n",
      "================================================================================\n",
      "(0:8:55) s 50/143, e 4 validation avg class xent loss = 42.6640\n",
      "================================================================================\n",
      "(0:9:2) s 60/143, e 4 avg class xent loss = 39.0203\n",
      "(0:9:9) s 70/143, e 4 avg class xent loss = 37.3676\n",
      "(0:9:16) s 80/143, e 4 avg class xent loss = 41.9029\n",
      "(0:9:23) s 90/143, e 4 avg class xent loss = 41.6782\n",
      "(0:9:30) s 100/143, e 4 avg class xent loss = 41.7671\n",
      "================================================================================\n",
      "(0:9:36) s 100/143, e 4 validation avg class xent loss = 42.3742\n",
      "================================================================================\n",
      "(0:9:42) s 110/143, e 4 avg class xent loss = 36.0674\n",
      "(0:9:49) s 120/143, e 4 avg class xent loss = 42.2089\n",
      "(0:9:57) s 130/143, e 4 avg class xent loss = 39.2461\n",
      "(0:10:3) s 140/143, e 4 avg class xent loss = 41.7391\n",
      "Macro P: 8.2988, R: 3.0500, F1: 4.4606\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-4004-17912\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "CYCLE 9\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "===== UNSUPERVISED TRAINING =====\n",
      "(0:0:1) step 0/143, epoch 0 Training Loss = 7.88591 :: 2771.873 phrases/sec :: (0:1:5) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <pathologists> '<X> do with <Y>' <scalpel>\n",
      "0: 1.000 : <pathologists> '<X> do with <Y>' <scalpel>\n",
      "1: 1.000 : <parents> '<X> killed with <Y>' <pills>\n",
      "2: 1.000 : <accused> '<X> killed with <Y>' <kirpan>\n",
      "3: 1.000 : <editor> '<X> improved with <Y>' <changes>\n",
      "4: 1.000 : <suitcase> '<X> with <Y>' <clothing>\n",
      "5: 1.000 : <users> '<X> navigate with <Y>' <keyboard>\n",
      "6: 1.000 : <user> '<X> accesses menu with <Y>' <keyboard>\n",
      "7: 1.000 : <performer> '<X> covers with <Y>' <newspaper>\n",
      "8: 1.000 : <crew> '<X> assisted with <Y>' <investigation>\n",
      "9: 1.000 : <uncle> '<X> liberated with <Y>' <uncle>\n",
      "10: 0.998 : <sword> '<X> appears in photograph with <Y>' <hilt>\n",
      "11: 0.997 : <crime> '<X> fiction is genre deals with <Y>' <crimes>\n",
      "12: 0.997 : <book> '<X> dealt with <Y>' <impact>\n",
      "13: 0.995 : <philosophy> '<X> of branch dealing with <Y>' <nature>\n",
      "14: 0.984 : <burglar> '<X> forgot log before leaving with <Y>' <rings>\n",
      "15: 0.978 : <suitcase> '<X> with <Y>' <bomb>\n",
      "16: 0.977 : <tube> '<X> cut with <Y>' <knife>\n",
      "17: 0.977 : <sections> '<X> denoted with <Y>' <asterisk>\n",
      "18: 0.976 : <documents> '<X> do with <Y>' <finance>\n",
      "19: 0.975 : <sailor> '<X> with <Y>' <musket>\n",
      "================================================================================\n",
      "Validation loss: 8.3290\n",
      "(0:0:17) step 10/143, epoch 0 Training Loss = 7.39051 :: 1456.946 phrases/sec :: (0:1:50) hours left\n",
      "(0:0:33) step 20/143, epoch 0 Training Loss = 6.89220 :: 1388.659 phrases/sec :: (0:1:40) hours left\n",
      "(0:0:50) step 30/143, epoch 0 Training Loss = 6.42719 :: 1370.175 phrases/sec :: (0:1:26) hours left\n",
      "(0:1:6) step 40/143, epoch 0 Training Loss = 6.06720 :: 1354.824 phrases/sec :: (0:1:11) hours left\n",
      "(0:1:22) step 50/143, epoch 0 Training Loss = 5.72866 :: 1339.916 phrases/sec :: (0:0:57) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <boy> '<X> was in <Y>' <desk>\n",
      "0: 1.000 : <species> '<X> in <Y>' <forest>\n",
      "1: 1.000 : <wall> '<X> in <Y>' <shop>\n",
      "2: 1.000 : <meat> '<X> of piece was in <Y>' <can>\n",
      "3: 1.000 : <boy> '<X> was in <Y>' <desk>\n",
      "4: 1.000 : <switchboard> '<X> in <Y>' <engine>\n",
      "5: 1.000 : <ingredients> '<X> of many in <Y>' <basket>\n",
      "6: 1.000 : <garment> '<X> found in <Y>' <reliquary>\n",
      "7: 1.000 : <awards> '<X> for apply in <Y>' <areas>\n",
      "8: 0.999 : <cell> '<X> mass measuring in <Y>' <flask>\n",
      "9: 0.999 : <charges> '<X> originated in <Y>' <blackmail>\n",
      "10: 0.999 : <citations> '<X> references appear in <Y>' <book>\n",
      "11: 0.999 : <arsenic> '<X> originated in <Y>' <coatings>\n",
      "12: 0.999 : <play> '<X> starts in <Y>' <state>\n",
      "13: 0.999 : <killings> '<X> resulted in <Y>' <firing>\n",
      "14: 0.999 : <book> '<X> is rich in <Y>' <exercises>\n",
      "15: 0.999 : <guard> '<X> participates in <Y>' <ceremony>\n",
      "16: 0.999 : <cocaine> '<X> was in <Y>' <crate>\n",
      "17: 0.999 : <blazer> '<X> was in <Y>' <bin>\n",
      "18: 0.999 : <place> '<X> was in <Y>' <desk>\n",
      "19: 0.999 : <model> '<X> was in <Y>' <jar>\n",
      "================================================================================\n",
      "Validation loss: 7.8390\n",
      "(0:1:38) step 60/143, epoch 0 Training Loss = 5.36960 :: 1336.992 phrases/sec :: (0:0:41) hours left\n",
      "(0:1:54) step 70/143, epoch 0 Training Loss = 5.07465 :: 1328.029 phrases/sec :: (0:0:25) hours left\n",
      "(0:2:10) step 80/143, epoch 0 Training Loss = 4.75496 :: 1324.169 phrases/sec :: (0:0:10) hours left\n",
      "(0:2:25) step 90/143, epoch 0 Training Loss = 4.46901 :: 1324.914 phrases/sec :: (-1:59:55) hours left\n",
      "(0:2:41) step 100/143, epoch 0 Training Loss = 4.24447 :: 1321.083 phrases/sec :: (-1:59:39) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <needle> '<X> inserted into <Y>' <machine>\n",
      "0: 1.000 : <keys> '<X> added into <Y>' <memory>\n",
      "1: 1.000 : <sewage> '<X> dumped into <Y>' <river>\n",
      "2: 1.000 : <needle> '<X> inserted into <Y>' <machine>\n",
      "3: 1.000 : <sound> '<X> inserted into <Y>' <announcements>\n",
      "4: 1.000 : <stack> '<X> loading into <Y>' <carton>\n",
      "5: 1.000 : <billions> '<X> pouring into <Y>' <nanotechnology>\n",
      "6: 1.000 : <beakers> '<X> pouring into <Y>' <formula>\n",
      "7: 1.000 : <integration> '<X> released into <Y>' <networks>\n",
      "8: 1.000 : <steroids> '<X> inject into <Y>' <muscles>\n",
      "9: 1.000 : <system> '<X> translates into <Y>' <speech>\n",
      "10: 1.000 : <empathy> '<X> poured into <Y>' <poetry>\n",
      "11: 1.000 : <billion> '<X> poured into <Y>' <economy>\n",
      "12: 1.000 : <concrete> '<X> poured into <Y>' <hull>\n",
      "13: 1.000 : <flour> '<X> poured into <Y>' <dragon>\n",
      "14: 1.000 : <aluminium> '<X> poured into <Y>' <ingots>\n",
      "15: 1.000 : <flour> '<X> poured into <Y>' <pan>\n",
      "16: 1.000 : <gallon> '<X> put into <Y>' <cart>\n",
      "17: 1.000 : <penny> '<X> put into <Y>' <machines>\n",
      "18: 1.000 : <poodle> '<X> fetched into <Y>' <acre>\n",
      "19: 1.000 : <wetlands> '<X> draining into <Y>' <ditches>\n",
      "================================================================================\n",
      "Validation loss: 6.6734\n",
      "(0:2:57) step 110/143, epoch 0 Training Loss = 3.96757 :: 1321.600 phrases/sec :: (-1:59:23) hours left\n",
      "(0:3:13) step 120/143, epoch 0 Training Loss = 3.75719 :: 1322.142 phrases/sec :: (-1:59:7) hours left\n",
      "(0:3:29) step 130/143, epoch 0 Training Loss = 3.55091 :: 1319.329 phrases/sec :: (-1:58:51) hours left\n",
      "(0:3:45) step 140/143, epoch 0 Training Loss = 3.35935 :: 1318.823 phrases/sec :: (-1:58:36) hours left\n",
      "Macro P: 1.2345, R: 5.9358, F1: 2.0440\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-4147-17912\n",
      "143\n",
      "***** SUPERVISED TRAINING *****\n",
      "(0:0:0) s 0/143, e 0 avg class xent loss = 35.4091\n",
      "================================================================================\n",
      "(0:0:6) s 0/143, e 0 validation avg class xent loss = 43.7284\n",
      "================================================================================\n",
      "(0:0:13) s 10/143, e 0 avg class xent loss = 49.5417\n",
      "(0:0:20) s 20/143, e 0 avg class xent loss = 44.3271\n",
      "(0:0:27) s 30/143, e 0 avg class xent loss = 38.3205\n",
      "(0:0:34) s 40/143, e 0 avg class xent loss = 44.5679\n",
      "(0:0:40) s 50/143, e 0 avg class xent loss = 42.9499\n",
      "================================================================================\n",
      "(0:0:47) s 50/143, e 0 validation avg class xent loss = 43.1925\n",
      "================================================================================\n",
      "(0:0:54) s 60/143, e 0 avg class xent loss = 36.9274\n",
      "(0:1:1) s 70/143, e 0 avg class xent loss = 39.5359\n",
      "(0:1:7) s 80/143, e 0 avg class xent loss = 43.1729\n",
      "(0:1:14) s 90/143, e 0 avg class xent loss = 41.2953\n",
      "(0:1:21) s 100/143, e 0 avg class xent loss = 41.7402\n",
      "================================================================================\n",
      "(0:1:27) s 100/143, e 0 validation avg class xent loss = 43.4392\n",
      "================================================================================\n",
      "(0:1:34) s 110/143, e 0 avg class xent loss = 43.4017\n",
      "(0:1:41) s 120/143, e 0 avg class xent loss = 38.1345\n",
      "(0:1:48) s 130/143, e 0 avg class xent loss = 35.1649\n",
      "(0:1:55) s 140/143, e 0 avg class xent loss = 35.4036\n",
      "Macro P: 6.0019, R: 3.3735, F1: 4.3192\n",
      "(0:2:2) s 0/143, e 1 avg class xent loss = 45.2890\n",
      "================================================================================\n",
      "(0:2:8) s 0/143, e 1 validation avg class xent loss = 42.5119\n",
      "================================================================================\n",
      "(0:2:15) s 10/143, e 1 avg class xent loss = 39.6796\n",
      "(0:2:22) s 20/143, e 1 avg class xent loss = 48.8499\n",
      "(0:2:29) s 30/143, e 1 avg class xent loss = 38.1166\n",
      "(0:2:36) s 40/143, e 1 avg class xent loss = 44.8088\n",
      "(0:2:43) s 50/143, e 1 avg class xent loss = 42.0616\n",
      "================================================================================\n",
      "(0:2:49) s 50/143, e 1 validation avg class xent loss = 42.8708\n",
      "================================================================================\n",
      "(0:2:56) s 60/143, e 1 avg class xent loss = 37.3747\n",
      "(0:3:3) s 70/143, e 1 avg class xent loss = 42.7622\n",
      "(0:3:10) s 80/143, e 1 avg class xent loss = 39.3935\n",
      "(0:3:16) s 90/143, e 1 avg class xent loss = 39.3529\n",
      "(0:3:23) s 100/143, e 1 avg class xent loss = 45.1421\n",
      "================================================================================\n",
      "(0:3:30) s 100/143, e 1 validation avg class xent loss = 43.1544\n",
      "================================================================================\n",
      "(0:3:36) s 110/143, e 1 avg class xent loss = 37.2235\n",
      "(0:3:43) s 120/143, e 1 avg class xent loss = 36.2423\n",
      "(0:3:50) s 130/143, e 1 avg class xent loss = 37.0279\n",
      "(0:3:57) s 140/143, e 1 avg class xent loss = 36.6610\n",
      "Macro P: 2.6622, R: 7.2944, F1: 3.9008\n",
      "(0:4:5) s 0/143, e 2 avg class xent loss = 46.0781\n",
      "================================================================================\n",
      "(0:4:11) s 0/143, e 2 validation avg class xent loss = 42.3201\n",
      "================================================================================\n",
      "(0:4:18) s 10/143, e 2 avg class xent loss = 42.3264\n",
      "(0:4:24) s 20/143, e 2 avg class xent loss = 42.4653\n",
      "(0:4:31) s 30/143, e 2 avg class xent loss = 41.2707\n",
      "(0:4:38) s 40/143, e 2 avg class xent loss = 44.8311\n",
      "(0:4:45) s 50/143, e 2 avg class xent loss = 42.8468\n",
      "================================================================================\n",
      "(0:4:51) s 50/143, e 2 validation avg class xent loss = 42.5608\n",
      "================================================================================\n",
      "(0:4:58) s 60/143, e 2 avg class xent loss = 40.2301\n",
      "(0:5:5) s 70/143, e 2 avg class xent loss = 38.2478\n",
      "(0:5:12) s 80/143, e 2 avg class xent loss = 43.1954\n",
      "(0:5:19) s 90/143, e 2 avg class xent loss = 41.5582\n",
      "(0:5:26) s 100/143, e 2 avg class xent loss = 42.2366\n",
      "================================================================================\n",
      "(0:5:32) s 100/143, e 2 validation avg class xent loss = 42.8938\n",
      "================================================================================\n",
      "(0:5:38) s 110/143, e 2 avg class xent loss = 39.3835\n",
      "(0:5:45) s 120/143, e 2 avg class xent loss = 37.8771\n",
      "(0:5:52) s 130/143, e 2 avg class xent loss = 41.9054\n",
      "(0:5:59) s 140/143, e 2 avg class xent loss = 39.9417\n",
      "Macro P: 5.0391, R: 3.2685, F1: 3.9651\n",
      "(0:6:7) s 0/143, e 3 avg class xent loss = 43.8404\n",
      "================================================================================\n",
      "(0:6:13) s 0/143, e 3 validation avg class xent loss = 42.6583\n",
      "================================================================================\n",
      "(0:6:20) s 10/143, e 3 avg class xent loss = 45.3682\n",
      "(0:6:27) s 20/143, e 3 avg class xent loss = 43.8016\n",
      "(0:6:34) s 30/143, e 3 avg class xent loss = 35.8468\n",
      "(0:6:40) s 40/143, e 3 avg class xent loss = 43.5750\n",
      "(0:6:47) s 50/143, e 3 avg class xent loss = 41.1760\n",
      "================================================================================\n",
      "(0:6:53) s 50/143, e 3 validation avg class xent loss = 42.5035\n",
      "================================================================================\n",
      "(0:7:0) s 60/143, e 3 avg class xent loss = 39.1393\n",
      "(0:7:7) s 70/143, e 3 avg class xent loss = 42.3434\n",
      "(0:7:14) s 80/143, e 3 avg class xent loss = 42.4528\n",
      "(0:7:21) s 90/143, e 3 avg class xent loss = 42.5860\n",
      "(0:7:28) s 100/143, e 3 avg class xent loss = 48.4506\n",
      "================================================================================\n",
      "(0:7:34) s 100/143, e 3 validation avg class xent loss = 42.2452\n",
      "================================================================================\n",
      "(0:7:41) s 110/143, e 3 avg class xent loss = 37.7045\n",
      "(0:7:48) s 120/143, e 3 avg class xent loss = 41.9150\n",
      "(0:7:55) s 130/143, e 3 avg class xent loss = 34.1012\n",
      "(0:8:1) s 140/143, e 3 avg class xent loss = 42.0358\n",
      "Macro P: 5.7091, R: 4.1929, F1: 4.8349\n",
      "(0:8:9) s 0/143, e 4 avg class xent loss = 40.0741\n",
      "================================================================================\n",
      "(0:8:15) s 0/143, e 4 validation avg class xent loss = 42.3573\n",
      "================================================================================\n",
      "(0:8:22) s 10/143, e 4 avg class xent loss = 38.3825\n",
      "(0:8:29) s 20/143, e 4 avg class xent loss = 40.3640\n",
      "(0:8:36) s 30/143, e 4 avg class xent loss = 37.9805\n",
      "(0:8:43) s 40/143, e 4 avg class xent loss = 44.3693\n",
      "(0:8:50) s 50/143, e 4 avg class xent loss = 38.3686\n",
      "================================================================================\n",
      "(0:8:56) s 50/143, e 4 validation avg class xent loss = 42.2819\n",
      "================================================================================\n",
      "(0:9:3) s 60/143, e 4 avg class xent loss = 40.6413\n",
      "(0:9:10) s 70/143, e 4 avg class xent loss = 41.2046\n",
      "(0:9:17) s 80/143, e 4 avg class xent loss = 37.0872\n",
      "(0:9:24) s 90/143, e 4 avg class xent loss = 44.2737\n",
      "(0:9:31) s 100/143, e 4 avg class xent loss = 39.8118\n",
      "================================================================================\n",
      "(0:9:37) s 100/143, e 4 validation avg class xent loss = 41.8026\n",
      "================================================================================\n",
      "(0:9:44) s 110/143, e 4 avg class xent loss = 38.0537\n",
      "(0:9:51) s 120/143, e 4 avg class xent loss = 41.7928\n",
      "(0:9:57) s 130/143, e 4 avg class xent loss = 38.4905\n",
      "(0:10:4) s 140/143, e 4 avg class xent loss = 41.1506\n",
      "Macro P: 4.5875, R: 6.1863, F1: 5.2682\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-4147-18622\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "CYCLE 10\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "===== UNSUPERVISED TRAINING =====\n",
      "(0:0:1) step 0/143, epoch 0 Training Loss = 7.88864 :: 2635.885 phrases/sec :: (0:1:8) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <coil> '<X> of <Y>' <galvanometer>\n",
      "0: 1.000 : <coil> '<X> of <Y>' <galvanometer>\n",
      "1: 1.000 : <author> '<X> of <Y>' <book>\n",
      "2: 1.000 : <components> '<X> of <Y>' <system>\n",
      "3: 1.000 : <clergy> '<X> of <Y>' <denominations>\n",
      "4: 1.000 : <stem> '<X> of <Y>' <tree>\n",
      "5: 1.000 : <richness> '<X> of <Y>' <martens>\n",
      "6: 1.000 : <bottle> '<X> full of <Y>' <air>\n",
      "7: 0.994 : <brotherhood> '<X> of <Y>' <rogues>\n",
      "8: 0.994 : <handful> '<X> of <Y>' <images>\n",
      "9: 0.994 : <squad> '<X> of <Y>' <policemen>\n",
      "10: 0.994 : <charm> '<X> of <Y>' <goldfinches>\n",
      "11: 0.994 : <phalanx> '<X> of <Y>' <umbrellas>\n",
      "12: 0.994 : <chin> '<X> of <Y>' <rockfish>\n",
      "13: 0.994 : <maze> '<X> of <Y>' <jurisdictions>\n",
      "14: 0.994 : <wheel> '<X> of <Y>' <panel>\n",
      "15: 0.994 : <devision> '<X> of <Y>' <crossbowmen>\n",
      "16: 0.994 : <minority> '<X> of <Y>' <physicians>\n",
      "17: 0.994 : <flight> '<X> of <Y>' <aircrafts>\n",
      "18: 0.994 : <fit> '<X> of <Y>' <jacket>\n",
      "19: 0.994 : <indicator> '<X> of <Y>' <transmitter>\n",
      "================================================================================\n",
      "Validation loss: 8.2118\n",
      "(0:0:17) step 10/143, epoch 0 Training Loss = 7.34461 :: 1450.473 phrases/sec :: (0:1:51) hours left\n",
      "(0:0:34) step 20/143, epoch 0 Training Loss = 6.84483 :: 1362.310 phrases/sec :: (0:1:42) hours left\n",
      "(0:0:50) step 30/143, epoch 0 Training Loss = 6.47240 :: 1348.057 phrases/sec :: (0:1:28) hours left\n",
      "(0:1:5) step 40/143, epoch 0 Training Loss = 6.09782 :: 1333.651 phrases/sec :: (0:1:14) hours left\n",
      "(0:1:21) step 50/143, epoch 0 Training Loss = 5.70853 :: 1331.917 phrases/sec :: (0:0:58) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <fire> '<X> venting from floor of <Y>' <building>\n",
      "0: 1.000 : <fire> '<X> venting from floor of <Y>' <building>\n",
      "1: 0.977 : <insert> '<X> placed inside of <Y>' <machine>\n",
      "2: 0.969 : <intestines> '<X> are part of system <Y>' <gastrointestinal>\n",
      "3: 0.959 : <puppet> '<X> recorded string of <Y>' <records>\n",
      "4: 0.959 : <downturn> '<X> in wake of <Y>' <bombs>\n",
      "5: 0.959 : <book> '<X> is triumph from pen of <Y>' <reporter>\n",
      "6: 0.958 : <goatfish> '<X> use pair of <Y>' <barbels>\n",
      "7: 0.957 : <flag> '<X> popped out of <Y>' <corpse>\n",
      "8: 0.957 : <member> '<X> takes in activity of <Y>' <organisation>\n",
      "9: 0.954 : <mountain> '<X> formed grew from depths of <Y>' <ocean>\n",
      "10: 0.951 : <ingredients> '<X> of many in <Y>' <basket>\n",
      "11: 0.951 : <turtle> '<X> pushing in front of <Y>' <mouth>\n",
      "12: 0.949 : <muscles> '<X> are parts of <Y>' <body>\n",
      "13: 0.946 : <comments> '<X> are parts of code <Y>' <source>\n",
      "14: 0.945 : <house> '<X> was full of <Y>' <items>\n",
      "15: 0.944 : <couple> '<X> relaxes with cup of <Y>' <coffee>\n",
      "16: 0.943 : <bar> '<X> builds out of <Y>' <cans>\n",
      "17: 0.943 : <boy> '<X> builds out of <Y>' <junk>\n",
      "18: 0.942 : <experts> '<X> said contributes creation of <Y>' <facilities>\n",
      "19: 0.941 : <transmission> '<X> of commencement of time mark from <Y>' <transmitter>\n",
      "================================================================================\n",
      "Validation loss: 7.0804\n",
      "(0:1:37) step 60/143, epoch 0 Training Loss = 5.36488 :: 1333.608 phrases/sec :: (0:0:42) hours left\n",
      "(0:1:53) step 70/143, epoch 0 Training Loss = 5.06065 :: 1331.578 phrases/sec :: (0:0:26) hours left\n",
      "(0:2:9) step 80/143, epoch 0 Training Loss = 4.75307 :: 1330.174 phrases/sec :: (0:0:11) hours left\n",
      "(0:2:25) step 90/143, epoch 0 Training Loss = 4.48455 :: 1324.384 phrases/sec :: (-1:59:55) hours left\n",
      "(0:2:40) step 100/143, epoch 0 Training Loss = 4.23556 :: 1326.257 phrases/sec :: (-1:59:39) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <mountain> '<X> formed grew from depths of <Y>' <ocean>\n",
      "0: 1.000 : <mountain> '<X> formed grew from depths of <Y>' <ocean>\n",
      "1: 0.996 : <welcome> '<X> speech of <Y>' <conference>\n",
      "2: 0.995 : <index> '<X> generated from <Y>' <surface>\n",
      "3: 0.995 : <house> '<X> was full of <Y>' <items>\n",
      "4: 0.995 : <fire> '<X> venting from floor of <Y>' <building>\n",
      "5: 0.994 : <urine> '<X> output of <Y>' <adults>\n",
      "6: 0.994 : <sergeant> '<X> major of <Y>' <army>\n",
      "7: 0.994 : <whirl> '<X> hedge of <Y>' <herons>\n",
      "8: 0.994 : <book> '<X> is triumph from pen of <Y>' <reporter>\n",
      "9: 0.994 : <mycoses> '<X> caused by group of <Y>' <fungi>\n",
      "10: 0.994 : <conference> '<X> held on topic of <Y>' <prevention>\n",
      "11: 0.994 : <eggs> '<X> come out of <Y>' <body>\n",
      "12: 0.994 : <bottle> '<X> full of <Y>' <air>\n",
      "13: 0.994 : <coil> '<X> of <Y>' <galvanometer>\n",
      "14: 0.994 : <author> '<X> of <Y>' <book>\n",
      "15: 0.994 : <components> '<X> of <Y>' <system>\n",
      "16: 0.994 : <clergy> '<X> of <Y>' <denominations>\n",
      "17: 0.994 : <stem> '<X> of <Y>' <tree>\n",
      "18: 0.994 : <richness> '<X> of <Y>' <martens>\n",
      "19: 0.991 : <jobs> '<X> was point of <Y>' <speech>\n",
      "================================================================================\n",
      "Validation loss: 6.0857\n",
      "(0:2:57) step 110/143, epoch 0 Training Loss = 3.96871 :: 1322.931 phrases/sec :: (-1:59:23) hours left\n",
      "(0:3:13) step 120/143, epoch 0 Training Loss = 3.75940 :: 1319.347 phrases/sec :: (-1:59:7) hours left\n",
      "(0:3:29) step 130/143, epoch 0 Training Loss = 3.52508 :: 1320.369 phrases/sec :: (-1:58:51) hours left\n",
      "(0:3:45) step 140/143, epoch 0 Training Loss = 3.39173 :: 1320.653 phrases/sec :: (-1:58:35) hours left\n",
      "Macro P: 1.6634, R: 4.7247, F1: 2.4605\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-4290-18622\n",
      "143\n",
      "***** SUPERVISED TRAINING *****\n",
      "(0:0:0) s 0/143, e 0 avg class xent loss = 42.8833\n",
      "================================================================================\n",
      "(0:0:6) s 0/143, e 0 validation avg class xent loss = 42.5602\n",
      "================================================================================\n",
      "(0:0:13) s 10/143, e 0 avg class xent loss = 48.7155\n",
      "(0:0:20) s 20/143, e 0 avg class xent loss = 42.7379\n",
      "(0:0:27) s 30/143, e 0 avg class xent loss = 40.7043\n",
      "(0:0:34) s 40/143, e 0 avg class xent loss = 44.7895\n",
      "(0:0:41) s 50/143, e 0 avg class xent loss = 39.6997\n",
      "================================================================================\n",
      "(0:0:47) s 50/143, e 0 validation avg class xent loss = 41.8274\n",
      "================================================================================\n",
      "(0:0:54) s 60/143, e 0 avg class xent loss = 35.6645\n",
      "(0:1:1) s 70/143, e 0 avg class xent loss = 40.7159\n",
      "(0:1:8) s 80/143, e 0 avg class xent loss = 40.4992\n",
      "(0:1:14) s 90/143, e 0 avg class xent loss = 42.6126\n",
      "(0:1:21) s 100/143, e 0 avg class xent loss = 41.4713\n",
      "================================================================================\n",
      "(0:1:27) s 100/143, e 0 validation avg class xent loss = 41.9622\n",
      "================================================================================\n",
      "(0:1:34) s 110/143, e 0 avg class xent loss = 42.5396\n",
      "(0:1:41) s 120/143, e 0 avg class xent loss = 39.3512\n",
      "(0:1:48) s 130/143, e 0 avg class xent loss = 40.4465\n",
      "(0:1:55) s 140/143, e 0 avg class xent loss = 41.9211\n",
      "Macro P: 3.9658, R: 6.7149, F1: 4.9865\n",
      "(0:2:2) s 0/143, e 1 avg class xent loss = 39.2790\n",
      "================================================================================\n",
      "(0:2:9) s 0/143, e 1 validation avg class xent loss = 42.2577\n",
      "================================================================================\n",
      "(0:2:16) s 10/143, e 1 avg class xent loss = 43.1035\n",
      "(0:2:22) s 20/143, e 1 avg class xent loss = 44.8088\n",
      "(0:2:29) s 30/143, e 1 avg class xent loss = 40.9410\n",
      "(0:2:36) s 40/143, e 1 avg class xent loss = 48.2312\n",
      "(0:2:43) s 50/143, e 1 avg class xent loss = 41.2080\n",
      "================================================================================\n",
      "(0:2:49) s 50/143, e 1 validation avg class xent loss = 42.6080\n",
      "================================================================================\n",
      "(0:2:56) s 60/143, e 1 avg class xent loss = 39.2603\n",
      "(0:3:3) s 70/143, e 1 avg class xent loss = 37.6223\n",
      "(0:3:10) s 80/143, e 1 avg class xent loss = 40.3734\n",
      "(0:3:17) s 90/143, e 1 avg class xent loss = 40.6773\n",
      "(0:3:24) s 100/143, e 1 avg class xent loss = 38.0058\n",
      "================================================================================\n",
      "(0:3:30) s 100/143, e 1 validation avg class xent loss = 41.9807\n",
      "================================================================================\n",
      "(0:3:37) s 110/143, e 1 avg class xent loss = 36.7591\n",
      "(0:3:44) s 120/143, e 1 avg class xent loss = 44.8550\n",
      "(0:3:50) s 130/143, e 1 avg class xent loss = 38.7910\n",
      "(0:3:57) s 140/143, e 1 avg class xent loss = 37.8989\n",
      "Macro P: 8.9009, R: 6.2540, F1: 7.3463\n",
      "(0:4:5) s 0/143, e 2 avg class xent loss = 41.2892\n",
      "================================================================================\n",
      "(0:4:11) s 0/143, e 2 validation avg class xent loss = 41.8585\n",
      "================================================================================\n",
      "(0:4:18) s 10/143, e 2 avg class xent loss = 37.6929\n",
      "(0:4:25) s 20/143, e 2 avg class xent loss = 47.3642\n",
      "(0:4:32) s 30/143, e 2 avg class xent loss = 40.6188\n",
      "(0:4:39) s 40/143, e 2 avg class xent loss = 40.6959\n",
      "(0:4:45) s 50/143, e 2 avg class xent loss = 36.8691\n",
      "================================================================================\n",
      "(0:4:52) s 50/143, e 2 validation avg class xent loss = 42.0244\n",
      "================================================================================\n",
      "(0:4:59) s 60/143, e 2 avg class xent loss = 40.5797\n",
      "(0:5:5) s 70/143, e 2 avg class xent loss = 41.7450\n",
      "(0:5:12) s 80/143, e 2 avg class xent loss = 37.4413\n",
      "(0:5:19) s 90/143, e 2 avg class xent loss = 39.6261\n",
      "(0:5:26) s 100/143, e 2 avg class xent loss = 41.9433\n",
      "================================================================================\n",
      "(0:5:32) s 100/143, e 2 validation avg class xent loss = 41.6943\n",
      "================================================================================\n",
      "(0:5:39) s 110/143, e 2 avg class xent loss = 40.8708\n",
      "(0:5:46) s 120/143, e 2 avg class xent loss = 45.3038\n",
      "(0:5:53) s 130/143, e 2 avg class xent loss = 40.4238\n",
      "(0:6:0) s 140/143, e 2 avg class xent loss = 40.8259\n",
      "Macro P: 5.8638, R: 6.4642, F1: 6.1494\n",
      "(0:6:7) s 0/143, e 3 avg class xent loss = 46.1360\n",
      "================================================================================\n",
      "(0:6:13) s 0/143, e 3 validation avg class xent loss = 41.3857\n",
      "================================================================================\n",
      "(0:6:20) s 10/143, e 3 avg class xent loss = 39.0052\n",
      "(0:6:27) s 20/143, e 3 avg class xent loss = 41.6976\n",
      "(0:6:34) s 30/143, e 3 avg class xent loss = 38.9670\n",
      "(0:6:41) s 40/143, e 3 avg class xent loss = 41.7041\n",
      "(0:6:48) s 50/143, e 3 avg class xent loss = 37.3357\n",
      "================================================================================\n",
      "(0:6:54) s 50/143, e 3 validation avg class xent loss = 42.5463\n",
      "================================================================================\n",
      "(0:7:1) s 60/143, e 3 avg class xent loss = 37.7845\n",
      "(0:7:8) s 70/143, e 3 avg class xent loss = 40.3288\n",
      "(0:7:15) s 80/143, e 3 avg class xent loss = 36.5945\n",
      "(0:7:22) s 90/143, e 3 avg class xent loss = 36.5747\n",
      "(0:7:29) s 100/143, e 3 avg class xent loss = 37.9682\n",
      "================================================================================\n",
      "(0:7:35) s 100/143, e 3 validation avg class xent loss = 41.2135\n",
      "================================================================================\n",
      "(0:7:42) s 110/143, e 3 avg class xent loss = 37.6491\n",
      "(0:7:49) s 120/143, e 3 avg class xent loss = 39.3131\n",
      "(0:7:56) s 130/143, e 3 avg class xent loss = 40.3005\n",
      "(0:8:2) s 140/143, e 3 avg class xent loss = 39.1866\n",
      "Macro P: 3.5641, R: 4.9824, F1: 4.1555\n",
      "(0:8:10) s 0/143, e 4 avg class xent loss = 43.0813\n",
      "================================================================================\n",
      "(0:8:16) s 0/143, e 4 validation avg class xent loss = 42.2361\n",
      "================================================================================\n",
      "(0:8:23) s 10/143, e 4 avg class xent loss = 37.5566\n",
      "(0:8:30) s 20/143, e 4 avg class xent loss = 46.0408\n",
      "(0:8:37) s 30/143, e 4 avg class xent loss = 37.4046\n",
      "(0:8:44) s 40/143, e 4 avg class xent loss = 45.6237\n",
      "(0:8:51) s 50/143, e 4 avg class xent loss = 39.7582\n",
      "================================================================================\n",
      "(0:8:57) s 50/143, e 4 validation avg class xent loss = 42.4273\n",
      "================================================================================\n",
      "(0:9:4) s 60/143, e 4 avg class xent loss = 33.5890\n",
      "(0:9:11) s 70/143, e 4 avg class xent loss = 37.0834\n",
      "(0:9:17) s 80/143, e 4 avg class xent loss = 40.7054\n",
      "(0:9:24) s 90/143, e 4 avg class xent loss = 40.3989\n",
      "(0:9:31) s 100/143, e 4 avg class xent loss = 39.0920\n",
      "================================================================================\n",
      "(0:9:37) s 100/143, e 4 validation avg class xent loss = 42.2268\n",
      "================================================================================\n",
      "(0:9:44) s 110/143, e 4 avg class xent loss = 38.9036\n",
      "(0:9:51) s 120/143, e 4 avg class xent loss = 41.1129\n",
      "(0:9:58) s 130/143, e 4 avg class xent loss = 39.8022\n",
      "(0:10:5) s 140/143, e 4 avg class xent loss = 40.6304\n",
      "Macro P: 3.7389, R: 4.3749, F1: 4.0320\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-4290-19332\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "CYCLE 11\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "===== UNSUPERVISED TRAINING =====\n",
      "(0:0:1) step 0/143, epoch 0 Training Loss = 7.67481 :: 2691.049 phrases/sec :: (0:1:7) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <alarm> '<X> triggered by workshop catching <Y>' <fire>\n",
      "0: 1.000 : <alarm> '<X> triggered by workshop catching <Y>' <fire>\n",
      "1: 0.952 : <participant> '<X> by adjusted using <Y>' <attenuator>\n",
      "2: 0.944 : <tools> '<X> developed by <Y>' <team>\n",
      "3: 0.943 : <meal> '<X> cooked by <Y>' <chef>\n",
      "4: 0.937 : <news> '<X> by encouraged contain <Y>' <tables>\n",
      "5: 0.937 : <sound> '<X> produced by <Y>' <drum>\n",
      "6: 0.932 : <infraction> '<X> triggered by <Y>' <clot>\n",
      "7: 0.922 : <preparations> '<X> developed by <Y>' <company>\n",
      "8: 0.920 : <influx> '<X> triggered by <Y>' <immigration>\n",
      "9: 0.920 : <interference> '<X> triggered by <Y>' <process>\n",
      "10: 0.920 : <spark> '<X> triggered by <Y>' <beam>\n",
      "11: 0.913 : <rampart> '<X> piled by <Y>' <gangs>\n",
      "12: 0.910 : <conflict> '<X> of interest created by <Y>' <charges>\n",
      "13: 0.908 : <electrodes> '<X> produced by <Y>' <method>\n",
      "14: 0.906 : <film> '<X> made by <Y>' <director>\n",
      "15: 0.902 : <story> '<X> fabricated by <Y>' <sheriff>\n",
      "16: 0.902 : <idea> '<X> sabotaged by <Y>' <script>\n",
      "17: 0.902 : <book> '<X> diminished by <Y>' <way>\n",
      "18: 0.899 : <protein> '<X> produced by <Y>' <pancreas>\n",
      "19: 0.899 : <cocoon> '<X> created by army of <Y>' <caterpillars>\n",
      "================================================================================\n",
      "Validation loss: 8.1568\n",
      "(0:0:18) step 10/143, epoch 0 Training Loss = 7.17038 :: 1412.803 phrases/sec :: (0:1:54) hours left\n",
      "(0:0:34) step 20/143, epoch 0 Training Loss = 6.75867 :: 1364.898 phrases/sec :: (0:1:42) hours left\n",
      "(0:0:50) step 30/143, epoch 0 Training Loss = 6.32839 :: 1334.818 phrases/sec :: (0:1:29) hours left\n",
      "(0:1:6) step 40/143, epoch 0 Training Loss = 5.95754 :: 1328.629 phrases/sec :: (0:1:14) hours left\n",
      "(0:1:21) step 50/143, epoch 0 Training Loss = 5.60374 :: 1334.821 phrases/sec :: (0:0:58) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <building> '<X> leaked from <Y>' <place>\n",
      "0: 1.000 : <building> '<X> leaked from <Y>' <place>\n",
      "1: 0.971 : <panzerkompanie> '<X> arrived from <Y>' <reserves>\n",
      "2: 0.971 : <liquor> '<X> made from <Y>' <fruit>\n",
      "3: 0.970 : <charges> '<X> originated in <Y>' <blackmail>\n",
      "4: 0.969 : <court> '<X> started from <Y>' <assumption>\n",
      "5: 0.968 : <material> '<X> reproduce from <Y>' <article>\n",
      "6: 0.967 : <flight> '<X> departs from <Y>' <airport>\n",
      "7: 0.965 : <letters> '<X> sent to <Y>' <government>\n",
      "8: 0.964 : <stern> '<X> continued settle as <Y>' <cruiser>\n",
      "9: 0.963 : <preparations> '<X> developed by <Y>' <company>\n",
      "10: 0.963 : <folder> '<X> went away from <Y>' <shell>\n",
      "11: 0.963 : <student> '<X> went away from <Y>' <interview>\n",
      "12: 0.963 : <fevers> '<X> caused by <Y>' <colds>\n",
      "13: 0.963 : <trauma> '<X> caused by <Y>' <arrival>\n",
      "14: 0.963 : <frustration> '<X> caused by <Y>' <system>\n",
      "15: 0.963 : <tools> '<X> developed by <Y>' <team>\n",
      "16: 0.962 : <difficulties> '<X> stemmed from <Y>' <structure>\n",
      "17: 0.962 : <chaos> '<X> urgency caused by <Y>' <hurricanes>\n",
      "18: 0.962 : <damage> '<X> caused by <Y>' <storm>\n",
      "19: 0.962 : <death> '<X> caused by <Y>' <storm>\n",
      "================================================================================\n",
      "Validation loss: 7.0154\n",
      "(0:1:37) step 60/143, epoch 0 Training Loss = 5.26850 :: 1336.133 phrases/sec :: (0:0:42) hours left\n",
      "(0:1:52) step 70/143, epoch 0 Training Loss = 4.95789 :: 1334.692 phrases/sec :: (0:0:26) hours left\n",
      "(0:2:8) step 80/143, epoch 0 Training Loss = 4.67804 :: 1340.327 phrases/sec :: (0:0:10) hours left\n",
      "(0:2:24) step 90/143, epoch 0 Training Loss = 4.40354 :: 1336.914 phrases/sec :: (-1:59:55) hours left\n",
      "(0:2:40) step 100/143, epoch 0 Training Loss = 4.14413 :: 1333.827 phrases/sec :: (-1:59:39) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <factory> '<X> for <Y>' <cars>\n",
      "0: 1.000 : <factory> '<X> for <Y>' <cars>\n",
      "1: 1.000 : <land> '<X> farmed for <Y>' <olives>\n",
      "2: 1.000 : <site> '<X> farmed for <Y>' <wheat>\n",
      "3: 1.000 : <island> '<X> farmed for <Y>' <oats>\n",
      "4: 0.994 : <notebook> '<X> for <Y>' <astronomers>\n",
      "5: 0.993 : <success> '<X> is reason for <Y>' <celebration>\n",
      "6: 0.992 : <facility> '<X> is for <Y>' <growth>\n",
      "7: 0.992 : <index> '<X> generated from <Y>' <surface>\n",
      "8: 0.990 : <missile> '<X> placed inside <Y>' <canister>\n",
      "9: 0.990 : <grenade> '<X> found inside <Y>' <sock>\n",
      "10: 0.988 : <grenade> '<X> was inside <Y>' <tin>\n",
      "11: 0.988 : <noise> '<X> inside <Y>' <car>\n",
      "12: 0.987 : <site> '<X> deep inside <Y>' <earth>\n",
      "13: 0.984 : <fiddler> '<X> distinguished by <Y>' <technique>\n",
      "14: 0.983 : <cancers> '<X> head of portion caused by <Y>' <papillomavirus>\n",
      "15: 0.983 : <creation> '<X> by <Y>' <students>\n",
      "16: 0.983 : <suit> '<X> for <Y>' <scene>\n",
      "17: 0.982 : <passages> '<X> inside <Y>' <monastery>\n",
      "18: 0.982 : <fallout> '<X> including depression from <Y>' <unemployment>\n",
      "19: 0.981 : <trail> '<X> starts at <Y>' <elevation>\n",
      "================================================================================\n",
      "Validation loss: 6.1355\n",
      "(0:2:56) step 110/143, epoch 0 Training Loss = 4.00533 :: 1329.018 phrases/sec :: (-1:59:23) hours left\n",
      "(0:3:13) step 120/143, epoch 0 Training Loss = 3.70786 :: 1325.331 phrases/sec :: (-1:59:7) hours left\n",
      "(0:3:29) step 130/143, epoch 0 Training Loss = 3.49112 :: 1321.749 phrases/sec :: (-1:58:51) hours left\n",
      "(0:3:44) step 140/143, epoch 0 Training Loss = 3.30340 :: 1323.246 phrases/sec :: (-1:58:36) hours left\n",
      "Macro P: 5.7917, R: 6.0951, F1: 5.9395\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-4433-19332\n",
      "143\n",
      "***** SUPERVISED TRAINING *****\n",
      "(0:0:0) s 0/143, e 0 avg class xent loss = 46.4563\n",
      "================================================================================\n",
      "(0:0:6) s 0/143, e 0 validation avg class xent loss = 41.7741\n",
      "================================================================================\n",
      "(0:0:13) s 10/143, e 0 avg class xent loss = 41.6673\n",
      "(0:0:20) s 20/143, e 0 avg class xent loss = 49.2024\n",
      "(0:0:27) s 30/143, e 0 avg class xent loss = 38.7752\n",
      "(0:0:34) s 40/143, e 0 avg class xent loss = 43.0793\n",
      "(0:0:41) s 50/143, e 0 avg class xent loss = 38.2245\n",
      "================================================================================\n",
      "(0:0:47) s 50/143, e 0 validation avg class xent loss = 41.6214\n",
      "================================================================================\n",
      "(0:0:54) s 60/143, e 0 avg class xent loss = 37.1189\n",
      "(0:1:1) s 70/143, e 0 avg class xent loss = 38.1800\n",
      "(0:1:8) s 80/143, e 0 avg class xent loss = 37.6627\n",
      "(0:1:14) s 90/143, e 0 avg class xent loss = 40.2204\n",
      "(0:1:21) s 100/143, e 0 avg class xent loss = 42.5575\n",
      "================================================================================\n",
      "(0:1:28) s 100/143, e 0 validation avg class xent loss = 42.6305\n",
      "================================================================================\n",
      "(0:1:35) s 110/143, e 0 avg class xent loss = 39.4340\n",
      "(0:1:42) s 120/143, e 0 avg class xent loss = 39.8939\n",
      "(0:1:48) s 130/143, e 0 avg class xent loss = 39.1449\n",
      "(0:1:55) s 140/143, e 0 avg class xent loss = 41.1764\n",
      "Macro P: 4.9649, R: 5.7514, F1: 5.3293\n",
      "(0:2:3) s 0/143, e 1 avg class xent loss = 41.5401\n",
      "================================================================================\n",
      "(0:2:9) s 0/143, e 1 validation avg class xent loss = 41.9492\n",
      "================================================================================\n",
      "(0:2:16) s 10/143, e 1 avg class xent loss = 46.8709\n",
      "(0:2:23) s 20/143, e 1 avg class xent loss = 48.4507\n",
      "(0:2:30) s 30/143, e 1 avg class xent loss = 37.5742\n",
      "(0:2:37) s 40/143, e 1 avg class xent loss = 44.1379\n",
      "(0:2:44) s 50/143, e 1 avg class xent loss = 40.2534\n",
      "================================================================================\n",
      "(0:2:50) s 50/143, e 1 validation avg class xent loss = 41.8529\n",
      "================================================================================\n",
      "(0:2:57) s 60/143, e 1 avg class xent loss = 35.7303\n",
      "(0:3:3) s 70/143, e 1 avg class xent loss = 44.9757\n",
      "(0:3:10) s 80/143, e 1 avg class xent loss = 39.1863\n",
      "(0:3:17) s 90/143, e 1 avg class xent loss = 38.2235\n",
      "(0:3:24) s 100/143, e 1 avg class xent loss = 40.1946\n",
      "================================================================================\n",
      "(0:3:31) s 100/143, e 1 validation avg class xent loss = 42.4208\n",
      "================================================================================\n",
      "(0:3:37) s 110/143, e 1 avg class xent loss = 38.3292\n",
      "(0:3:44) s 120/143, e 1 avg class xent loss = 39.8203\n",
      "(0:3:51) s 130/143, e 1 avg class xent loss = 39.9714\n",
      "(0:3:58) s 140/143, e 1 avg class xent loss = 34.8246\n",
      "Macro P: 9.6025, R: 2.3546, F1: 3.7819\n",
      "(0:4:5) s 0/143, e 2 avg class xent loss = 42.3301\n",
      "================================================================================\n",
      "(0:4:11) s 0/143, e 2 validation avg class xent loss = 41.5797\n",
      "================================================================================\n",
      "(0:4:18) s 10/143, e 2 avg class xent loss = 41.2817\n",
      "(0:4:25) s 20/143, e 2 avg class xent loss = 42.6169\n",
      "(0:4:32) s 30/143, e 2 avg class xent loss = 36.0913\n",
      "(0:4:39) s 40/143, e 2 avg class xent loss = 41.4565\n",
      "(0:4:46) s 50/143, e 2 avg class xent loss = 40.0057\n",
      "================================================================================\n",
      "(0:4:52) s 50/143, e 2 validation avg class xent loss = 41.8244\n",
      "================================================================================\n",
      "(0:4:59) s 60/143, e 2 avg class xent loss = 38.3059\n",
      "(0:5:6) s 70/143, e 2 avg class xent loss = 42.3285\n",
      "(0:5:13) s 80/143, e 2 avg class xent loss = 36.3370\n",
      "(0:5:20) s 90/143, e 2 avg class xent loss = 40.7503\n",
      "(0:5:27) s 100/143, e 2 avg class xent loss = 40.1406\n",
      "================================================================================\n",
      "(0:5:33) s 100/143, e 2 validation avg class xent loss = 41.7969\n",
      "================================================================================\n",
      "(0:5:40) s 110/143, e 2 avg class xent loss = 39.1743\n",
      "(0:5:47) s 120/143, e 2 avg class xent loss = 44.1772\n",
      "(0:5:54) s 130/143, e 2 avg class xent loss = 37.1158\n",
      "(0:6:1) s 140/143, e 2 avg class xent loss = 43.9802\n",
      "Macro P: 2.9685, R: 3.6286, F1: 3.2655\n",
      "(0:6:8) s 0/143, e 3 avg class xent loss = 38.3120\n",
      "================================================================================\n",
      "(0:6:14) s 0/143, e 3 validation avg class xent loss = 41.1765\n",
      "================================================================================\n",
      "(0:6:21) s 10/143, e 3 avg class xent loss = 35.8734\n",
      "(0:6:28) s 20/143, e 3 avg class xent loss = 43.8717\n",
      "(0:6:35) s 30/143, e 3 avg class xent loss = 36.0858\n",
      "(0:6:42) s 40/143, e 3 avg class xent loss = 39.4564\n",
      "(0:6:49) s 50/143, e 3 avg class xent loss = 42.6973\n",
      "================================================================================\n",
      "(0:6:55) s 50/143, e 3 validation avg class xent loss = 41.5875\n",
      "================================================================================\n",
      "(0:7:2) s 60/143, e 3 avg class xent loss = 34.3673\n",
      "(0:7:9) s 70/143, e 3 avg class xent loss = 40.4549\n",
      "(0:7:15) s 80/143, e 3 avg class xent loss = 42.7506\n",
      "(0:7:22) s 90/143, e 3 avg class xent loss = 39.0815\n",
      "(0:7:29) s 100/143, e 3 avg class xent loss = 46.0514\n",
      "================================================================================\n",
      "(0:7:35) s 100/143, e 3 validation avg class xent loss = 41.8030\n",
      "================================================================================\n",
      "(0:7:42) s 110/143, e 3 avg class xent loss = 36.6882\n",
      "(0:7:49) s 120/143, e 3 avg class xent loss = 37.9412\n",
      "(0:7:56) s 130/143, e 3 avg class xent loss = 38.3093\n",
      "(0:8:3) s 140/143, e 3 avg class xent loss = 43.0916\n",
      "Macro P: 3.8972, R: 5.7598, F1: 4.6489\n",
      "(0:8:10) s 0/143, e 4 avg class xent loss = 42.7218\n",
      "================================================================================\n",
      "(0:8:16) s 0/143, e 4 validation avg class xent loss = 41.5845\n",
      "================================================================================\n",
      "(0:8:23) s 10/143, e 4 avg class xent loss = 44.0094\n",
      "(0:8:30) s 20/143, e 4 avg class xent loss = 42.1165\n",
      "(0:8:37) s 30/143, e 4 avg class xent loss = 38.6331\n",
      "(0:8:44) s 40/143, e 4 avg class xent loss = 48.5061\n",
      "(0:8:51) s 50/143, e 4 avg class xent loss = 36.8066\n",
      "================================================================================\n",
      "(0:8:57) s 50/143, e 4 validation avg class xent loss = 42.0703\n",
      "================================================================================\n",
      "(0:9:4) s 60/143, e 4 avg class xent loss = 36.0512\n",
      "(0:9:11) s 70/143, e 4 avg class xent loss = 40.5931\n",
      "(0:9:17) s 80/143, e 4 avg class xent loss = 38.9408\n",
      "(0:9:24) s 90/143, e 4 avg class xent loss = 37.6234\n",
      "(0:9:31) s 100/143, e 4 avg class xent loss = 39.5302\n",
      "================================================================================\n",
      "(0:9:37) s 100/143, e 4 validation avg class xent loss = 42.0231\n",
      "================================================================================\n",
      "(0:9:44) s 110/143, e 4 avg class xent loss = 39.7113\n",
      "(0:9:51) s 120/143, e 4 avg class xent loss = 42.2772\n",
      "(0:9:58) s 130/143, e 4 avg class xent loss = 35.3048\n",
      "(0:10:5) s 140/143, e 4 avg class xent loss = 42.0472\n",
      "Macro P: 7.7134, R: 4.5956, F1: 5.7596\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-4433-20042\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "CYCLE 12\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "===== UNSUPERVISED TRAINING =====\n",
      "(0:0:1) step 0/143, epoch 0 Training Loss = 7.61300 :: 2700.101 phrases/sec :: (0:1:7) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <report> '<X> insisted on <Y>' <need>\n",
      "0: 1.000 : <report> '<X> insisted on <Y>' <need>\n",
      "1: 1.000 : <players> '<X> flew on <Y>' <plane>\n",
      "2: 0.999 : <light> '<X> on <Y>' <telephone>\n",
      "3: 0.999 : <war> '<X> erupted on <Y>' <internet>\n",
      "4: 0.998 : <ideas> '<X> insist on <Y>' <gambles>\n",
      "5: 0.994 : <series> '<X> reflected on <Y>' <changes>\n",
      "6: 0.956 : <timer> '<X> on <Y>' <oven>\n",
      "7: 0.956 : <meeting> '<X> on <Y>' <road>\n",
      "8: 0.923 : <centerboard> '<X> inspecting on <Y>' <yacht>\n",
      "9: 0.878 : <chap> '<X> plays on <Y>' <fiddle>\n",
      "10: 0.872 : <audit> '<X> of purpose was report on statements <Y>' <financial>\n",
      "11: 0.862 : <e> '<X> mail in commented on <Y>' <request>\n",
      "12: 0.815 : <government> '<X> produced return <Y>' <factual>\n",
      "13: 0.793 : <success> '<X> comes from <Y>' <ability>\n",
      "14: 0.793 : <name> '<X> comes from <Y>' <mythology>\n",
      "15: 0.793 : <heat> '<X> comes from <Y>' <boiler>\n",
      "16: 0.793 : <statement> '<X> comes from <Y>' <website>\n",
      "17: 0.767 : <index> '<X> generated from <Y>' <surface>\n",
      "18: 0.765 : <battlements> '<X> towers gleam <Y>' <fortress>\n",
      "19: 0.762 : <trail> '<X> starts at <Y>' <elevation>\n",
      "================================================================================\n",
      "Validation loss: 8.0381\n",
      "(0:0:18) step 10/143, epoch 0 Training Loss = 7.11467 :: 1426.693 phrases/sec :: (0:1:52) hours left\n",
      "(0:0:34) step 20/143, epoch 0 Training Loss = 6.71511 :: 1366.541 phrases/sec :: (0:1:42) hours left\n",
      "(0:0:51) step 30/143, epoch 0 Training Loss = 6.25692 :: 1327.112 phrases/sec :: (0:1:29) hours left\n",
      "(0:1:7) step 40/143, epoch 0 Training Loss = 5.86210 :: 1319.610 phrases/sec :: (0:1:14) hours left\n",
      "(0:1:22) step 50/143, epoch 0 Training Loss = 5.50270 :: 1322.648 phrases/sec :: (0:0:58) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <sedge> '<X> of <Y>' <bitterns>\n",
      "0: 1.000 : <isle> '<X> of <Y>' <store>\n",
      "1: 1.000 : <array> '<X> of <Y>' <hedgehogs>\n",
      "2: 1.000 : <galaxy> '<X> of <Y>' <footballers>\n",
      "3: 1.000 : <rig> '<X> of <Y>' <vessel>\n",
      "4: 1.000 : <faction> '<X> of <Y>' <extremists>\n",
      "5: 1.000 : <creep> '<X> of <Y>' <tortoises>\n",
      "6: 1.000 : <rivet> '<X> of <Y>' <button>\n",
      "7: 1.000 : <sorority> '<X> of <Y>' <misfits>\n",
      "8: 1.000 : <brigade> '<X> of <Y>' <soldiers>\n",
      "9: 1.000 : <clique> '<X> of <Y>' <girls>\n",
      "10: 1.000 : <crowd> '<X> of <Y>' <protesters>\n",
      "11: 1.000 : <battery> '<X> of <Y>' <tests>\n",
      "12: 1.000 : <rangale> '<X> of <Y>' <deer>\n",
      "13: 1.000 : <handgrip> '<X> of <Y>' <camera>\n",
      "14: 1.000 : <glut> '<X> of <Y>' <startups>\n",
      "15: 1.000 : <riffraff> '<X> of <Y>' <liars>\n",
      "16: 1.000 : <hookup> '<X> of <Y>' <vessels>\n",
      "17: 1.000 : <sounder> '<X> of <Y>' <pigs>\n",
      "18: 1.000 : <paddle> '<X> of <Y>' <switch>\n",
      "19: 1.000 : <hood> '<X> of <Y>' <truck>\n",
      "================================================================================\n",
      "Validation loss: 6.9172\n",
      "(0:1:39) step 60/143, epoch 0 Training Loss = 5.22057 :: 1319.480 phrases/sec :: (0:0:42) hours left\n",
      "(0:1:55) step 70/143, epoch 0 Training Loss = 4.94067 :: 1312.538 phrases/sec :: (0:0:26) hours left\n",
      "(0:2:10) step 80/143, epoch 0 Training Loss = 4.60508 :: 1315.761 phrases/sec :: (0:0:11) hours left\n",
      "(0:2:26) step 90/143, epoch 0 Training Loss = 4.39636 :: 1316.185 phrases/sec :: (-1:59:55) hours left\n",
      "(0:2:41) step 100/143, epoch 0 Training Loss = 4.10793 :: 1318.362 phrases/sec :: (-1:59:39) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <legion> '<X> of <Y>' <musketeers>\n",
      "0: 1.000 : <isle> '<X> of <Y>' <store>\n",
      "1: 1.000 : <array> '<X> of <Y>' <hedgehogs>\n",
      "2: 1.000 : <galaxy> '<X> of <Y>' <footballers>\n",
      "3: 1.000 : <rig> '<X> of <Y>' <vessel>\n",
      "4: 1.000 : <faction> '<X> of <Y>' <extremists>\n",
      "5: 1.000 : <creep> '<X> of <Y>' <tortoises>\n",
      "6: 1.000 : <rivet> '<X> of <Y>' <button>\n",
      "7: 1.000 : <sorority> '<X> of <Y>' <misfits>\n",
      "8: 1.000 : <brigade> '<X> of <Y>' <soldiers>\n",
      "9: 1.000 : <clique> '<X> of <Y>' <girls>\n",
      "10: 1.000 : <crowd> '<X> of <Y>' <protesters>\n",
      "11: 1.000 : <battery> '<X> of <Y>' <tests>\n",
      "12: 1.000 : <rangale> '<X> of <Y>' <deer>\n",
      "13: 1.000 : <handgrip> '<X> of <Y>' <camera>\n",
      "14: 1.000 : <glut> '<X> of <Y>' <startups>\n",
      "15: 1.000 : <riffraff> '<X> of <Y>' <liars>\n",
      "16: 1.000 : <hookup> '<X> of <Y>' <vessels>\n",
      "17: 1.000 : <sounder> '<X> of <Y>' <pigs>\n",
      "18: 1.000 : <paddle> '<X> of <Y>' <switch>\n",
      "19: 1.000 : <hood> '<X> of <Y>' <truck>\n",
      "================================================================================\n",
      "Validation loss: 5.9247\n",
      "(0:2:58) step 110/143, epoch 0 Training Loss = 3.89888 :: 1317.786 phrases/sec :: (-1:59:23) hours left\n",
      "(0:3:13) step 120/143, epoch 0 Training Loss = 3.65695 :: 1320.708 phrases/sec :: (-1:59:7) hours left\n",
      "(0:3:29) step 130/143, epoch 0 Training Loss = 3.46757 :: 1323.092 phrases/sec :: (-1:58:51) hours left\n",
      "(0:3:45) step 140/143, epoch 0 Training Loss = 3.34923 :: 1321.590 phrases/sec :: (-1:58:35) hours left\n",
      "Macro P: 8.9526, R: 6.5966, F1: 7.5961\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-4576-20042\n",
      "143\n",
      "***** SUPERVISED TRAINING *****\n",
      "(0:0:0) s 0/143, e 0 avg class xent loss = 36.5756\n",
      "================================================================================\n",
      "(0:0:6) s 0/143, e 0 validation avg class xent loss = 42.5386\n",
      "================================================================================\n",
      "(0:0:13) s 10/143, e 0 avg class xent loss = 43.4482\n",
      "(0:0:20) s 20/143, e 0 avg class xent loss = 48.7230\n",
      "(0:0:27) s 30/143, e 0 avg class xent loss = 37.1502\n",
      "(0:0:34) s 40/143, e 0 avg class xent loss = 42.5732\n",
      "(0:0:41) s 50/143, e 0 avg class xent loss = 34.3309\n",
      "================================================================================\n",
      "(0:0:47) s 50/143, e 0 validation avg class xent loss = 42.0442\n",
      "================================================================================\n",
      "(0:0:54) s 60/143, e 0 avg class xent loss = 36.9701\n",
      "(0:1:1) s 70/143, e 0 avg class xent loss = 44.1811\n",
      "(0:1:8) s 80/143, e 0 avg class xent loss = 38.9286\n",
      "(0:1:15) s 90/143, e 0 avg class xent loss = 41.4569\n",
      "(0:1:21) s 100/143, e 0 avg class xent loss = 42.4310\n",
      "================================================================================\n",
      "(0:1:27) s 100/143, e 0 validation avg class xent loss = 41.4780\n",
      "================================================================================\n",
      "(0:1:34) s 110/143, e 0 avg class xent loss = 36.2227\n",
      "(0:1:41) s 120/143, e 0 avg class xent loss = 42.0378\n",
      "(0:1:48) s 130/143, e 0 avg class xent loss = 39.8616\n",
      "(0:1:55) s 140/143, e 0 avg class xent loss = 39.4058\n",
      "Macro P: 2.6286, R: 4.8777, F1: 3.4162\n",
      "(0:2:3) s 0/143, e 1 avg class xent loss = 43.3562\n",
      "================================================================================\n",
      "(0:2:9) s 0/143, e 1 validation avg class xent loss = 41.7731\n",
      "================================================================================\n",
      "(0:2:16) s 10/143, e 1 avg class xent loss = 44.2722\n",
      "(0:2:23) s 20/143, e 1 avg class xent loss = 43.0075\n",
      "(0:2:29) s 30/143, e 1 avg class xent loss = 39.9016\n",
      "(0:2:36) s 40/143, e 1 avg class xent loss = 41.4592\n",
      "(0:2:43) s 50/143, e 1 avg class xent loss = 42.1009\n",
      "================================================================================\n",
      "(0:2:50) s 50/143, e 1 validation avg class xent loss = 42.4469\n",
      "================================================================================\n",
      "(0:2:56) s 60/143, e 1 avg class xent loss = 35.7465\n",
      "(0:3:3) s 70/143, e 1 avg class xent loss = 38.1846\n",
      "(0:3:10) s 80/143, e 1 avg class xent loss = 41.0150\n",
      "(0:3:17) s 90/143, e 1 avg class xent loss = 43.6853\n",
      "(0:3:24) s 100/143, e 1 avg class xent loss = 44.2623\n",
      "================================================================================\n",
      "(0:3:30) s 100/143, e 1 validation avg class xent loss = 41.8398\n",
      "================================================================================\n",
      "(0:3:37) s 110/143, e 1 avg class xent loss = 34.2785\n",
      "(0:3:44) s 120/143, e 1 avg class xent loss = 40.7806\n",
      "(0:3:51) s 130/143, e 1 avg class xent loss = 43.0423\n",
      "(0:3:58) s 140/143, e 1 avg class xent loss = 37.2375\n",
      "Macro P: 4.7753, R: 3.3984, F1: 3.9709\n",
      "(0:4:5) s 0/143, e 2 avg class xent loss = 39.6659\n",
      "================================================================================\n",
      "(0:4:11) s 0/143, e 2 validation avg class xent loss = 41.4396\n",
      "================================================================================\n",
      "(0:4:18) s 10/143, e 2 avg class xent loss = 42.9241\n",
      "(0:4:25) s 20/143, e 2 avg class xent loss = 44.2396\n",
      "(0:4:32) s 30/143, e 2 avg class xent loss = 40.5992\n",
      "(0:4:39) s 40/143, e 2 avg class xent loss = 43.3484\n",
      "(0:4:45) s 50/143, e 2 avg class xent loss = 34.6876\n",
      "================================================================================\n",
      "(0:4:52) s 50/143, e 2 validation avg class xent loss = 42.0054\n",
      "================================================================================\n",
      "(0:4:59) s 60/143, e 2 avg class xent loss = 37.4215\n",
      "(0:5:6) s 70/143, e 2 avg class xent loss = 38.4976\n",
      "(0:5:12) s 80/143, e 2 avg class xent loss = 39.4388\n",
      "(0:5:19) s 90/143, e 2 avg class xent loss = 39.8810\n",
      "(0:5:26) s 100/143, e 2 avg class xent loss = 41.8921\n",
      "================================================================================\n",
      "(0:5:32) s 100/143, e 2 validation avg class xent loss = 42.2679\n",
      "================================================================================\n",
      "(0:5:39) s 110/143, e 2 avg class xent loss = 39.0211\n",
      "(0:5:46) s 120/143, e 2 avg class xent loss = 40.0341\n",
      "(0:5:53) s 130/143, e 2 avg class xent loss = 42.0731\n",
      "(0:6:0) s 140/143, e 2 avg class xent loss = 40.5591\n",
      "Macro P: 3.5845, R: 5.6093, F1: 4.3739\n",
      "(0:6:7) s 0/143, e 3 avg class xent loss = 41.8142\n",
      "================================================================================\n",
      "(0:6:14) s 0/143, e 3 validation avg class xent loss = 41.5978\n",
      "================================================================================\n",
      "(0:6:20) s 10/143, e 3 avg class xent loss = 44.4314\n",
      "(0:6:27) s 20/143, e 3 avg class xent loss = 42.7833\n",
      "(0:6:34) s 30/143, e 3 avg class xent loss = 38.0989\n",
      "(0:6:41) s 40/143, e 3 avg class xent loss = 44.2184\n",
      "(0:6:48) s 50/143, e 3 avg class xent loss = 37.2368\n",
      "================================================================================\n",
      "(0:6:54) s 50/143, e 3 validation avg class xent loss = 42.0158\n",
      "================================================================================\n",
      "(0:7:1) s 60/143, e 3 avg class xent loss = 34.9600\n",
      "(0:7:8) s 70/143, e 3 avg class xent loss = 39.7352\n",
      "(0:7:15) s 80/143, e 3 avg class xent loss = 40.0114\n",
      "(0:7:21) s 90/143, e 3 avg class xent loss = 41.5783\n",
      "(0:7:28) s 100/143, e 3 avg class xent loss = 43.7252\n",
      "================================================================================\n",
      "(0:7:34) s 100/143, e 3 validation avg class xent loss = 42.7419\n",
      "================================================================================\n",
      "(0:7:41) s 110/143, e 3 avg class xent loss = 38.4179\n",
      "(0:7:48) s 120/143, e 3 avg class xent loss = 40.9314\n",
      "(0:7:55) s 130/143, e 3 avg class xent loss = 35.6443\n",
      "(0:8:2) s 140/143, e 3 avg class xent loss = 44.9222\n",
      "Macro P: 1.9563, R: 4.2297, F1: 2.6753\n",
      "(0:8:10) s 0/143, e 4 avg class xent loss = 42.6849\n",
      "================================================================================\n",
      "(0:8:16) s 0/143, e 4 validation avg class xent loss = 41.6831\n",
      "================================================================================\n",
      "(0:8:23) s 10/143, e 4 avg class xent loss = 38.6082\n",
      "(0:8:29) s 20/143, e 4 avg class xent loss = 43.4984\n",
      "(0:8:36) s 30/143, e 4 avg class xent loss = 34.9672\n",
      "(0:8:43) s 40/143, e 4 avg class xent loss = 43.8934\n",
      "(0:8:50) s 50/143, e 4 avg class xent loss = 39.9807\n",
      "================================================================================\n",
      "(0:8:56) s 50/143, e 4 validation avg class xent loss = 42.7421\n",
      "================================================================================\n",
      "(0:9:3) s 60/143, e 4 avg class xent loss = 37.6368\n",
      "(0:9:10) s 70/143, e 4 avg class xent loss = 45.6895\n",
      "(0:9:17) s 80/143, e 4 avg class xent loss = 38.1950\n",
      "(0:9:24) s 90/143, e 4 avg class xent loss = 40.9079\n",
      "(0:9:31) s 100/143, e 4 avg class xent loss = 38.2340\n",
      "================================================================================\n",
      "(0:9:37) s 100/143, e 4 validation avg class xent loss = 42.2755\n",
      "================================================================================\n",
      "(0:9:44) s 110/143, e 4 avg class xent loss = 38.7544\n",
      "(0:9:51) s 120/143, e 4 avg class xent loss = 33.8333\n",
      "(0:9:57) s 130/143, e 4 avg class xent loss = 41.3602\n",
      "(0:10:4) s 140/143, e 4 avg class xent loss = 41.2973\n",
      "Macro P: 4.8878, R: 6.2858, F1: 5.4993\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-4576-20752\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "CYCLE 13\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "===== UNSUPERVISED TRAINING =====\n",
      "(0:0:1) step 0/143, epoch 0 Training Loss = 7.53560 :: 2487.950 phrases/sec :: (0:1:12) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <earthquake> '<X> caused by <Y>' <rupture>\n",
      "0: 1.000 : <inflammation> '<X> caused by <Y>' <growth>\n",
      "1: 1.000 : <cancer> '<X> caused by <Y>' <infection>\n",
      "2: 1.000 : <collapse> '<X> caused by <Y>' <consumers>\n",
      "3: 1.000 : <deficits> '<X> caused by <Y>' <people>\n",
      "4: 1.000 : <earthquake> '<X> caused by <Y>' <rupture>\n",
      "5: 1.000 : <unemployment> '<X> caused by <Y>' <people>\n",
      "6: 1.000 : <harm> '<X> caused by <Y>' <system>\n",
      "7: 1.000 : <injury> '<X> caused by <Y>' <intoxication>\n",
      "8: 1.000 : <problems> '<X> caused by <Y>' <overflows>\n",
      "9: 0.990 : <symptoms> '<X> caused by changes <Y>' <chemical>\n",
      "10: 0.990 : <granules> '<X> caused by force <Y>' <magnetic>\n",
      "11: 0.937 : <disruption> '<X> caused by <Y>' <strike>\n",
      "12: 0.937 : <hardship> '<X> caused by <Y>' <recession>\n",
      "13: 0.931 : <problem> '<X> caused by <Y>' <state>\n",
      "14: 0.920 : <cancers> '<X> head of portion caused by <Y>' <papillomavirus>\n",
      "15: 0.893 : <fevers> '<X> caused by <Y>' <colds>\n",
      "16: 0.893 : <trauma> '<X> caused by <Y>' <arrival>\n",
      "17: 0.893 : <frustration> '<X> caused by <Y>' <system>\n",
      "18: 0.880 : <chaos> '<X> urgency caused by <Y>' <hurricanes>\n",
      "19: 0.879 : <damage> '<X> caused by <Y>' <storm>\n",
      "================================================================================\n",
      "Validation loss: 7.9368\n",
      "(0:0:18) step 10/143, epoch 0 Training Loss = 7.09508 :: 1433.580 phrases/sec :: (0:1:52) hours left\n",
      "(0:0:33) step 20/143, epoch 0 Training Loss = 6.63861 :: 1395.984 phrases/sec :: (0:1:39) hours left\n",
      "(0:0:49) step 30/143, epoch 0 Training Loss = 6.24483 :: 1369.251 phrases/sec :: (0:1:26) hours left\n",
      "(0:1:5) step 40/143, epoch 0 Training Loss = 5.83653 :: 1355.413 phrases/sec :: (0:1:12) hours left\n",
      "(0:1:20) step 50/143, epoch 0 Training Loss = 5.52170 :: 1355.470 phrases/sec :: (0:0:56) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <products> '<X> manufactured by <Y>' <firm>\n",
      "0: 1.000 : <products> '<X> manufactured by <Y>' <firm>\n",
      "1: 0.996 : <tsunamis> '<X> triggered by <Y>' <earthquakes>\n",
      "2: 0.995 : <disease> '<X> is disorder of intestine triggered by <Y>' <ingestion>\n",
      "3: 0.994 : <success> '<X> is reason for <Y>' <celebration>\n",
      "4: 0.991 : <casket> '<X> in reburied put inside <Y>' <sarcophagus>\n",
      "5: 0.991 : <plane> '<X> far from <Y>' <runway>\n",
      "6: 0.990 : <plane> '<X> taxies from <Y>' <runway>\n",
      "7: 0.989 : <tools> '<X> developed by <Y>' <team>\n",
      "8: 0.989 : <influx> '<X> triggered by <Y>' <immigration>\n",
      "9: 0.989 : <interference> '<X> triggered by <Y>' <process>\n",
      "10: 0.989 : <spark> '<X> triggered by <Y>' <beam>\n",
      "11: 0.989 : <facility> '<X> is for <Y>' <growth>\n",
      "12: 0.988 : <preparations> '<X> developed by <Y>' <company>\n",
      "13: 0.988 : <disease> '<X> spreads to <Y>' <dogs>\n",
      "14: 0.987 : <awards> '<X> for apply in <Y>' <areas>\n",
      "15: 0.986 : <author> '<X> makes reference to <Y>' <sciences>\n",
      "16: 0.986 : <grief> '<X> experiencing after <Y>' <death>\n",
      "17: 0.986 : <disruption> '<X> caused by <Y>' <strike>\n",
      "18: 0.986 : <hardship> '<X> caused by <Y>' <recession>\n",
      "19: 0.986 : <revenue> '<X> earning from <Y>' <money>\n",
      "================================================================================\n",
      "Validation loss: 6.8388\n",
      "(0:1:37) step 60/143, epoch 0 Training Loss = 5.21954 :: 1351.126 phrases/sec :: (0:0:41) hours left\n",
      "(0:1:52) step 70/143, epoch 0 Training Loss = 4.91108 :: 1344.021 phrases/sec :: (0:0:25) hours left\n",
      "(0:2:8) step 80/143, epoch 0 Training Loss = 4.62984 :: 1342.771 phrases/sec :: (0:0:10) hours left\n",
      "(0:2:24) step 90/143, epoch 0 Training Loss = 4.34843 :: 1338.129 phrases/sec :: (-1:59:55) hours left\n",
      "(0:2:39) step 100/143, epoch 0 Training Loss = 4.10554 :: 1338.706 phrases/sec :: (-1:59:39) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <dog> '<X> has ball on <Y>' <snout>\n",
      "0: 1.000 : <dog> '<X> has ball on <Y>' <snout>\n",
      "1: 0.999 : <difficulties> '<X> stemmed from <Y>' <structure>\n",
      "2: 0.999 : <jobs> '<X> was point of <Y>' <speech>\n",
      "3: 0.999 : <house> '<X> contains minimum of <Y>' <bedrooms>\n",
      "4: 0.999 : <report> '<X> insisted on <Y>' <need>\n",
      "5: 0.998 : <report> '<X> gave details of <Y>' <events>\n",
      "6: 0.998 : <text> '<X> makes contribution to <Y>' <literature>\n",
      "7: 0.998 : <author> '<X> makes reference to <Y>' <sciences>\n",
      "8: 0.998 : <legacy> '<X> has relation to <Y>' <time>\n",
      "9: 0.998 : <play> '<X> starts in <Y>' <state>\n",
      "10: 0.998 : <publication> '<X> has connection to <Y>' <project>\n",
      "11: 0.998 : <slapshot> '<X> popped out of <Y>' <glove>\n",
      "12: 0.997 : <book> '<X> is triumph from pen of <Y>' <reporter>\n",
      "13: 0.997 : <relationship> '<X> is subject of <Y>' <controversy>\n",
      "14: 0.997 : <glamour> '<X> is subject of <Y>' <exhibition>\n",
      "15: 0.997 : <facility> '<X> is for <Y>' <growth>\n",
      "16: 0.997 : <trail> '<X> starts at <Y>' <elevation>\n",
      "17: 0.997 : <walk> '<X> starts at <Y>' <entry>\n",
      "18: 0.997 : <member> '<X> takes in activity of <Y>' <organisation>\n",
      "19: 0.997 : <court> '<X> started from <Y>' <assumption>\n",
      "================================================================================\n",
      "Validation loss: 5.8723\n",
      "(0:2:56) step 110/143, epoch 0 Training Loss = 3.85118 :: 1337.537 phrases/sec :: (-1:59:23) hours left\n",
      "(0:3:11) step 120/143, epoch 0 Training Loss = 3.65888 :: 1339.259 phrases/sec :: (-1:59:7) hours left\n",
      "(0:3:27) step 130/143, epoch 0 Training Loss = 3.44725 :: 1334.739 phrases/sec :: (-1:58:52) hours left\n",
      "(0:3:43) step 140/143, epoch 0 Training Loss = 3.26032 :: 1332.112 phrases/sec :: (-1:58:36) hours left\n",
      "Macro P: 1.2308, R: 4.3424, F1: 1.9179\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-4719-20752\n",
      "143\n",
      "***** SUPERVISED TRAINING *****\n",
      "(0:0:0) s 0/143, e 0 avg class xent loss = 42.2479\n",
      "================================================================================\n",
      "(0:0:6) s 0/143, e 0 validation avg class xent loss = 41.7888\n",
      "================================================================================\n",
      "(0:0:13) s 10/143, e 0 avg class xent loss = 45.5304\n",
      "(0:0:20) s 20/143, e 0 avg class xent loss = 41.6638\n",
      "(0:0:27) s 30/143, e 0 avg class xent loss = 38.4968\n",
      "(0:0:34) s 40/143, e 0 avg class xent loss = 47.3281\n",
      "(0:0:41) s 50/143, e 0 avg class xent loss = 43.1191\n",
      "================================================================================\n",
      "(0:0:47) s 50/143, e 0 validation avg class xent loss = 42.1740\n",
      "================================================================================\n",
      "(0:0:54) s 60/143, e 0 avg class xent loss = 32.7653\n",
      "(0:1:1) s 70/143, e 0 avg class xent loss = 39.0110\n",
      "(0:1:7) s 80/143, e 0 avg class xent loss = 37.8364\n",
      "(0:1:14) s 90/143, e 0 avg class xent loss = 38.8726\n",
      "(0:1:21) s 100/143, e 0 avg class xent loss = 40.3605\n",
      "================================================================================\n",
      "(0:1:27) s 100/143, e 0 validation avg class xent loss = 43.0896\n",
      "================================================================================\n",
      "(0:1:34) s 110/143, e 0 avg class xent loss = 36.4972\n",
      "(0:1:41) s 120/143, e 0 avg class xent loss = 37.4298\n",
      "(0:1:48) s 130/143, e 0 avg class xent loss = 35.0640\n",
      "(0:1:55) s 140/143, e 0 avg class xent loss = 43.7356\n",
      "Macro P: 4.9827, R: 3.3309, F1: 3.9927\n",
      "(0:2:3) s 0/143, e 1 avg class xent loss = 40.4058\n",
      "================================================================================\n",
      "(0:2:9) s 0/143, e 1 validation avg class xent loss = 42.2229\n",
      "================================================================================\n",
      "(0:2:15) s 10/143, e 1 avg class xent loss = 37.1502\n",
      "(0:2:22) s 20/143, e 1 avg class xent loss = 43.1825\n",
      "(0:2:29) s 30/143, e 1 avg class xent loss = 36.4931\n",
      "(0:2:36) s 40/143, e 1 avg class xent loss = 40.8746\n",
      "(0:2:43) s 50/143, e 1 avg class xent loss = 39.5694\n",
      "================================================================================\n",
      "(0:2:49) s 50/143, e 1 validation avg class xent loss = 42.8867\n",
      "================================================================================\n",
      "(0:2:56) s 60/143, e 1 avg class xent loss = 36.5302\n",
      "(0:3:3) s 70/143, e 1 avg class xent loss = 38.0685\n",
      "(0:3:10) s 80/143, e 1 avg class xent loss = 41.9603\n",
      "(0:3:17) s 90/143, e 1 avg class xent loss = 44.4290\n",
      "(0:3:23) s 100/143, e 1 avg class xent loss = 42.6757\n",
      "================================================================================\n",
      "(0:3:30) s 100/143, e 1 validation avg class xent loss = 42.2408\n",
      "================================================================================\n",
      "(0:3:36) s 110/143, e 1 avg class xent loss = 40.0377\n",
      "(0:3:43) s 120/143, e 1 avg class xent loss = 43.1622\n",
      "(0:3:50) s 130/143, e 1 avg class xent loss = 34.2045\n",
      "(0:3:57) s 140/143, e 1 avg class xent loss = 41.0195\n",
      "Macro P: 2.1023, R: 3.4239, F1: 2.6051\n",
      "(0:4:4) s 0/143, e 2 avg class xent loss = 38.8197\n",
      "================================================================================\n",
      "(0:4:11) s 0/143, e 2 validation avg class xent loss = 42.0725\n",
      "================================================================================\n",
      "(0:4:18) s 10/143, e 2 avg class xent loss = 39.8866\n",
      "(0:4:25) s 20/143, e 2 avg class xent loss = 42.8352\n",
      "(0:4:31) s 30/143, e 2 avg class xent loss = 35.8941\n",
      "(0:4:38) s 40/143, e 2 avg class xent loss = 37.4683\n",
      "(0:4:45) s 50/143, e 2 avg class xent loss = 37.7539\n",
      "================================================================================\n",
      "(0:4:51) s 50/143, e 2 validation avg class xent loss = 41.8027\n",
      "================================================================================\n",
      "(0:4:58) s 60/143, e 2 avg class xent loss = 42.8384\n",
      "(0:5:5) s 70/143, e 2 avg class xent loss = 40.4198\n",
      "(0:5:12) s 80/143, e 2 avg class xent loss = 39.6544\n",
      "(0:5:19) s 90/143, e 2 avg class xent loss = 37.9912\n",
      "(0:5:26) s 100/143, e 2 avg class xent loss = 39.8566\n",
      "================================================================================\n",
      "(0:5:32) s 100/143, e 2 validation avg class xent loss = 41.2303\n",
      "================================================================================\n",
      "(0:5:39) s 110/143, e 2 avg class xent loss = 40.6829\n",
      "(0:5:46) s 120/143, e 2 avg class xent loss = 43.2696\n",
      "(0:5:53) s 130/143, e 2 avg class xent loss = 36.9707\n",
      "(0:5:59) s 140/143, e 2 avg class xent loss = 39.6136\n",
      "Macro P: 5.1057, R: 6.8817, F1: 5.8621\n",
      "(0:6:7) s 0/143, e 3 avg class xent loss = 40.3239\n",
      "================================================================================\n",
      "(0:6:13) s 0/143, e 3 validation avg class xent loss = 40.7458\n",
      "================================================================================\n",
      "(0:6:20) s 10/143, e 3 avg class xent loss = 40.5964\n",
      "(0:6:27) s 20/143, e 3 avg class xent loss = 37.2499\n",
      "(0:6:34) s 30/143, e 3 avg class xent loss = 35.7803\n",
      "(0:6:41) s 40/143, e 3 avg class xent loss = 41.5065\n",
      "(0:6:48) s 50/143, e 3 avg class xent loss = 37.2878\n",
      "================================================================================\n",
      "(0:6:54) s 50/143, e 3 validation avg class xent loss = 41.6392\n",
      "================================================================================\n",
      "(0:7:1) s 60/143, e 3 avg class xent loss = 34.2735\n",
      "(0:7:7) s 70/143, e 3 avg class xent loss = 40.0382\n",
      "(0:7:14) s 80/143, e 3 avg class xent loss = 37.1323\n",
      "(0:7:21) s 90/143, e 3 avg class xent loss = 41.5094\n",
      "(0:7:28) s 100/143, e 3 avg class xent loss = 41.2022\n",
      "================================================================================\n",
      "(0:7:34) s 100/143, e 3 validation avg class xent loss = 41.5601\n",
      "================================================================================\n",
      "(0:7:41) s 110/143, e 3 avg class xent loss = 42.0319\n",
      "(0:7:48) s 120/143, e 3 avg class xent loss = 39.8647\n",
      "(0:7:55) s 130/143, e 3 avg class xent loss = 33.9108\n",
      "(0:8:2) s 140/143, e 3 avg class xent loss = 39.0264\n",
      "Macro P: 3.6203, R: 4.6200, F1: 4.0595\n",
      "(0:8:9) s 0/143, e 4 avg class xent loss = 43.6340\n",
      "================================================================================\n",
      "(0:8:15) s 0/143, e 4 validation avg class xent loss = 41.5225\n",
      "================================================================================\n",
      "(0:8:22) s 10/143, e 4 avg class xent loss = 41.9284\n",
      "(0:8:29) s 20/143, e 4 avg class xent loss = 38.4498\n",
      "(0:8:36) s 30/143, e 4 avg class xent loss = 40.7070\n",
      "(0:8:43) s 40/143, e 4 avg class xent loss = 41.1193\n",
      "(0:8:50) s 50/143, e 4 avg class xent loss = 37.7312\n",
      "================================================================================\n",
      "(0:8:56) s 50/143, e 4 validation avg class xent loss = 41.8309\n",
      "================================================================================\n",
      "(0:9:3) s 60/143, e 4 avg class xent loss = 39.8211\n",
      "(0:9:10) s 70/143, e 4 avg class xent loss = 45.5528\n",
      "(0:9:17) s 80/143, e 4 avg class xent loss = 42.7414\n",
      "(0:9:24) s 90/143, e 4 avg class xent loss = 39.4307\n",
      "(0:9:30) s 100/143, e 4 avg class xent loss = 37.7776\n",
      "================================================================================\n",
      "(0:9:37) s 100/143, e 4 validation avg class xent loss = 41.4550\n",
      "================================================================================\n",
      "(0:9:44) s 110/143, e 4 avg class xent loss = 39.6346\n",
      "(0:9:50) s 120/143, e 4 avg class xent loss = 41.7008\n",
      "(0:9:57) s 130/143, e 4 avg class xent loss = 35.1891\n",
      "(0:10:4) s 140/143, e 4 avg class xent loss = 45.2034\n",
      "Macro P: 12.9314, R: 6.5260, F1: 8.6744\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-4719-21462\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "CYCLE 14\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "===== UNSUPERVISED TRAINING =====\n",
      "(0:0:1) step 0/143, epoch 0 Training Loss = 7.53119 :: 2699.607 phrases/sec :: (0:1:7) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <maps> '<X> <Y>' <representations>\n",
      "0: 1.000 : <work> '<X> <Y>' <food>\n",
      "1: 1.000 : <clergy> '<X> <Y>' <vestments>\n",
      "2: 1.000 : <maps> '<X> <Y>' <representations>\n",
      "3: 0.946 : <snake> '<X> <Y>' <tongue>\n",
      "4: 0.946 : <manufacturer> '<X> <Y>' <drug>\n",
      "5: 0.943 : <documents> '<X> illustrating <Y>' <history>\n",
      "6: 0.937 : <headhunter> '<X> <Y>' <company>\n",
      "7: 0.937 : <designer> '<X> <Y>' <hotel>\n",
      "8: 0.931 : <communities> '<X> built <Y>' <builder>\n",
      "9: 0.915 : <scientist> '<X> <Y>' <theories>\n",
      "10: 0.912 : <special> '<X> dedicated to explaining <Y>' <term>\n",
      "11: 0.910 : <inquiry> '<X> confined to investigating issues <Y>' <safety>\n",
      "12: 0.907 : <driver> '<X> <Y>' <seat>\n",
      "13: 0.907 : <grandmother> '<X> <Y>' <liver>\n",
      "14: 0.907 : <factory> '<X> <Y>' <success>\n",
      "15: 0.907 : <author> '<X> <Y>' <initials>\n",
      "16: 0.906 : <construction> '<X> rescheduled to year <Y>' <next>\n",
      "17: 0.900 : <hurdles> '<X> for <Y>' <drilling>\n",
      "18: 0.895 : <visitors> '<X> including <Y>' <waterbirds>\n",
      "19: 0.895 : <preparations> '<X> developed by <Y>' <company>\n",
      "================================================================================\n",
      "Validation loss: 7.9592\n",
      "(0:0:17) step 10/143, epoch 0 Training Loss = 6.99794 :: 1461.977 phrases/sec :: (0:1:49) hours left\n",
      "(0:0:33) step 20/143, epoch 0 Training Loss = 6.56698 :: 1400.719 phrases/sec :: (0:1:39) hours left\n",
      "(0:0:49) step 30/143, epoch 0 Training Loss = 6.15392 :: 1387.336 phrases/sec :: (0:1:25) hours left\n",
      "(0:1:4) step 40/143, epoch 0 Training Loss = 5.80191 :: 1377.391 phrases/sec :: (0:1:10) hours left\n",
      "(0:1:21) step 50/143, epoch 0 Training Loss = 5.49594 :: 1353.423 phrases/sec :: (0:0:56) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <bag> '<X> contained <Y>' <books>\n",
      "0: 1.000 : <crypt> '<X> contained <Y>' <tomb>\n",
      "1: 1.000 : <bag> '<X> contained <Y>' <books>\n",
      "2: 1.000 : <envelope> '<X> contained <Y>' <sheet>\n",
      "3: 1.000 : <box> '<X> contained <Y>' <recipes>\n",
      "4: 1.000 : <machine> '<X> contained <Y>' <sounds>\n",
      "5: 1.000 : <surgeon> '<X> cuts <Y>' <hole>\n",
      "6: 1.000 : <kitchen> '<X> holds <Y>' <cooker>\n",
      "7: 1.000 : <mother> '<X> suckles <Y>' <young>\n",
      "8: 1.000 : <molt> '<X> produces <Y>' <feathers>\n",
      "9: 1.000 : <contract> '<X> governs <Y>' <wages>\n",
      "10: 1.000 : <wire> '<X> caused <Y>' <injury>\n",
      "11: 1.000 : <mistake> '<X> caused <Y>' <quarrel>\n",
      "12: 1.000 : <malfunction> '<X> caused <Y>' <launch>\n",
      "13: 1.000 : <steam> '<X> caused <Y>' <backpressure>\n",
      "14: 1.000 : <producers> '<X> planted <Y>' <scallops>\n",
      "15: 1.000 : <contents> '<X> included <Y>' <gender>\n",
      "16: 1.000 : <base> '<X> encloses <Y>' <seedpod>\n",
      "17: 1.000 : <paper> '<X> received <Y>' <comments>\n",
      "18: 1.000 : <conclusion> '<X> highlights <Y>' <importance>\n",
      "19: 1.000 : <hairdresser> '<X> prefers <Y>' <scissors>\n",
      "================================================================================\n",
      "Validation loss: 7.1761\n",
      "(0:1:36) step 60/143, epoch 0 Training Loss = 5.17811 :: 1353.584 phrases/sec :: (0:0:41) hours left\n",
      "(0:1:52) step 70/143, epoch 0 Training Loss = 4.84662 :: 1351.069 phrases/sec :: (0:0:25) hours left\n",
      "(0:2:8) step 80/143, epoch 0 Training Loss = 4.61292 :: 1353.112 phrases/sec :: (0:0:9) hours left\n",
      "(0:2:24) step 90/143, epoch 0 Training Loss = 4.30246 :: 1352.251 phrases/sec :: (-1:59:53) hours left\n",
      "(0:2:40) step 100/143, epoch 0 Training Loss = 4.06987 :: 1345.351 phrases/sec :: (-1:59:38) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <plants> '<X> came bore <Y>' <grain>\n",
      "0: 1.000 : <plants> '<X> came bore <Y>' <grain>\n",
      "1: 1.000 : <serial> '<X> was charted <Y>' <dynasty>\n",
      "2: 1.000 : <factory> '<X> producing <Y>' <plates>\n",
      "3: 1.000 : <painter> '<X> continues adding <Y>' <paint>\n",
      "4: 1.000 : <statute> '<X> covering <Y>' <matter>\n",
      "5: 1.000 : <cruisers> '<X> have <Y>' <fittings>\n",
      "6: 1.000 : <genie> '<X> popped beat <Y>' <lamp>\n",
      "7: 1.000 : <documentary> '<X> detailing <Y>' <stages>\n",
      "8: 1.000 : <focus> '<X> groups of purpose was determine <Y>' <needs>\n",
      "9: 1.000 : <women> '<X> thrown into inhibiting <Y>' <situations>\n",
      "10: 1.000 : <book> '<X> criticizing <Y>' <writings>\n",
      "11: 1.000 : <man> '<X> grew <Y>' <ear>\n",
      "12: 1.000 : <special> '<X> dedicated to explaining <Y>' <term>\n",
      "13: 1.000 : <official> '<X> sacked drawn <Y>' <plans>\n",
      "14: 1.000 : <researches> '<X> pointing <Y>' <image>\n",
      "15: 1.000 : <toxoplasmosis> '<X> caused obligate <Y>' <parasite>\n",
      "16: 1.000 : <steam> '<X> set <Y>' <alarm>\n",
      "17: 1.000 : <fortress> '<X> has <Y>' <bastions>\n",
      "18: 1.000 : <player> '<X> has <Y>' <jack>\n",
      "19: 1.000 : <evaluators> '<X> applied <Y>' <generalization>\n",
      "================================================================================\n",
      "Validation loss: 6.1743\n",
      "(0:2:56) step 110/143, epoch 0 Training Loss = 3.84887 :: 1341.369 phrases/sec :: (-1:59:22) hours left\n",
      "(0:3:12) step 120/143, epoch 0 Training Loss = 3.65974 :: 1339.733 phrases/sec :: (-1:59:7) hours left\n",
      "(0:3:27) step 130/143, epoch 0 Training Loss = 3.41763 :: 1340.442 phrases/sec :: (-1:58:51) hours left\n",
      "(0:3:43) step 140/143, epoch 0 Training Loss = 3.26678 :: 1341.059 phrases/sec :: (-1:58:36) hours left\n",
      "Macro P: 11.7755, R: 7.2637, F1: 8.9850\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-4862-21462\n",
      "143\n",
      "***** SUPERVISED TRAINING *****\n",
      "(0:0:0) s 0/143, e 0 avg class xent loss = 38.4006\n",
      "================================================================================\n",
      "(0:0:6) s 0/143, e 0 validation avg class xent loss = 40.8796\n",
      "================================================================================\n",
      "(0:0:13) s 10/143, e 0 avg class xent loss = 43.9511\n",
      "(0:0:20) s 20/143, e 0 avg class xent loss = 41.7468\n",
      "(0:0:27) s 30/143, e 0 avg class xent loss = 41.8824\n",
      "(0:0:34) s 40/143, e 0 avg class xent loss = 44.3528\n",
      "(0:0:41) s 50/143, e 0 avg class xent loss = 38.9425\n",
      "================================================================================\n",
      "(0:0:47) s 50/143, e 0 validation avg class xent loss = 40.8744\n",
      "================================================================================\n",
      "(0:0:53) s 60/143, e 0 avg class xent loss = 36.7714\n",
      "(0:1:0) s 70/143, e 0 avg class xent loss = 40.7888\n",
      "(0:1:7) s 80/143, e 0 avg class xent loss = 38.4302\n",
      "(0:1:14) s 90/143, e 0 avg class xent loss = 39.2511\n",
      "(0:1:21) s 100/143, e 0 avg class xent loss = 40.6613\n",
      "================================================================================\n",
      "(0:1:28) s 100/143, e 0 validation avg class xent loss = 41.7358\n",
      "================================================================================\n",
      "(0:1:34) s 110/143, e 0 avg class xent loss = 38.8152\n",
      "(0:1:41) s 120/143, e 0 avg class xent loss = 43.3709\n",
      "(0:1:48) s 130/143, e 0 avg class xent loss = 36.6058\n",
      "(0:1:55) s 140/143, e 0 avg class xent loss = 39.7399\n",
      "Macro P: 3.3316, R: 6.8957, F1: 4.4926\n",
      "(0:2:2) s 0/143, e 1 avg class xent loss = 41.4739\n",
      "================================================================================\n",
      "(0:2:9) s 0/143, e 1 validation avg class xent loss = 41.4310\n",
      "================================================================================\n",
      "(0:2:15) s 10/143, e 1 avg class xent loss = 40.5095\n",
      "(0:2:23) s 20/143, e 1 avg class xent loss = 46.4900\n",
      "(0:2:29) s 30/143, e 1 avg class xent loss = 37.3205\n",
      "(0:2:36) s 40/143, e 1 avg class xent loss = 42.9374\n",
      "(0:2:43) s 50/143, e 1 avg class xent loss = 39.0993\n",
      "================================================================================\n",
      "(0:2:49) s 50/143, e 1 validation avg class xent loss = 41.5241\n",
      "================================================================================\n",
      "(0:2:56) s 60/143, e 1 avg class xent loss = 37.1279\n",
      "(0:3:3) s 70/143, e 1 avg class xent loss = 39.5734\n",
      "(0:3:10) s 80/143, e 1 avg class xent loss = 42.1068\n",
      "(0:3:16) s 90/143, e 1 avg class xent loss = 40.0290\n",
      "(0:3:23) s 100/143, e 1 avg class xent loss = 41.0510\n",
      "================================================================================\n",
      "(0:3:30) s 100/143, e 1 validation avg class xent loss = 40.8474\n",
      "================================================================================\n",
      "(0:3:37) s 110/143, e 1 avg class xent loss = 40.4430\n",
      "(0:3:43) s 120/143, e 1 avg class xent loss = 36.9410\n",
      "(0:3:50) s 130/143, e 1 avg class xent loss = 37.9710\n",
      "(0:3:57) s 140/143, e 1 avg class xent loss = 38.4742\n",
      "Macro P: 9.2331, R: 7.2412, F1: 8.1167\n",
      "(0:4:5) s 0/143, e 2 avg class xent loss = 43.1196\n",
      "================================================================================\n",
      "(0:4:11) s 0/143, e 2 validation avg class xent loss = 40.6580\n",
      "================================================================================\n",
      "(0:4:18) s 10/143, e 2 avg class xent loss = 50.5727\n",
      "(0:4:24) s 20/143, e 2 avg class xent loss = 38.8024\n",
      "(0:4:31) s 30/143, e 2 avg class xent loss = 37.4624\n",
      "(0:4:38) s 40/143, e 2 avg class xent loss = 40.7678\n",
      "(0:4:45) s 50/143, e 2 avg class xent loss = 34.3047\n",
      "================================================================================\n",
      "(0:4:51) s 50/143, e 2 validation avg class xent loss = 41.0133\n",
      "================================================================================\n",
      "(0:4:58) s 60/143, e 2 avg class xent loss = 34.1423\n",
      "(0:5:5) s 70/143, e 2 avg class xent loss = 45.3244\n",
      "(0:5:12) s 80/143, e 2 avg class xent loss = 38.5976\n",
      "(0:5:18) s 90/143, e 2 avg class xent loss = 39.2253\n",
      "(0:5:25) s 100/143, e 2 avg class xent loss = 44.4940\n",
      "================================================================================\n",
      "(0:5:32) s 100/143, e 2 validation avg class xent loss = 41.5359\n",
      "================================================================================\n",
      "(0:5:39) s 110/143, e 2 avg class xent loss = 40.5273\n",
      "(0:5:46) s 120/143, e 2 avg class xent loss = 37.7157\n",
      "(0:5:53) s 130/143, e 2 avg class xent loss = 39.9857\n",
      "(0:5:59) s 140/143, e 2 avg class xent loss = 39.8950\n",
      "Macro P: 4.8419, R: 5.3173, F1: 5.0685\n",
      "(0:6:7) s 0/143, e 3 avg class xent loss = 44.5172\n",
      "================================================================================\n",
      "(0:6:13) s 0/143, e 3 validation avg class xent loss = 41.1583\n",
      "================================================================================\n",
      "(0:6:20) s 10/143, e 3 avg class xent loss = 38.1861\n",
      "(0:6:27) s 20/143, e 3 avg class xent loss = 42.9517\n",
      "(0:6:34) s 30/143, e 3 avg class xent loss = 40.3848\n",
      "(0:6:41) s 40/143, e 3 avg class xent loss = 41.7670\n",
      "(0:6:48) s 50/143, e 3 avg class xent loss = 39.2827\n",
      "================================================================================\n",
      "(0:6:54) s 50/143, e 3 validation avg class xent loss = 42.0662\n",
      "================================================================================\n",
      "(0:7:1) s 60/143, e 3 avg class xent loss = 36.0818\n",
      "(0:7:7) s 70/143, e 3 avg class xent loss = 42.8694\n",
      "(0:7:14) s 80/143, e 3 avg class xent loss = 40.1118\n",
      "(0:7:21) s 90/143, e 3 avg class xent loss = 38.7910\n",
      "(0:7:28) s 100/143, e 3 avg class xent loss = 42.2870\n",
      "================================================================================\n",
      "(0:7:35) s 100/143, e 3 validation avg class xent loss = 42.3439\n",
      "================================================================================\n",
      "(0:7:41) s 110/143, e 3 avg class xent loss = 35.4136\n",
      "(0:7:48) s 120/143, e 3 avg class xent loss = 40.7666\n",
      "(0:7:55) s 130/143, e 3 avg class xent loss = 34.7200\n",
      "(0:8:2) s 140/143, e 3 avg class xent loss = 41.0811\n",
      "Macro P: 3.6915, R: 5.9894, F1: 4.5677\n",
      "(0:8:9) s 0/143, e 4 avg class xent loss = 46.4104\n",
      "================================================================================\n",
      "(0:8:16) s 0/143, e 4 validation avg class xent loss = 41.1617\n",
      "================================================================================\n",
      "(0:8:22) s 10/143, e 4 avg class xent loss = 40.6877\n",
      "(0:8:29) s 20/143, e 4 avg class xent loss = 45.3372\n",
      "(0:8:36) s 30/143, e 4 avg class xent loss = 41.5431\n",
      "(0:8:43) s 40/143, e 4 avg class xent loss = 43.5913\n",
      "(0:8:50) s 50/143, e 4 avg class xent loss = 40.9046\n",
      "================================================================================\n",
      "(0:8:56) s 50/143, e 4 validation avg class xent loss = 41.7028\n",
      "================================================================================\n",
      "(0:9:3) s 60/143, e 4 avg class xent loss = 38.4929\n",
      "(0:9:10) s 70/143, e 4 avg class xent loss = 44.0579\n",
      "(0:9:17) s 80/143, e 4 avg class xent loss = 38.6129\n",
      "(0:9:24) s 90/143, e 4 avg class xent loss = 37.2312\n",
      "(0:9:31) s 100/143, e 4 avg class xent loss = 44.4332\n",
      "================================================================================\n",
      "(0:9:37) s 100/143, e 4 validation avg class xent loss = 42.0577\n",
      "================================================================================\n",
      "(0:9:44) s 110/143, e 4 avg class xent loss = 35.8473\n",
      "(0:9:51) s 120/143, e 4 avg class xent loss = 38.7298\n",
      "(0:9:58) s 130/143, e 4 avg class xent loss = 36.0833\n",
      "(0:10:4) s 140/143, e 4 avg class xent loss = 35.4490\n",
      "Macro P: 6.0052, R: 5.4838, F1: 5.7327\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-4862-22172\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "CYCLE 15\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "===== UNSUPERVISED TRAINING =====\n",
      "(0:0:1) step 0/143, epoch 0 Training Loss = 7.41238 :: 2143.858 phrases/sec :: (0:1:24) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <wire> '<X> welding coiled in <Y>' <pail>\n",
      "0: 1.000 : <wire> '<X> welding coiled in <Y>' <pail>\n",
      "1: 0.993 : <wine> '<X> stored in <Y>' <temperature>\n",
      "2: 0.993 : <body> '<X> in <Y>' <casket>\n",
      "3: 0.993 : <qualifications> '<X> in <Y>' <care>\n",
      "4: 0.992 : <nostrils> '<X> opened in <Y>' <nose>\n",
      "5: 0.986 : <teeth> '<X> found in <Y>' <wallet>\n",
      "6: 0.984 : <body> '<X> found tied in <Y>' <sack>\n",
      "7: 0.982 : <linoleum> '<X> cleaning in <Y>' <kitchen>\n",
      "8: 0.982 : <popcorn> '<X> stirring in <Y>' <kettle>\n",
      "9: 0.982 : <tooth> '<X> implanted in <Y>' <eye>\n",
      "10: 0.981 : <phone> '<X> placed in <Y>' <cradle>\n",
      "11: 0.980 : <ceremony> '<X> hold in <Y>' <building>\n",
      "12: 0.980 : <suitcase> '<X> filled with <NUM> in <Y>' <cash>\n",
      "13: 0.978 : <results> '<X> presented in <Y>' <report>\n",
      "14: 0.977 : <record> '<X> documented in <Y>' <book>\n",
      "15: 0.977 : <market> '<X> rooted in <Y>' <structure>\n",
      "16: 0.976 : <conclusions> '<X> set in <Y>' <document>\n",
      "17: 0.976 : <charges> '<X> originated in <Y>' <blackmail>\n",
      "18: 0.976 : <garment> '<X> found in <Y>' <reliquary>\n",
      "19: 0.973 : <book> '<X> is rich in <Y>' <exercises>\n",
      "================================================================================\n",
      "Validation loss: 7.8508\n",
      "(0:0:17) step 10/143, epoch 0 Training Loss = 6.91680 :: 1430.267 phrases/sec :: (0:1:52) hours left\n",
      "(0:0:33) step 20/143, epoch 0 Training Loss = 6.45063 :: 1387.837 phrases/sec :: (0:1:41) hours left\n",
      "(0:0:49) step 30/143, epoch 0 Training Loss = 6.05308 :: 1376.805 phrases/sec :: (0:1:26) hours left\n",
      "(0:1:4) step 40/143, epoch 0 Training Loss = 5.70208 :: 1375.696 phrases/sec :: (0:1:11) hours left\n",
      "(0:1:20) step 50/143, epoch 0 Training Loss = 5.38612 :: 1366.450 phrases/sec :: (0:0:56) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <manufacturer> '<X> <Y>' <drug>\n",
      "0: 1.000 : <snake> '<X> <Y>' <tongue>\n",
      "1: 1.000 : <manufacturer> '<X> <Y>' <drug>\n",
      "2: 0.997 : <book> '<X> in becomes <Y>' <gentleman>\n",
      "3: 0.996 : <song> '<X> in later interjected <Y>' <composer>\n",
      "4: 0.991 : <fish> '<X> <Y>' <oil>\n",
      "5: 0.991 : <apricot> '<X> <Y>' <marmalade>\n",
      "6: 0.991 : <cranberry> '<X> <Y>' <syrup>\n",
      "7: 0.991 : <rice> '<X> <Y>' <spirits>\n",
      "8: 0.991 : <lemon> '<X> <Y>' <cake>\n",
      "9: 0.991 : <lemon> '<X> <Y>' <cake>\n",
      "10: 0.991 : <wool> '<X> <Y>' <industry>\n",
      "11: 0.991 : <radio> '<X> <Y>' <tuner>\n",
      "12: 0.991 : <snowstorm> '<X> <Y>' <losses>\n",
      "13: 0.991 : <drinking> '<X> <Y>' <regulations>\n",
      "14: 0.991 : <fertilizer> '<X> <Y>' <company>\n",
      "15: 0.991 : <powerboat> '<X> <Y>' <manufacturer>\n",
      "16: 0.989 : <vegetable> '<X> <Y>' <oil>\n",
      "17: 0.989 : <famine> '<X> <Y>' <drought>\n",
      "18: 0.979 : <news> '<X> by encouraged contain <Y>' <tables>\n",
      "19: 0.979 : <tale> '<X> makes point be <Y>' <risk>\n",
      "================================================================================\n",
      "Validation loss: 7.0947\n",
      "(0:1:36) step 60/143, epoch 0 Training Loss = 5.06327 :: 1359.934 phrases/sec :: (0:0:40) hours left\n",
      "(0:1:52) step 70/143, epoch 0 Training Loss = 4.75951 :: 1355.083 phrases/sec :: (0:0:24) hours left\n",
      "(0:2:8) step 80/143, epoch 0 Training Loss = 4.49195 :: 1351.772 phrases/sec :: (0:0:9) hours left\n",
      "(0:2:24) step 90/143, epoch 0 Training Loss = 4.23885 :: 1349.002 phrases/sec :: (-1:59:54) hours left\n",
      "(0:2:39) step 100/143, epoch 0 Training Loss = 4.01325 :: 1351.514 phrases/sec :: (-1:59:38) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <message> '<X> from <Y>' <chairman>\n",
      "0: 1.000 : <message> '<X> from <Y>' <chairman>\n",
      "1: 1.000 : <index> '<X> generated from <Y>' <surface>\n",
      "2: 1.000 : <shell> '<X> made from <Y>' <aluminum>\n",
      "3: 1.000 : <kids> '<X> tuckered from <Y>' <castle>\n",
      "4: 1.000 : <peptide> '<X> derived from <Y>' <protein>\n",
      "5: 1.000 : <legend> '<X> derived from <Y>' <publication>\n",
      "6: 1.000 : <colours> '<X> derived from <Y>' <stylesheet>\n",
      "7: 1.000 : <name> '<X> derived from <Y>' <word>\n",
      "8: 1.000 : <essay> '<X> derived from <Y>' <study>\n",
      "9: 1.000 : <aeroplane> '<X> withdrawn from <Y>' <duty>\n",
      "10: 1.000 : <sense> '<X> extended from <Y>' <language>\n",
      "11: 1.000 : <perspective> '<X> gained from <Y>' <knowledge>\n",
      "12: 1.000 : <birds> '<X> descended from <Y>' <parent>\n",
      "13: 1.000 : <topics> '<X> emerging from <Y>' <literature>\n",
      "14: 1.000 : <plane> '<X> drive from <Y>' <runway>\n",
      "15: 0.999 : <bytecodes> '<X> compiled from <Y>' <structure>\n",
      "16: 0.999 : <plane> '<X> taxies from <Y>' <runway>\n",
      "17: 0.999 : <building> '<X> leaked from <Y>' <place>\n",
      "18: 0.999 : <panic> '<X> from <Y>' <morning>\n",
      "19: 0.999 : <ache> '<X> from <Y>' <vaccine>\n",
      "================================================================================\n",
      "Validation loss: 6.0638\n",
      "(0:2:55) step 110/143, epoch 0 Training Loss = 3.78958 :: 1348.405 phrases/sec :: (-1:59:22) hours left\n",
      "(0:3:11) step 120/143, epoch 0 Training Loss = 3.53761 :: 1347.333 phrases/sec :: (-1:59:7) hours left\n",
      "(0:3:27) step 130/143, epoch 0 Training Loss = 3.39386 :: 1339.586 phrases/sec :: (-1:58:51) hours left\n",
      "(0:3:43) step 140/143, epoch 0 Training Loss = 3.16749 :: 1341.194 phrases/sec :: (-1:58:35) hours left\n",
      "Macro P: 4.1771, R: 6.5880, F1: 5.1125\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-5005-22172\n",
      "143\n",
      "***** SUPERVISED TRAINING *****\n",
      "(0:0:0) s 0/143, e 0 avg class xent loss = 43.5240\n",
      "================================================================================\n",
      "(0:0:6) s 0/143, e 0 validation avg class xent loss = 40.6834\n",
      "================================================================================\n",
      "(0:0:13) s 10/143, e 0 avg class xent loss = 44.6620\n",
      "(0:0:20) s 20/143, e 0 avg class xent loss = 46.2707\n",
      "(0:0:27) s 30/143, e 0 avg class xent loss = 40.9568\n",
      "(0:0:34) s 40/143, e 0 avg class xent loss = 48.0800\n",
      "(0:0:41) s 50/143, e 0 avg class xent loss = 40.3074\n",
      "================================================================================\n",
      "(0:0:47) s 50/143, e 0 validation avg class xent loss = 41.0219\n",
      "================================================================================\n",
      "(0:0:54) s 60/143, e 0 avg class xent loss = 37.7329\n",
      "(0:1:1) s 70/143, e 0 avg class xent loss = 37.5740\n",
      "(0:1:8) s 80/143, e 0 avg class xent loss = 38.0507\n",
      "(0:1:14) s 90/143, e 0 avg class xent loss = 40.9060\n",
      "(0:1:21) s 100/143, e 0 avg class xent loss = 40.5367\n",
      "================================================================================\n",
      "(0:1:27) s 100/143, e 0 validation avg class xent loss = 40.9991\n",
      "================================================================================\n",
      "(0:1:34) s 110/143, e 0 avg class xent loss = 41.1753\n",
      "(0:1:41) s 120/143, e 0 avg class xent loss = 38.1573\n",
      "(0:1:48) s 130/143, e 0 avg class xent loss = 37.6575\n",
      "(0:1:55) s 140/143, e 0 avg class xent loss = 41.7233\n",
      "Macro P: 4.6054, R: 7.1289, F1: 5.5958\n",
      "(0:2:3) s 0/143, e 1 avg class xent loss = 40.0303\n",
      "================================================================================\n",
      "(0:2:9) s 0/143, e 1 validation avg class xent loss = 41.2637\n",
      "================================================================================\n",
      "(0:2:16) s 10/143, e 1 avg class xent loss = 43.1549\n",
      "(0:2:22) s 20/143, e 1 avg class xent loss = 40.6828\n",
      "(0:2:29) s 30/143, e 1 avg class xent loss = 37.0283\n",
      "(0:2:36) s 40/143, e 1 avg class xent loss = 40.7504\n",
      "(0:2:43) s 50/143, e 1 avg class xent loss = 42.8581\n",
      "================================================================================\n",
      "(0:2:49) s 50/143, e 1 validation avg class xent loss = 41.6317\n",
      "================================================================================\n",
      "(0:2:56) s 60/143, e 1 avg class xent loss = 34.8073\n",
      "(0:3:3) s 70/143, e 1 avg class xent loss = 37.3875\n",
      "(0:3:10) s 80/143, e 1 avg class xent loss = 38.5883\n",
      "(0:3:17) s 90/143, e 1 avg class xent loss = 37.0805\n",
      "(0:3:23) s 100/143, e 1 avg class xent loss = 42.1699\n",
      "================================================================================\n",
      "(0:3:30) s 100/143, e 1 validation avg class xent loss = 41.3469\n",
      "================================================================================\n",
      "(0:3:36) s 110/143, e 1 avg class xent loss = 36.8467\n",
      "(0:3:43) s 120/143, e 1 avg class xent loss = 40.4431\n",
      "(0:3:50) s 130/143, e 1 avg class xent loss = 37.9642\n",
      "(0:3:57) s 140/143, e 1 avg class xent loss = 45.7920\n",
      "Macro P: 4.1774, R: 3.6557, F1: 3.8992\n",
      "(0:4:5) s 0/143, e 2 avg class xent loss = 39.9908\n",
      "================================================================================\n",
      "(0:4:11) s 0/143, e 2 validation avg class xent loss = 40.7211\n",
      "================================================================================\n",
      "(0:4:18) s 10/143, e 2 avg class xent loss = 44.9141\n",
      "(0:4:25) s 20/143, e 2 avg class xent loss = 40.9855\n",
      "(0:4:31) s 30/143, e 2 avg class xent loss = 37.4943\n",
      "(0:4:38) s 40/143, e 2 avg class xent loss = 42.3723\n",
      "(0:4:45) s 50/143, e 2 avg class xent loss = 39.9957\n",
      "================================================================================\n",
      "(0:4:52) s 50/143, e 2 validation avg class xent loss = 41.1491\n",
      "================================================================================\n",
      "(0:4:59) s 60/143, e 2 avg class xent loss = 39.7015\n",
      "(0:5:6) s 70/143, e 2 avg class xent loss = 36.4674\n",
      "(0:5:13) s 80/143, e 2 avg class xent loss = 36.2611\n",
      "(0:5:20) s 90/143, e 2 avg class xent loss = 39.7513\n",
      "(0:5:26) s 100/143, e 2 avg class xent loss = 45.4739\n",
      "================================================================================\n",
      "(0:5:32) s 100/143, e 2 validation avg class xent loss = 41.5094\n",
      "================================================================================\n",
      "(0:5:40) s 110/143, e 2 avg class xent loss = 38.4424\n",
      "(0:5:46) s 120/143, e 2 avg class xent loss = 41.1228\n",
      "(0:5:53) s 130/143, e 2 avg class xent loss = 37.0209\n",
      "(0:6:0) s 140/143, e 2 avg class xent loss = 38.8289\n",
      "Macro P: 4.6912, R: 3.7899, F1: 4.1927\n",
      "(0:6:8) s 0/143, e 3 avg class xent loss = 41.2311\n",
      "================================================================================\n",
      "(0:6:14) s 0/143, e 3 validation avg class xent loss = 40.8904\n",
      "================================================================================\n",
      "(0:6:21) s 10/143, e 3 avg class xent loss = 41.2501\n",
      "(0:6:28) s 20/143, e 3 avg class xent loss = 42.1273\n",
      "(0:6:34) s 30/143, e 3 avg class xent loss = 39.1764\n",
      "(0:6:41) s 40/143, e 3 avg class xent loss = 42.7897\n",
      "(0:6:48) s 50/143, e 3 avg class xent loss = 38.8870\n",
      "================================================================================\n",
      "(0:6:55) s 50/143, e 3 validation avg class xent loss = 41.9366\n",
      "================================================================================\n",
      "(0:7:2) s 60/143, e 3 avg class xent loss = 36.6245\n",
      "(0:7:8) s 70/143, e 3 avg class xent loss = 40.5404\n",
      "(0:7:15) s 80/143, e 3 avg class xent loss = 38.1268\n",
      "(0:7:22) s 90/143, e 3 avg class xent loss = 41.3074\n",
      "(0:7:29) s 100/143, e 3 avg class xent loss = 45.1177\n",
      "================================================================================\n",
      "(0:7:35) s 100/143, e 3 validation avg class xent loss = 41.4036\n",
      "================================================================================\n",
      "(0:7:42) s 110/143, e 3 avg class xent loss = 35.8626\n",
      "(0:7:49) s 120/143, e 3 avg class xent loss = 42.7493\n",
      "(0:7:56) s 130/143, e 3 avg class xent loss = 40.0127\n",
      "(0:8:3) s 140/143, e 3 avg class xent loss = 41.4303\n",
      "Macro P: 9.9922, R: 5.3981, F1: 7.0094\n",
      "(0:8:11) s 0/143, e 4 avg class xent loss = 42.4646\n",
      "================================================================================\n",
      "(0:8:17) s 0/143, e 4 validation avg class xent loss = 41.0938\n",
      "================================================================================\n",
      "(0:8:24) s 10/143, e 4 avg class xent loss = 41.4774\n",
      "(0:8:30) s 20/143, e 4 avg class xent loss = 43.7308\n",
      "(0:8:37) s 30/143, e 4 avg class xent loss = 40.6501\n",
      "(0:8:44) s 40/143, e 4 avg class xent loss = 43.9848\n",
      "(0:8:51) s 50/143, e 4 avg class xent loss = 39.1599\n",
      "================================================================================\n",
      "(0:8:57) s 50/143, e 4 validation avg class xent loss = 41.7278\n",
      "================================================================================\n",
      "(0:9:4) s 60/143, e 4 avg class xent loss = 39.8488\n",
      "(0:9:11) s 70/143, e 4 avg class xent loss = 36.0029\n",
      "(0:9:18) s 80/143, e 4 avg class xent loss = 35.5710\n",
      "(0:9:25) s 90/143, e 4 avg class xent loss = 40.4723\n",
      "(0:9:31) s 100/143, e 4 avg class xent loss = 40.7691\n",
      "================================================================================\n",
      "(0:9:38) s 100/143, e 4 validation avg class xent loss = 40.9477\n",
      "================================================================================\n",
      "(0:9:44) s 110/143, e 4 avg class xent loss = 41.3796\n",
      "(0:9:51) s 120/143, e 4 avg class xent loss = 39.2032\n",
      "(0:9:58) s 130/143, e 4 avg class xent loss = 36.1544\n",
      "(0:10:5) s 140/143, e 4 avg class xent loss = 41.0480\n",
      "Macro P: 5.7391, R: 5.0795, F1: 5.3892\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-5005-22882\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "CYCLE 16\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "===== UNSUPERVISED TRAINING =====\n",
      "(0:0:1) step 0/143, epoch 0 Training Loss = 7.31951 :: 2520.154 phrases/sec :: (0:1:11) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <fertilizer> '<X> <Y>' <company>\n",
      "0: 1.000 : <fish> '<X> <Y>' <oil>\n",
      "1: 1.000 : <apricot> '<X> <Y>' <marmalade>\n",
      "2: 1.000 : <cranberry> '<X> <Y>' <syrup>\n",
      "3: 1.000 : <rice> '<X> <Y>' <spirits>\n",
      "4: 1.000 : <lemon> '<X> <Y>' <cake>\n",
      "5: 1.000 : <lemon> '<X> <Y>' <cake>\n",
      "6: 1.000 : <wool> '<X> <Y>' <industry>\n",
      "7: 1.000 : <radio> '<X> <Y>' <tuner>\n",
      "8: 1.000 : <snowstorm> '<X> <Y>' <losses>\n",
      "9: 1.000 : <drinking> '<X> <Y>' <regulations>\n",
      "10: 1.000 : <fertilizer> '<X> <Y>' <company>\n",
      "11: 1.000 : <powerboat> '<X> <Y>' <manufacturer>\n",
      "12: 0.990 : <pen> '<X> <Y>' <point>\n",
      "13: 0.987 : <manhole> '<X> <Y>' <cover>\n",
      "14: 0.985 : <snake> '<X> <Y>' <tongue>\n",
      "15: 0.985 : <manufacturer> '<X> <Y>' <drug>\n",
      "16: 0.972 : <order> '<X> fulfillment <Y>' <from>\n",
      "17: 0.955 : <scientist> '<X> <Y>' <theories>\n",
      "18: 0.945 : <battlements> '<X> towers gleam <Y>' <fortress>\n",
      "19: 0.937 : <crane> '<X> <Y>' <arm>\n",
      "================================================================================\n",
      "Validation loss: 7.7755\n",
      "(0:0:17) step 10/143, epoch 0 Training Loss = 6.83253 :: 1481.185 phrases/sec :: (0:1:48) hours left\n",
      "(0:0:33) step 20/143, epoch 0 Training Loss = 6.36712 :: 1419.343 phrases/sec :: (0:1:38) hours left\n",
      "(0:0:49) step 30/143, epoch 0 Training Loss = 6.00063 :: 1379.283 phrases/sec :: (0:1:26) hours left\n",
      "(0:1:4) step 40/143, epoch 0 Training Loss = 5.61873 :: 1379.786 phrases/sec :: (0:1:11) hours left\n",
      "(0:1:19) step 50/143, epoch 0 Training Loss = 5.33238 :: 1381.986 phrases/sec :: (0:0:55) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <centerboard> '<X> inspecting on <Y>' <yacht>\n",
      "0: 1.000 : <centerboard> '<X> inspecting on <Y>' <yacht>\n",
      "1: 1.000 : <e> '<X> mail in commented on <Y>' <request>\n",
      "2: 0.998 : <war> '<X> erupted on <Y>' <internet>\n",
      "3: 0.998 : <report> '<X> insisted on <Y>' <need>\n",
      "4: 0.998 : <players> '<X> flew on <Y>' <plane>\n",
      "5: 0.998 : <ideas> '<X> insist on <Y>' <gambles>\n",
      "6: 0.997 : <dog> '<X> has ball on <Y>' <snout>\n",
      "7: 0.996 : <chap> '<X> plays on <Y>' <fiddle>\n",
      "8: 0.992 : <series> '<X> reflected on <Y>' <changes>\n",
      "9: 0.986 : <light> '<X> on <Y>' <telephone>\n",
      "10: 0.985 : <timer> '<X> on <Y>' <oven>\n",
      "11: 0.985 : <meeting> '<X> on <Y>' <road>\n",
      "12: 0.956 : <novelist> '<X> hunched before <Y>' <computer>\n",
      "13: 0.952 : <attention> '<X> directed toward <Y>' <study>\n",
      "14: 0.938 : <works> '<X> of exhibition 's by <Y>' <quilters>\n",
      "15: 0.937 : <insert> '<X> placed inside of <Y>' <machine>\n",
      "16: 0.935 : <book> '<X> looks at <Y>' <life>\n",
      "17: 0.934 : <trail> '<X> starts at <Y>' <elevation>\n",
      "18: 0.934 : <walk> '<X> starts at <Y>' <entry>\n",
      "19: 0.933 : <controversy> '<X> over <Y>' <research>\n",
      "================================================================================\n",
      "Validation loss: 7.0260\n",
      "(0:1:35) step 60/143, epoch 0 Training Loss = 5.00068 :: 1368.797 phrases/sec :: (0:0:40) hours left\n",
      "(0:1:51) step 70/143, epoch 0 Training Loss = 4.71481 :: 1368.495 phrases/sec :: (0:0:25) hours left\n",
      "(0:2:7) step 80/143, epoch 0 Training Loss = 4.44957 :: 1359.987 phrases/sec :: (0:0:9) hours left\n",
      "(0:2:23) step 90/143, epoch 0 Training Loss = 4.17294 :: 1354.386 phrases/sec :: (-1:59:54) hours left\n",
      "(0:2:39) step 100/143, epoch 0 Training Loss = 3.95754 :: 1349.346 phrases/sec :: (-1:59:39) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <fertilizer> '<X> <Y>' <company>\n",
      "0: 1.000 : <fish> '<X> <Y>' <oil>\n",
      "1: 1.000 : <apricot> '<X> <Y>' <marmalade>\n",
      "2: 1.000 : <cranberry> '<X> <Y>' <syrup>\n",
      "3: 1.000 : <rice> '<X> <Y>' <spirits>\n",
      "4: 1.000 : <lemon> '<X> <Y>' <cake>\n",
      "5: 1.000 : <lemon> '<X> <Y>' <cake>\n",
      "6: 1.000 : <wool> '<X> <Y>' <industry>\n",
      "7: 1.000 : <radio> '<X> <Y>' <tuner>\n",
      "8: 1.000 : <snowstorm> '<X> <Y>' <losses>\n",
      "9: 1.000 : <drinking> '<X> <Y>' <regulations>\n",
      "10: 1.000 : <fertilizer> '<X> <Y>' <company>\n",
      "11: 1.000 : <powerboat> '<X> <Y>' <manufacturer>\n",
      "12: 1.000 : <vegetable> '<X> <Y>' <oil>\n",
      "13: 1.000 : <famine> '<X> <Y>' <drought>\n",
      "14: 0.999 : <snake> '<X> <Y>' <tongue>\n",
      "15: 0.999 : <manufacturer> '<X> <Y>' <drug>\n",
      "16: 0.996 : <book> '<X> in becomes <Y>' <gentleman>\n",
      "17: 0.996 : <song> '<X> in later interjected <Y>' <composer>\n",
      "18: 0.992 : <news> '<X> by encouraged contain <Y>' <tables>\n",
      "19: 0.990 : <round> '<X> lets answer <Y>' <contestants>\n",
      "================================================================================\n",
      "Validation loss: 5.9732\n",
      "(0:2:55) step 110/143, epoch 0 Training Loss = 3.72457 :: 1348.026 phrases/sec :: (-1:59:22) hours left\n",
      "(0:3:11) step 120/143, epoch 0 Training Loss = 3.48326 :: 1348.383 phrases/sec :: (-1:59:6) hours left\n",
      "(0:3:26) step 130/143, epoch 0 Training Loss = 3.31943 :: 1349.879 phrases/sec :: (-1:58:51) hours left\n",
      "(0:3:41) step 140/143, epoch 0 Training Loss = 3.13863 :: 1354.316 phrases/sec :: (-1:58:35) hours left\n",
      "Macro P: 3.4585, R: 5.6111, F1: 4.2793\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-5148-22882\n",
      "143\n",
      "***** SUPERVISED TRAINING *****\n",
      "(0:0:0) s 0/143, e 0 avg class xent loss = 36.0884\n",
      "================================================================================\n",
      "(0:0:6) s 0/143, e 0 validation avg class xent loss = 41.8050\n",
      "================================================================================\n",
      "(0:0:13) s 10/143, e 0 avg class xent loss = 49.8496\n",
      "(0:0:20) s 20/143, e 0 avg class xent loss = 46.1433\n",
      "(0:0:27) s 30/143, e 0 avg class xent loss = 39.8964\n",
      "(0:0:34) s 40/143, e 0 avg class xent loss = 45.2551\n",
      "(0:0:41) s 50/143, e 0 avg class xent loss = 43.4558\n",
      "================================================================================\n",
      "(0:0:47) s 50/143, e 0 validation avg class xent loss = 41.2734\n",
      "================================================================================\n",
      "(0:0:54) s 60/143, e 0 avg class xent loss = 34.8209\n",
      "(0:1:1) s 70/143, e 0 avg class xent loss = 41.5711\n",
      "(0:1:8) s 80/143, e 0 avg class xent loss = 38.6681\n",
      "(0:1:15) s 90/143, e 0 avg class xent loss = 36.2837\n",
      "(0:1:22) s 100/143, e 0 avg class xent loss = 37.5554\n",
      "================================================================================\n",
      "(0:1:28) s 100/143, e 0 validation avg class xent loss = 41.8325\n",
      "================================================================================\n",
      "(0:1:35) s 110/143, e 0 avg class xent loss = 39.8811\n",
      "(0:1:41) s 120/143, e 0 avg class xent loss = 38.5125\n",
      "(0:1:48) s 130/143, e 0 avg class xent loss = 34.0491\n",
      "(0:1:55) s 140/143, e 0 avg class xent loss = 36.3052\n",
      "Macro P: 2.9696, R: 6.3103, F1: 4.0386\n",
      "(0:2:3) s 0/143, e 1 avg class xent loss = 44.5962\n",
      "================================================================================\n",
      "(0:2:9) s 0/143, e 1 validation avg class xent loss = 41.5530\n",
      "================================================================================\n",
      "(0:2:16) s 10/143, e 1 avg class xent loss = 41.8416\n",
      "(0:2:23) s 20/143, e 1 avg class xent loss = 41.3753\n",
      "(0:2:29) s 30/143, e 1 avg class xent loss = 34.8698\n",
      "(0:2:36) s 40/143, e 1 avg class xent loss = 43.3469\n",
      "(0:2:43) s 50/143, e 1 avg class xent loss = 39.9641\n",
      "================================================================================\n",
      "(0:2:49) s 50/143, e 1 validation avg class xent loss = 42.0385\n",
      "================================================================================\n",
      "(0:2:56) s 60/143, e 1 avg class xent loss = 38.3166\n",
      "(0:3:3) s 70/143, e 1 avg class xent loss = 40.1569\n",
      "(0:3:10) s 80/143, e 1 avg class xent loss = 41.3971\n",
      "(0:3:17) s 90/143, e 1 avg class xent loss = 43.6437\n",
      "(0:3:24) s 100/143, e 1 avg class xent loss = 47.1593\n",
      "================================================================================\n",
      "(0:3:30) s 100/143, e 1 validation avg class xent loss = 41.6523\n",
      "================================================================================\n",
      "(0:3:36) s 110/143, e 1 avg class xent loss = 36.2582\n",
      "(0:3:43) s 120/143, e 1 avg class xent loss = 39.8743\n",
      "(0:3:50) s 130/143, e 1 avg class xent loss = 35.9074\n",
      "(0:3:57) s 140/143, e 1 avg class xent loss = 41.1442\n",
      "Macro P: 6.2736, R: 3.5953, F1: 4.5710\n",
      "(0:4:5) s 0/143, e 2 avg class xent loss = 40.0312\n",
      "================================================================================\n",
      "(0:4:11) s 0/143, e 2 validation avg class xent loss = 41.2084\n",
      "================================================================================\n",
      "(0:4:18) s 10/143, e 2 avg class xent loss = 44.0076\n",
      "(0:4:25) s 20/143, e 2 avg class xent loss = 40.0248\n",
      "(0:4:32) s 30/143, e 2 avg class xent loss = 41.1660\n",
      "(0:4:39) s 40/143, e 2 avg class xent loss = 42.1219\n",
      "(0:4:45) s 50/143, e 2 avg class xent loss = 42.4387\n",
      "================================================================================\n",
      "(0:4:52) s 50/143, e 2 validation avg class xent loss = 41.9203\n",
      "================================================================================\n",
      "(0:4:58) s 60/143, e 2 avg class xent loss = 35.5203\n",
      "(0:5:5) s 70/143, e 2 avg class xent loss = 47.5107\n",
      "(0:5:12) s 80/143, e 2 avg class xent loss = 37.8834\n",
      "(0:5:19) s 90/143, e 2 avg class xent loss = 41.0447\n",
      "(0:5:26) s 100/143, e 2 avg class xent loss = 41.0996\n",
      "================================================================================\n",
      "(0:5:32) s 100/143, e 2 validation avg class xent loss = 41.6121\n",
      "================================================================================\n",
      "(0:5:39) s 110/143, e 2 avg class xent loss = 40.8214\n",
      "(0:5:46) s 120/143, e 2 avg class xent loss = 40.8310\n",
      "(0:5:53) s 130/143, e 2 avg class xent loss = 38.9782\n",
      "(0:5:59) s 140/143, e 2 avg class xent loss = 37.6248\n",
      "Macro P: 1.9853, R: 4.2629, F1: 2.7089\n",
      "(0:6:7) s 0/143, e 3 avg class xent loss = 42.6088\n",
      "================================================================================\n",
      "(0:6:13) s 0/143, e 3 validation avg class xent loss = 40.8267\n",
      "================================================================================\n",
      "(0:6:20) s 10/143, e 3 avg class xent loss = 34.0976\n",
      "(0:6:27) s 20/143, e 3 avg class xent loss = 33.9804\n",
      "(0:6:34) s 30/143, e 3 avg class xent loss = 38.3654\n",
      "(0:6:41) s 40/143, e 3 avg class xent loss = 41.3681\n",
      "(0:6:47) s 50/143, e 3 avg class xent loss = 42.1336\n",
      "================================================================================\n",
      "(0:6:54) s 50/143, e 3 validation avg class xent loss = 40.9581\n",
      "================================================================================\n",
      "(0:7:1) s 60/143, e 3 avg class xent loss = 39.6491\n",
      "(0:7:7) s 70/143, e 3 avg class xent loss = 44.9696\n",
      "(0:7:15) s 80/143, e 3 avg class xent loss = 37.6641\n",
      "(0:7:21) s 90/143, e 3 avg class xent loss = 34.9394\n",
      "(0:7:28) s 100/143, e 3 avg class xent loss = 37.7925\n",
      "================================================================================\n",
      "(0:7:34) s 100/143, e 3 validation avg class xent loss = 41.2697\n",
      "================================================================================\n",
      "(0:7:41) s 110/143, e 3 avg class xent loss = 41.3619\n",
      "(0:7:48) s 120/143, e 3 avg class xent loss = 40.0131\n",
      "(0:7:55) s 130/143, e 3 avg class xent loss = 39.9062\n",
      "(0:8:2) s 140/143, e 3 avg class xent loss = 38.3440\n",
      "Macro P: 3.8402, R: 4.9872, F1: 4.3392\n",
      "(0:8:9) s 0/143, e 4 avg class xent loss = 39.0189\n",
      "================================================================================\n",
      "(0:8:15) s 0/143, e 4 validation avg class xent loss = 41.2080\n",
      "================================================================================\n",
      "(0:8:22) s 10/143, e 4 avg class xent loss = 39.7470\n",
      "(0:8:29) s 20/143, e 4 avg class xent loss = 42.5998\n",
      "(0:8:36) s 30/143, e 4 avg class xent loss = 42.9787\n",
      "(0:8:43) s 40/143, e 4 avg class xent loss = 38.9192\n",
      "(0:8:50) s 50/143, e 4 avg class xent loss = 41.7904\n",
      "================================================================================\n",
      "(0:8:56) s 50/143, e 4 validation avg class xent loss = 41.4163\n",
      "================================================================================\n",
      "(0:9:3) s 60/143, e 4 avg class xent loss = 40.5985\n",
      "(0:9:9) s 70/143, e 4 avg class xent loss = 40.5362\n",
      "(0:9:16) s 80/143, e 4 avg class xent loss = 37.3950\n",
      "(0:9:24) s 90/143, e 4 avg class xent loss = 42.5787\n",
      "(0:9:30) s 100/143, e 4 avg class xent loss = 40.5971\n",
      "================================================================================\n",
      "(0:9:37) s 100/143, e 4 validation avg class xent loss = 41.2365\n",
      "================================================================================\n",
      "(0:9:43) s 110/143, e 4 avg class xent loss = 39.0790\n",
      "(0:9:50) s 120/143, e 4 avg class xent loss = 37.8117\n",
      "(0:9:57) s 130/143, e 4 avg class xent loss = 38.6038\n",
      "(0:10:4) s 140/143, e 4 avg class xent loss = 35.1502\n",
      "Macro P: 5.0663, R: 3.5925, F1: 4.2040\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-5148-23592\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "CYCLE 17\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "===== UNSUPERVISED TRAINING =====\n",
      "(0:0:1) step 0/143, epoch 0 Training Loss = 7.27930 :: 2778.689 phrases/sec :: (0:1:5) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <sewage> '<X> dumped into <Y>' <river>\n",
      "0: 1.000 : <sewage> '<X> dumped into <Y>' <river>\n",
      "1: 1.000 : <coolant> '<X> leaked into <Y>' <oil>\n",
      "2: 1.000 : <girl> '<X> placed into <Y>' <family>\n",
      "3: 1.000 : <stack> '<X> loading into <Y>' <carton>\n",
      "4: 1.000 : <company> '<X> moved into <Y>' <business>\n",
      "5: 1.000 : <empathy> '<X> poured into <Y>' <poetry>\n",
      "6: 1.000 : <billion> '<X> poured into <Y>' <economy>\n",
      "7: 1.000 : <concrete> '<X> poured into <Y>' <hull>\n",
      "8: 1.000 : <flour> '<X> poured into <Y>' <dragon>\n",
      "9: 1.000 : <aluminium> '<X> poured into <Y>' <ingots>\n",
      "10: 1.000 : <flour> '<X> poured into <Y>' <pan>\n",
      "11: 1.000 : <catheter> '<X> placed into <Y>' <stomach>\n",
      "12: 1.000 : <supernatant> '<X> removed into <Y>' <tube>\n",
      "13: 1.000 : <poodle> '<X> fetched into <Y>' <acre>\n",
      "14: 1.000 : <stores> '<X> draining into <Y>' <memory>\n",
      "15: 1.000 : <travellers> '<X> commuters running into <Y>' <delays>\n",
      "16: 1.000 : <keys> '<X> added into <Y>' <memory>\n",
      "17: 1.000 : <jacks> '<X> spreading into <Y>' <areas>\n",
      "18: 1.000 : <steroids> '<X> inject into <Y>' <muscles>\n",
      "19: 1.000 : <wetlands> '<X> draining into <Y>' <ditches>\n",
      "================================================================================\n",
      "Validation loss: 7.6501\n",
      "(0:0:17) step 10/143, epoch 0 Training Loss = 6.81969 :: 1455.037 phrases/sec :: (0:1:50) hours left\n",
      "(0:0:32) step 20/143, epoch 0 Training Loss = 6.38177 :: 1412.806 phrases/sec :: (0:1:39) hours left\n",
      "(0:0:48) step 30/143, epoch 0 Training Loss = 5.99753 :: 1381.281 phrases/sec :: (0:1:26) hours left\n",
      "(0:1:4) step 40/143, epoch 0 Training Loss = 5.64956 :: 1355.787 phrases/sec :: (0:1:12) hours left\n",
      "(0:1:20) step 50/143, epoch 0 Training Loss = 5.32933 :: 1354.024 phrases/sec :: (0:0:57) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <sword> '<X> appears in photograph with <Y>' <hilt>\n",
      "0: 1.000 : <sword> '<X> appears in photograph with <Y>' <hilt>\n",
      "1: 1.000 : <media> '<X> creates self fulfilling prophesy with <Y>' <reports>\n",
      "2: 1.000 : <user> '<X> accesses menu with <Y>' <keyboard>\n",
      "3: 1.000 : <blow> '<X> made with <Y>' <chisel>\n",
      "4: 1.000 : <burglar> '<X> forgot log before leaving with <Y>' <rings>\n",
      "5: 1.000 : <parents> '<X> killed with <Y>' <pills>\n",
      "6: 1.000 : <accused> '<X> killed with <Y>' <kirpan>\n",
      "7: 1.000 : <crew> '<X> assisted with <Y>' <investigation>\n",
      "8: 1.000 : <users> '<X> navigate with <Y>' <keyboard>\n",
      "9: 1.000 : <editor> '<X> improved with <Y>' <changes>\n",
      "10: 1.000 : <uncle> '<X> liberated with <Y>' <uncle>\n",
      "11: 1.000 : <performer> '<X> covers with <Y>' <newspaper>\n",
      "12: 1.000 : <pathologists> '<X> do with <Y>' <scalpel>\n",
      "13: 1.000 : <suitcase> '<X> with <Y>' <clothing>\n",
      "14: 1.000 : <debtor> '<X> gets liens released for less with <Y>' <redemption>\n",
      "15: 0.997 : <philosophy> '<X> of branch dealing with <Y>' <nature>\n",
      "16: 0.995 : <book> '<X> dealt with <Y>' <impact>\n",
      "17: 0.991 : <suitcase> '<X> with <Y>' <bomb>\n",
      "18: 0.991 : <tube> '<X> cut with <Y>' <knife>\n",
      "19: 0.991 : <sections> '<X> denoted with <Y>' <asterisk>\n",
      "================================================================================\n",
      "Validation loss: 6.5825\n",
      "(0:1:36) step 60/143, epoch 0 Training Loss = 4.97265 :: 1356.756 phrases/sec :: (0:0:41) hours left\n",
      "(0:1:52) step 70/143, epoch 0 Training Loss = 4.66182 :: 1352.388 phrases/sec :: (0:0:25) hours left\n",
      "(0:2:7) step 80/143, epoch 0 Training Loss = 4.43951 :: 1354.386 phrases/sec :: (0:0:10) hours left\n",
      "(0:2:22) step 90/143, epoch 0 Training Loss = 4.17972 :: 1354.402 phrases/sec :: (-1:59:54) hours left\n",
      "(0:2:38) step 100/143, epoch 0 Training Loss = 3.93907 :: 1355.058 phrases/sec :: (-1:59:38) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <striker> '<X> of <Y>' <team>\n",
      "0: 1.000 : <trembling> '<X> of <Y>' <finches>\n",
      "1: 1.000 : <network> '<X> of <Y>' <markets>\n",
      "2: 1.000 : <orchard> '<X> of <Y>' <apples>\n",
      "3: 1.000 : <striker> '<X> of <Y>' <team>\n",
      "4: 1.000 : <cooperative> '<X> of <Y>' <consumers>\n",
      "5: 0.999 : <fastener> '<X> mechanism are components of <Y>' <platform>\n",
      "6: 0.998 : <eggs> '<X> come out of <Y>' <body>\n",
      "7: 0.998 : <congress> '<X> of <Y>' <nations>\n",
      "8: 0.998 : <crash> '<X> of <Y>' <hippopotami>\n",
      "9: 0.998 : <cabinet> '<X> of <Y>' <names>\n",
      "10: 0.998 : <unit> '<X> of <Y>' <musketeers>\n",
      "11: 0.998 : <pack> '<X> of <Y>' <hounds>\n",
      "12: 0.998 : <division> '<X> of <Y>' <musketeers>\n",
      "13: 0.998 : <round> '<X> of <Y>' <drinks>\n",
      "14: 0.998 : <legion> '<X> of <Y>' <marksmen>\n",
      "15: 0.998 : <heel> '<X> of <Y>' <shoes>\n",
      "16: 0.998 : <chapter> '<X> of <Y>' <canons>\n",
      "17: 0.998 : <cornucopia> '<X> of <Y>' <foods>\n",
      "18: 0.998 : <brigade> '<X> of <Y>' <riflemen>\n",
      "19: 0.998 : <pile> '<X> of <Y>' <junk>\n",
      "================================================================================\n",
      "Validation loss: 5.5887\n",
      "(0:2:55) step 110/143, epoch 0 Training Loss = 3.71716 :: 1356.157 phrases/sec :: (-1:59:22) hours left\n",
      "(0:3:10) step 120/143, epoch 0 Training Loss = 3.54517 :: 1360.373 phrases/sec :: (-1:59:6) hours left\n",
      "(0:3:25) step 130/143, epoch 0 Training Loss = 3.34944 :: 1358.923 phrases/sec :: (-1:58:51) hours left\n",
      "(0:3:41) step 140/143, epoch 0 Training Loss = 3.14516 :: 1356.203 phrases/sec :: (-1:58:36) hours left\n",
      "Macro P: 0.7649, R: 3.9711, F1: 1.2827\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-5291-23592\n",
      "143\n",
      "***** SUPERVISED TRAINING *****\n",
      "(0:0:0) s 0/143, e 0 avg class xent loss = 38.2196\n",
      "================================================================================\n",
      "(0:0:6) s 0/143, e 0 validation avg class xent loss = 40.4768\n",
      "================================================================================\n",
      "(0:0:13) s 10/143, e 0 avg class xent loss = 42.5855\n",
      "(0:0:20) s 20/143, e 0 avg class xent loss = 39.9463\n",
      "(0:0:27) s 30/143, e 0 avg class xent loss = 38.9493\n",
      "(0:0:34) s 40/143, e 0 avg class xent loss = 43.7388\n",
      "(0:0:41) s 50/143, e 0 avg class xent loss = 37.6583\n",
      "================================================================================\n",
      "(0:0:47) s 50/143, e 0 validation avg class xent loss = 40.5853\n",
      "================================================================================\n",
      "(0:0:54) s 60/143, e 0 avg class xent loss = 34.7389\n",
      "(0:1:0) s 70/143, e 0 avg class xent loss = 40.9633\n",
      "(0:1:7) s 80/143, e 0 avg class xent loss = 37.5752\n",
      "(0:1:14) s 90/143, e 0 avg class xent loss = 46.4576\n",
      "(0:1:21) s 100/143, e 0 avg class xent loss = 43.4977\n",
      "================================================================================\n",
      "(0:1:28) s 100/143, e 0 validation avg class xent loss = 41.3483\n",
      "================================================================================\n",
      "(0:1:34) s 110/143, e 0 avg class xent loss = 33.8178\n",
      "(0:1:41) s 120/143, e 0 avg class xent loss = 40.3040\n",
      "(0:1:48) s 130/143, e 0 avg class xent loss = 36.1048\n",
      "(0:1:55) s 140/143, e 0 avg class xent loss = 46.8581\n",
      "Macro P: 6.4654, R: 4.5626, F1: 5.3498\n",
      "(0:2:3) s 0/143, e 1 avg class xent loss = 47.2587\n",
      "================================================================================\n",
      "(0:2:9) s 0/143, e 1 validation avg class xent loss = 41.2415\n",
      "================================================================================\n",
      "(0:2:16) s 10/143, e 1 avg class xent loss = 36.5586\n",
      "(0:2:22) s 20/143, e 1 avg class xent loss = 39.8917\n",
      "(0:2:30) s 30/143, e 1 avg class xent loss = 41.1002\n",
      "(0:2:36) s 40/143, e 1 avg class xent loss = 47.1671\n",
      "(0:2:43) s 50/143, e 1 avg class xent loss = 39.5115\n",
      "================================================================================\n",
      "(0:2:50) s 50/143, e 1 validation avg class xent loss = 41.5971\n",
      "================================================================================\n",
      "(0:2:56) s 60/143, e 1 avg class xent loss = 38.0131\n",
      "(0:3:3) s 70/143, e 1 avg class xent loss = 39.2580\n",
      "(0:3:10) s 80/143, e 1 avg class xent loss = 38.0958\n",
      "(0:3:17) s 90/143, e 1 avg class xent loss = 45.5073\n",
      "(0:3:24) s 100/143, e 1 avg class xent loss = 41.1904\n",
      "================================================================================\n",
      "(0:3:31) s 100/143, e 1 validation avg class xent loss = 40.8536\n",
      "================================================================================\n",
      "(0:3:37) s 110/143, e 1 avg class xent loss = 33.6667\n",
      "(0:3:44) s 120/143, e 1 avg class xent loss = 39.7301\n",
      "(0:3:51) s 130/143, e 1 avg class xent loss = 32.4104\n",
      "(0:3:58) s 140/143, e 1 avg class xent loss = 43.9421\n",
      "Macro P: 3.9863, R: 3.3463, F1: 3.6384\n",
      "(0:4:5) s 0/143, e 2 avg class xent loss = 40.0204\n",
      "================================================================================\n",
      "(0:4:11) s 0/143, e 2 validation avg class xent loss = 40.9414\n",
      "================================================================================\n",
      "(0:4:18) s 10/143, e 2 avg class xent loss = 40.6898\n",
      "(0:4:25) s 20/143, e 2 avg class xent loss = 37.7476\n",
      "(0:4:32) s 30/143, e 2 avg class xent loss = 35.4894\n",
      "(0:4:39) s 40/143, e 2 avg class xent loss = 41.9901\n",
      "(0:4:46) s 50/143, e 2 avg class xent loss = 36.8351\n",
      "================================================================================\n",
      "(0:4:52) s 50/143, e 2 validation avg class xent loss = 41.0305\n",
      "================================================================================\n",
      "(0:4:59) s 60/143, e 2 avg class xent loss = 33.5490\n",
      "(0:5:6) s 70/143, e 2 avg class xent loss = 44.1438\n",
      "(0:5:13) s 80/143, e 2 avg class xent loss = 36.2908\n",
      "(0:5:19) s 90/143, e 2 avg class xent loss = 39.2111\n",
      "(0:5:26) s 100/143, e 2 avg class xent loss = 41.8187\n",
      "================================================================================\n",
      "(0:5:33) s 100/143, e 2 validation avg class xent loss = 40.9829\n",
      "================================================================================\n",
      "(0:5:40) s 110/143, e 2 avg class xent loss = 34.2913\n",
      "(0:5:47) s 120/143, e 2 avg class xent loss = 37.5692\n",
      "(0:5:53) s 130/143, e 2 avg class xent loss = 36.1280\n",
      "(0:6:0) s 140/143, e 2 avg class xent loss = 39.7710\n",
      "Macro P: 4.1182, R: 3.8991, F1: 4.0057\n",
      "(0:6:8) s 0/143, e 3 avg class xent loss = 37.1119\n",
      "================================================================================\n",
      "(0:6:14) s 0/143, e 3 validation avg class xent loss = 40.1111\n",
      "================================================================================\n",
      "(0:6:21) s 10/143, e 3 avg class xent loss = 34.6126\n",
      "(0:6:27) s 20/143, e 3 avg class xent loss = 44.0694\n",
      "(0:6:34) s 30/143, e 3 avg class xent loss = 33.2548\n",
      "(0:6:41) s 40/143, e 3 avg class xent loss = 40.7007\n",
      "(0:6:48) s 50/143, e 3 avg class xent loss = 41.5591\n",
      "================================================================================\n",
      "(0:6:54) s 50/143, e 3 validation avg class xent loss = 40.3100\n",
      "================================================================================\n",
      "(0:7:1) s 60/143, e 3 avg class xent loss = 34.9796\n",
      "(0:7:8) s 70/143, e 3 avg class xent loss = 38.5171\n",
      "(0:7:15) s 80/143, e 3 avg class xent loss = 38.0203\n",
      "(0:7:22) s 90/143, e 3 avg class xent loss = 43.0153\n",
      "(0:7:28) s 100/143, e 3 avg class xent loss = 41.9803\n",
      "================================================================================\n",
      "(0:7:34) s 100/143, e 3 validation avg class xent loss = 39.6539\n",
      "================================================================================\n",
      "(0:7:42) s 110/143, e 3 avg class xent loss = 33.4640\n",
      "(0:7:48) s 120/143, e 3 avg class xent loss = 37.1257\n",
      "(0:7:55) s 130/143, e 3 avg class xent loss = 40.9923\n",
      "(0:8:2) s 140/143, e 3 avg class xent loss = 38.8045\n",
      "Macro P: 2.5432, R: 4.5363, F1: 3.2592\n",
      "(0:8:10) s 0/143, e 4 avg class xent loss = 39.2544\n",
      "================================================================================\n",
      "(0:8:16) s 0/143, e 4 validation avg class xent loss = 39.3812\n",
      "================================================================================\n",
      "(0:8:23) s 10/143, e 4 avg class xent loss = 39.6622\n",
      "(0:8:30) s 20/143, e 4 avg class xent loss = 41.8616\n",
      "(0:8:37) s 30/143, e 4 avg class xent loss = 38.7740\n",
      "(0:8:44) s 40/143, e 4 avg class xent loss = 39.4584\n",
      "(0:8:51) s 50/143, e 4 avg class xent loss = 35.6786\n",
      "================================================================================\n",
      "(0:8:57) s 50/143, e 4 validation avg class xent loss = 40.1514\n",
      "================================================================================\n",
      "(0:9:3) s 60/143, e 4 avg class xent loss = 37.7192\n",
      "(0:9:10) s 70/143, e 4 avg class xent loss = 37.4634\n",
      "(0:9:17) s 80/143, e 4 avg class xent loss = 37.1900\n",
      "(0:9:24) s 90/143, e 4 avg class xent loss = 38.8469\n",
      "(0:9:31) s 100/143, e 4 avg class xent loss = 39.4711\n",
      "================================================================================\n",
      "(0:9:37) s 100/143, e 4 validation avg class xent loss = 40.1736\n",
      "================================================================================\n",
      "(0:9:44) s 110/143, e 4 avg class xent loss = 36.1113\n",
      "(0:9:51) s 120/143, e 4 avg class xent loss = 37.1341\n",
      "(0:9:58) s 130/143, e 4 avg class xent loss = 40.0917\n",
      "(0:10:5) s 140/143, e 4 avg class xent loss = 43.9431\n",
      "Macro P: 3.8479, R: 4.1016, F1: 3.9707\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-5291-24302\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "CYCLE 18\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "===== UNSUPERVISED TRAINING =====\n",
      "(0:0:1) step 0/143, epoch 0 Training Loss = 7.11520 :: 2397.956 phrases/sec :: (0:1:15) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <orchard> '<X> of <Y>' <apples>\n",
      "0: 1.000 : <trembling> '<X> of <Y>' <finches>\n",
      "1: 1.000 : <network> '<X> of <Y>' <markets>\n",
      "2: 1.000 : <orchard> '<X> of <Y>' <apples>\n",
      "3: 1.000 : <striker> '<X> of <Y>' <team>\n",
      "4: 1.000 : <cooperative> '<X> of <Y>' <consumers>\n",
      "5: 1.000 : <brotherhood> '<X> of <Y>' <rogues>\n",
      "6: 1.000 : <handful> '<X> of <Y>' <images>\n",
      "7: 1.000 : <squad> '<X> of <Y>' <policemen>\n",
      "8: 1.000 : <charm> '<X> of <Y>' <goldfinches>\n",
      "9: 1.000 : <phalanx> '<X> of <Y>' <umbrellas>\n",
      "10: 1.000 : <chin> '<X> of <Y>' <rockfish>\n",
      "11: 1.000 : <maze> '<X> of <Y>' <jurisdictions>\n",
      "12: 1.000 : <wheel> '<X> of <Y>' <panel>\n",
      "13: 1.000 : <devision> '<X> of <Y>' <crossbowmen>\n",
      "14: 1.000 : <minority> '<X> of <Y>' <physicians>\n",
      "15: 1.000 : <flight> '<X> of <Y>' <aircrafts>\n",
      "16: 1.000 : <fit> '<X> of <Y>' <jacket>\n",
      "17: 1.000 : <indicator> '<X> of <Y>' <transmitter>\n",
      "18: 1.000 : <bore> '<X> of <Y>' <trumpet>\n",
      "19: 1.000 : <rope> '<X> of <Y>' <swing>\n",
      "================================================================================\n",
      "Validation loss: 7.5412\n",
      "(0:0:17) step 10/143, epoch 0 Training Loss = 6.66431 :: 1464.093 phrases/sec :: (0:1:49) hours left\n",
      "(0:0:33) step 20/143, epoch 0 Training Loss = 6.25616 :: 1420.644 phrases/sec :: (0:1:38) hours left\n",
      "(0:0:48) step 30/143, epoch 0 Training Loss = 5.85905 :: 1394.974 phrases/sec :: (0:1:25) hours left\n",
      "(0:1:4) step 40/143, epoch 0 Training Loss = 5.56020 :: 1384.936 phrases/sec :: (0:1:10) hours left\n",
      "(0:1:20) step 50/143, epoch 0 Training Loss = 5.21702 :: 1380.033 phrases/sec :: (0:0:55) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <pellets> '<X> blown into <Y>' <cavities>\n",
      "0: 1.000 : <pellets> '<X> blown into <Y>' <cavities>\n",
      "1: 1.000 : <garbage> '<X> thrown into <Y>' <bin>\n",
      "2: 1.000 : <slider> '<X> inserted into <Y>' <machine>\n",
      "3: 1.000 : <droxyapatite> '<X> implanted into <Y>' <gaps>\n",
      "4: 1.000 : <album> '<X> put into <Y>' <folder>\n",
      "5: 1.000 : <bottom> '<X> welded into <Y>' <casket>\n",
      "6: 0.999 : <supernatant> '<X> removed into <Y>' <tube>\n",
      "7: 0.995 : <catheter> '<X> placed into <Y>' <stomach>\n",
      "8: 0.993 : <company> '<X> moved into <Y>' <business>\n",
      "9: 0.993 : <researchers> '<X> turned into <Y>' <simulator>\n",
      "10: 0.993 : <billions> '<X> flow into <Y>' <products>\n",
      "11: 0.991 : <aircraft> '<X> landing into <Y>' <sea>\n",
      "12: 0.990 : <protests> '<X> turning into <Y>' <revolution>\n",
      "13: 0.990 : <jacks> '<X> spreading into <Y>' <areas>\n",
      "14: 0.990 : <ship> '<X> sinking into <Y>' <ocean>\n",
      "15: 0.990 : <gunman> '<X> pumped into <Y>' <leg>\n",
      "16: 0.990 : <variable> '<X> moving into <Y>' <axis>\n",
      "17: 0.990 : <cocktail> '<X> flew into <Y>' <fan>\n",
      "18: 0.990 : <program> '<X> running into <Y>' <difficulties>\n",
      "19: 0.990 : <water> '<X> running into <Y>' <pipe>\n",
      "================================================================================\n",
      "Validation loss: 6.3700\n",
      "(0:1:36) step 60/143, epoch 0 Training Loss = 4.91813 :: 1373.462 phrases/sec :: (0:0:39) hours left\n",
      "(0:1:51) step 70/143, epoch 0 Training Loss = 4.64314 :: 1366.680 phrases/sec :: (0:0:24) hours left\n",
      "(0:2:7) step 80/143, epoch 0 Training Loss = 4.35122 :: 1358.981 phrases/sec :: (0:0:9) hours left\n",
      "(0:2:23) step 90/143, epoch 0 Training Loss = 4.11578 :: 1359.961 phrases/sec :: (-1:59:53) hours left\n",
      "(0:2:39) step 100/143, epoch 0 Training Loss = 3.87182 :: 1356.324 phrases/sec :: (-1:59:38) hours left\n",
      "================================================================================\n",
      "Top 20 closest phrases to <slowdown> '<X> caused by <Y>' <recession>\n",
      "0: 1.000 : <damage> '<X> caused by <Y>' <storm>\n",
      "1: 1.000 : <death> '<X> caused by <Y>' <storm>\n",
      "2: 1.000 : <devastations> '<X> caused by <Y>' <storms>\n",
      "3: 1.000 : <emergency> '<X> caused by <Y>' <landslide>\n",
      "4: 1.000 : <slowdown> '<X> caused by <Y>' <recession>\n",
      "5: 1.000 : <devastation> '<X> caused by <Y>' <tornado>\n",
      "6: 1.000 : <suffering> '<X> caused by <Y>' <drinking>\n",
      "7: 1.000 : <sorrow> '<X> caused by <Y>' <attack>\n",
      "8: 1.000 : <influx> '<X> triggered by <Y>' <immigration>\n",
      "9: 1.000 : <interference> '<X> triggered by <Y>' <process>\n",
      "10: 1.000 : <spark> '<X> triggered by <Y>' <beam>\n",
      "11: 1.000 : <disruption> '<X> caused by <Y>' <strike>\n",
      "12: 1.000 : <hardship> '<X> caused by <Y>' <recession>\n",
      "13: 1.000 : <preparations> '<X> developed by <Y>' <company>\n",
      "14: 0.998 : <chaos> '<X> urgency caused by <Y>' <hurricanes>\n",
      "15: 0.998 : <cocoon> '<X> created by army of <Y>' <caterpillars>\n",
      "16: 0.998 : <fevers> '<X> caused by <Y>' <colds>\n",
      "17: 0.998 : <trauma> '<X> caused by <Y>' <arrival>\n",
      "18: 0.998 : <frustration> '<X> caused by <Y>' <system>\n",
      "19: 0.998 : <sound> '<X> produced by <Y>' <drum>\n",
      "================================================================================\n",
      "Validation loss: 5.4912\n",
      "(0:2:55) step 110/143, epoch 0 Training Loss = 3.65171 :: 1357.051 phrases/sec :: (-1:59:22) hours left\n",
      "(0:3:10) step 120/143, epoch 0 Training Loss = 3.45883 :: 1355.324 phrases/sec :: (-1:59:7) hours left\n",
      "(0:3:25) step 130/143, epoch 0 Training Loss = 3.26344 :: 1357.544 phrases/sec :: (-1:58:51) hours left\n",
      "(0:3:41) step 140/143, epoch 0 Training Loss = 3.10348 :: 1355.902 phrases/sec :: (-1:58:35) hours left\n",
      "Macro P: 1.6864, R: 3.9118, F1: 2.3567\n",
      "Saving model to file: checkpoints/semeval_blank_rank_lambda_0.01_clip1.ckpt-5434-24302\n",
      "143\n",
      "***** SUPERVISED TRAINING *****\n",
      "(0:0:0) s 0/143, e 0 avg class xent loss = 40.2268\n",
      "================================================================================\n",
      "(0:0:6) s 0/143, e 0 validation avg class xent loss = 40.5467\n",
      "================================================================================\n",
      "(0:0:13) s 10/143, e 0 avg class xent loss = 45.8768\n",
      "(0:0:20) s 20/143, e 0 avg class xent loss = 45.6549\n",
      "(0:0:27) s 30/143, e 0 avg class xent loss = 41.7458\n",
      "(0:0:34) s 40/143, e 0 avg class xent loss = 43.8777\n",
      "(0:0:41) s 50/143, e 0 avg class xent loss = 33.9496\n",
      "================================================================================\n",
      "(0:0:47) s 50/143, e 0 validation avg class xent loss = 40.5526\n",
      "================================================================================\n",
      "(0:0:54) s 60/143, e 0 avg class xent loss = 36.8865\n",
      "(0:1:1) s 70/143, e 0 avg class xent loss = 42.7378\n",
      "(0:1:7) s 80/143, e 0 avg class xent loss = 35.7892\n",
      "(0:1:14) s 90/143, e 0 avg class xent loss = 37.8037\n",
      "(0:1:21) s 100/143, e 0 avg class xent loss = 41.4262\n",
      "================================================================================\n",
      "(0:1:27) s 100/143, e 0 validation avg class xent loss = 40.8273\n",
      "================================================================================\n",
      "(0:1:34) s 110/143, e 0 avg class xent loss = 36.8997\n",
      "(0:1:41) s 120/143, e 0 avg class xent loss = 35.2952\n",
      "(0:1:48) s 130/143, e 0 avg class xent loss = 40.8648\n",
      "(0:1:55) s 140/143, e 0 avg class xent loss = 36.2599\n",
      "Macro P: 3.6985, R: 4.2803, F1: 3.9682\n",
      "(0:2:2) s 0/143, e 1 avg class xent loss = 39.3885\n",
      "================================================================================\n",
      "(0:2:9) s 0/143, e 1 validation avg class xent loss = 40.7971\n",
      "================================================================================\n",
      "(0:2:15) s 10/143, e 1 avg class xent loss = 45.3167\n",
      "(0:2:22) s 20/143, e 1 avg class xent loss = 46.1696\n",
      "(0:2:29) s 30/143, e 1 avg class xent loss = 42.9035\n",
      "(0:2:36) s 40/143, e 1 avg class xent loss = 46.1372\n",
      "(0:2:43) s 50/143, e 1 avg class xent loss = 37.6263\n",
      "================================================================================\n",
      "(0:2:50) s 50/143, e 1 validation avg class xent loss = 41.4786\n",
      "================================================================================\n",
      "(0:2:57) s 60/143, e 1 avg class xent loss = 34.1369\n",
      "(0:3:3) s 70/143, e 1 avg class xent loss = 37.8922\n",
      "(0:3:10) s 80/143, e 1 avg class xent loss = 35.5494\n",
      "(0:3:17) s 90/143, e 1 avg class xent loss = 39.6942\n",
      "(0:3:24) s 100/143, e 1 avg class xent loss = 43.2408\n",
      "================================================================================\n",
      "(0:3:31) s 100/143, e 1 validation avg class xent loss = 40.9274\n",
      "================================================================================\n",
      "(0:3:38) s 110/143, e 1 avg class xent loss = 39.9895\n",
      "(0:3:45) s 120/143, e 1 avg class xent loss = 40.1341\n",
      "(0:3:53) s 130/143, e 1 avg class xent loss = 37.9138\n",
      "(0:4:1) s 140/143, e 1 avg class xent loss = 39.1435\n",
      "Macro P: 3.6407, R: 5.6303, F1: 4.4220\n",
      "(0:4:9) s 0/143, e 2 avg class xent loss = 40.2465\n",
      "================================================================================\n",
      "(0:4:16) s 0/143, e 2 validation avg class xent loss = 40.5929\n",
      "================================================================================\n",
      "(0:4:24) s 10/143, e 2 avg class xent loss = 38.3103\n",
      "(0:4:31) s 20/143, e 2 avg class xent loss = 41.7864\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-f782be945a4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mclass_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mclass_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mxent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_class_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mclass_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mclass_step\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdisplay_mod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdivmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-113-07473aad75eb>\u001b[0m in \u001b[0;36mpartial_class_fit\u001b[0;34m(self, input_phrases, input_targets, class_labels, input_lengths, keep_prob)\u001b[0m\n\u001b[1;32m    514\u001b[0m                                                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_labels_mask\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mclass_labels_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m                                                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_lengths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minput_lengths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m                                                             self._keep_prob:keep_prob})\n\u001b[0m\u001b[1;32m    517\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_summaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_summary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thomaseffland/.virtualenvs/rel/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict)\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;34m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m`\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mdoesn\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mexist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \"\"\"\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpartial_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thomaseffland/.virtualenvs/rel/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict)\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m     results = self._do_run(handle, target_list, unique_fetches,\n\u001b[0;32m--> 511\u001b[0;31m                            feed_dict_string)\n\u001b[0m\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thomaseffland/.virtualenvs/rel/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict)\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 564\u001b[0;31m                            target_list)\n\u001b[0m\u001b[1;32m    565\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/thomaseffland/.virtualenvs/rel/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    569\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatusNotOK\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m       \u001b[0me_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thomaseffland/.virtualenvs/rel/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for cycle in range(20):\n",
    "    print(\"+\"*80)\n",
    "    print(\"CYCLE %i\" % cycle)\n",
    "    print(\"+\"*80)\n",
    "    # hyperparameters\n",
    "    num_epochs = 1\n",
    "    batch_size =50\n",
    "    neg_per = 25\n",
    "    num_nearby = 20\n",
    "    nearby_mod = 50\n",
    "    sample_power = .75\n",
    "    DH.scale_vocab_dist(sample_power)\n",
    "\n",
    "    # # bookkeeping\n",
    "    num_steps = DH.num_steps(batch_size)\n",
    "    total_step = 1\n",
    "    save_interval = 30 * 60 # half hour in seconds\n",
    "    save_time = time()\n",
    "\n",
    "    #timing stuff\n",
    "    start = time()\n",
    "    fit_time = 0\n",
    "    nearby_time = 0\n",
    "    print(\"===== UNSUPERVISED TRAINING =====\")\n",
    "    for epoch in range(num_epochs):\n",
    "        if cycle == 0: break # do supervised first\n",
    "        offset = 0 #if epoch else 400\n",
    "        DH.shuffle_data()\n",
    "        for step , batch in enumerate(DH.batches(batch_size, offset=offset, neg_per=neg_per)):\n",
    "            if not step: step = offset\n",
    "            t0 = time()\n",
    "            loss = drnn.partial_unsup_fit(*batch)\n",
    "            fit_time = (fit_time * float(total_step) +  time() - t0) / (total_step + 1) # running average\n",
    "            if step % 10 == 0:\n",
    "                m,s = divmod(time()-start, 60)\n",
    "                h,m = divmod(m, 60)\n",
    "                left = time_left(num_epochs, num_steps, fit_time, nearby_time, start, nearby_mod)\n",
    "                ml,sl = divmod(left, 60)\n",
    "                hl,ml = divmod(ml, 60)\n",
    "                pps = batch_size*(neg_per + 1) / fit_time \n",
    "                print(\"(%i:%i:%i) step %i/%i, epoch %i Training Loss = %1.5f :: %0.3f phrases/sec :: (%i:%i:%i) hours left\" \n",
    "                      % (h,m,s, step, num_steps, epoch, loss, pps, hl, ml, sl))\n",
    "            if (total_step-1) % nearby_mod == 0: # do one right away so we get a good timing estimate\n",
    "                t0 = time()\n",
    "                run_validation_test(num_nearby) # check out the nearby phrases in the validation set\n",
    "                valid_loss = drnn.validation_loss(*DH.validation_batch())\n",
    "                print(\"Validation loss: %0.4f\" % valid_loss)\n",
    "                nearby_time = (nearby_time * float(total_step) + time() - t0) / (total_step + 1) # running average\n",
    "\n",
    "            if (time() - save_time) > save_interval:\n",
    "                print(\"Saving model...\")\n",
    "                drnn.checkpoint()\n",
    "                save_time = time()\n",
    "            total_step +=1\n",
    "        valid_batch = DH.classification_batch(len(valid['labels']), valid['sdps'], valid['targets'], valid['labels'])\n",
    "        label_set = set(train['labels'])\n",
    "        preds = drnn.predict(valid_batch[0], valid_batch[1], valid_batch[3])\n",
    "        cm, stats = confusion_matrix(preds, valid['labels'], label_set)\n",
    "        print(\"Macro P: %2.4f, R: %3.4f, F1: %0.4f\" % (stats['macro_precision'], stats['macro_recall'], stats['macro_f1']))\n",
    "    drnn.checkpoint()\n",
    "\n",
    "    batch_size = 50\n",
    "    class_steps = len(train['labels']) // batch_size\n",
    "    class_epochs = 5\n",
    "    display_mod = 10\n",
    "    valid_mod = 50\n",
    "\n",
    "\n",
    "\n",
    "    print(num_steps)\n",
    "    print(\"***** SUPERVISED TRAINING *****\")\n",
    "    start = time()\n",
    "    for class_epoch in range(class_epochs):\n",
    "    #     class_batch = DH.classification_batch(batch_size, train['sdps'], train['targets'], train['labels'], offset=0)\n",
    "    #     random.shuffle(class_batch)\n",
    "\n",
    "        for class_step in range(class_steps):\n",
    "            inputs, targets, labels, lens = DH.classification_batch(batch_size, train['sdps'], train['targets'], train['labels'], offset=class_step)\n",
    "            class_batch = zip(inputs, targets, labels, lens)\n",
    "            random.shuffle(class_batch)\n",
    "            class_batch = zip(*class_batch)\n",
    "            xent = drnn.partial_class_fit(*class_batch)\n",
    "            if class_step % display_mod == 0:   \n",
    "                m,s = divmod(time()-start, 60)\n",
    "                h,m = divmod(m, 60)\n",
    "                print(\"(%i:%i:%i) s %i/%i, e %i avg class xent loss = %0.4f\" % (h,m,s, class_step, num_steps, class_epoch, xent))\n",
    "            if class_step % valid_mod == 0:\n",
    "                valid_batch = DH.classification_batch(len(valid['labels']), valid['sdps'], valid['targets'], valid['labels'])\n",
    "                valid_xent = drnn.validation_class_loss(*valid_batch)\n",
    "                m,s = divmod(time()-start, 60)\n",
    "                h,m = divmod(m, 60)\n",
    "                print(\"=\"*80)\n",
    "                print(\"(%i:%i:%i) s %i/%i, e %i validation avg class xent loss = %0.4f\" % (h,m,s, class_step, num_steps, class_epoch, valid_xent))\n",
    "                print(\"=\"*80)\n",
    "    #             print(\"Saving model...\")\n",
    "    #             drnn.checkpoint()\n",
    "        label_set = set(train['labels'])\n",
    "        preds = drnn.predict(valid_batch[0], valid_batch[1], valid_batch[3])\n",
    "        cm, stats = confusion_matrix(preds, valid['labels'], label_set)\n",
    "        print(\"Macro P: %2.4f, R: %3.4f, F1: %0.4f\" % (stats['macro_precision'], stats['macro_recall'], stats['macro_f1']))\n",
    "    drnn.checkpoint()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
